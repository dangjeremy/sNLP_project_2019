{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Create datasets.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"frQxvuJ0MtzY","colab_type":"text"},"cell_type":"markdown","source":["# NLP assignment 3 - create datasets"]},{"metadata":{"id":"nps6QSr6-VF9","colab_type":"text"},"cell_type":"markdown","source":["## Imports"]},{"metadata":{"id":"P5kCV0ym-PBV","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import csv\n","import json\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_Y5s_mQ6-0j9","colab_type":"code","outputId":"01d467e1-778c-41c7-c4e7-ab020e612269","executionInfo":{"status":"ok","timestamp":1551716688079,"user_tz":0,"elapsed":19580,"user":{"displayName":"Joe Farrington","photoUrl":"https://lh5.googleusercontent.com/-bNEtdlkbGn8/AAAAAAAAAAI/AAAAAAAAAF4/7VpSGeR6wrY/s64/photo.jpg","userId":"09132137217736073231"}},"colab":{"base_uri":"https://localhost:8080/","height":189}},"cell_type":"code","source":["#Allow access to Google Drive\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"metadata":{"id":"lX_hoLrZLPop","colab_type":"text"},"cell_type":"markdown","source":["## Load in the data using the script from the SARC GitHub\n","https://github.com/NLPrinceton/SARC"]},{"metadata":{"id":"2fB14WvfLYqV","colab_type":"code","colab":{}},"cell_type":"code","source":["def load_sarc_responses(train_file, test_file, comment_file, lower=True):\n","  '''loads SARC data from csv files\n","  Args:\n","    train_file: csv file with train sequences\n","    test_file: csv file with train sequences\n","    comment_file: json file with details about all comments\n","    lower: boolean; if True, converts comments to lowercase\n","  Returns:\n","    train_sequences, train_labels, test_sequences, test_labels\n","    train_sequences: {'ancestors': list of ancestors for all sequences,\n","                      'responses': list of responses for all sequences}\n","    train_labels: list of labels for responses for all sequences.\n","  '''\n","\n","  with open(comment_file, 'r') as f:\n","    comments = json.load(f)\n","\n","  train_docs = {'ancestors': [], 'responses': []}\n","  train_labels = []\n","  with open(train_file, 'r') as f:\n","    reader = csv.reader(f, delimiter='|')\n","    for row in reader:\n","      ancestors = row[0].split(' ')\n","      responses = row[1].split(' ')\n","      labels = row[2].split(' ')\n","      if lower:\n","        train_docs['ancestors'].append([comments[r]['text'].lower() for r in ancestors])\n","        train_docs['responses'].append([comments[r]['text'].lower() for r in responses])\n","      else:\n","        train_docs['ancestors'].append([comments[r]['text'] for r in ancestors])\n","        train_docs['responses'].append([comments[r]['text'] for r in responses])\n","      train_labels.append(labels)\n","\n","  test_docs = {'ancestors': [], 'responses': []}\n","  test_labels = []\n","  with open(test_file, 'r') as f:\n","    reader = csv.reader(f, delimiter='|')\n","    for row in reader:\n","      ancestors = row[0].split(' ')\n","      responses = row[1].split(' ')\n","      labels = row[2].split(' ')\n","      if lower:\n","        test_docs['ancestors'].append([comments[r]['text'].lower() for r in ancestors])\n","        test_docs['responses'].append([comments[r]['text'].lower() for r in responses])\n","      else:\n","        test_docs['ancestors'].append([comments[r]['text'] for r in ancestors])\n","        test_docs['responses'].append([comments[r]['text'] for r in responses])\n","      test_labels.append(labels)\n","\n","  return train_docs, test_docs, train_labels, test_labels"],"execution_count":0,"outputs":[]},{"metadata":{"id":"oGiehT0nLtCr","colab_type":"code","colab":{}},"cell_type":"code","source":["### SARC Directory Paths ###\n","SARC_POL = '/content/gdrive/My Drive/SARC pol/'"],"execution_count":0,"outputs":[]},{"metadata":{"id":"WZR7Dq3fLwtl","colab_type":"code","colab":{}},"cell_type":"code","source":["#Load in the balanced data\n","balanced_train_docs, balanced_test_docs, balanced_train_labels, balanced_test_labels = load_sarc_responses(\n","    SARC_POL+'train-balanced.csv', SARC_POL+'test-balanced.csv', \n","    SARC_POL+'comments.json', lower=False)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"au4zfhMsMKEF","colab_type":"code","colab":{}},"cell_type":"code","source":["#Load in the unbalanced test data\n","_, unbalanced_test_docs, _, unbalanced_test_labels = load_sarc_responses(\n","    SARC_POL+'train-unbalanced.csv', SARC_POL+'test-unbalanced.csv', \n","    SARC_POL+'comments.json', lower=False)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"CT2e55h3Mbcu","colab_type":"text"},"cell_type":"markdown","source":["## Split the balanced training set to create a training set (80% of original) and a validation set (20%)"]},{"metadata":{"id":"rnu0di8FMpRC","colab_type":"code","colab":{}},"cell_type":"code","source":["#Create a dataframe of the ancestors, so that each has a unique index\n","anc_df = pd.DataFrame(balanced_train_docs['ancestors'])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wIjvWaa3NKn6","colab_type":"code","colab":{}},"cell_type":"code","source":["#Perform a random split\n","anc_train, anc_valid = train_test_split(anc_df, test_size = 0.2, random_state = 5)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"NhG2SHBdOJc0","colab_type":"code","colab":{}},"cell_type":"code","source":["#Create a dataframe for the 80% training set\n","resp_train = pd.DataFrame(columns = ['ancestor_index', 'response', 'label'])\n","\n","for i in anc_train.index:\n","  resp_train = resp_train.append({\"ancestor_index\": int(i), \"response\": balanced_train_docs['responses'][i][0], \"label\": balanced_train_labels[i][0]}, ignore_index = True)\n","  resp_train = resp_train.append({\"ancestor_index\": int(i), \"response\": balanced_train_docs['responses'][i][1], \"label\": balanced_train_labels[i][1]}, ignore_index = True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"nonWYYHTOJX7","colab_type":"code","colab":{}},"cell_type":"code","source":["#Create a dataframe for the 20% validation set\n","resp_valid = pd.DataFrame(columns = ['ancestor_index', 'response', 'label'])\n","\n","for i in anc_valid.index:\n","  resp_valid = resp_valid.append({\"ancestor_index\": int(i), \"response\": balanced_train_docs['responses'][i][0], \"label\": balanced_train_labels[i][0]}, ignore_index = True)\n","  resp_valid = resp_valid.append({\"ancestor_index\": int(i), \"response\": balanced_train_docs['responses'][i][1], \"label\": balanced_train_labels[i][1]}, ignore_index = True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"T0sy5I5HRbI1","colab_type":"text"},"cell_type":"markdown","source":["### Save the split training and validation sets as csv files: we will call this training set the 100% project training set. "]},{"metadata":{"id":"uR-tRditNVBF","colab_type":"code","colab":{}},"cell_type":"code","source":["#100% project training set\n","resp_train.to_csv(SARC_POL+'project_data/project_training_100.csv')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"U8P-fcHaSOfB","colab_type":"code","colab":{}},"cell_type":"code","source":["#validation set\n","resp_valid.to_csv(SARC_POL+'project_data/project_validation.csv')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"jccMEDEPSWyU","colab_type":"text"},"cell_type":"markdown","source":["## Split the project training set into the smaller training sets: 50%, 25% and 12.5%"]},{"metadata":{"id":"vBpn9O-iSel_","colab_type":"text"},"cell_type":"markdown","source":["### 50% project training set"]},{"metadata":{"id":"QNvFPRphSdn3","colab_type":"code","colab":{}},"cell_type":"code","source":["#Perform a random split\n","anc_train50, _ = train_test_split(anc_train, test_size = 0.5, random_state = 50)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"61wkoFWYSyXq","colab_type":"code","colab":{}},"cell_type":"code","source":["#Create a dataframe for the 50% project training set\n","resp_train50 = pd.DataFrame(columns = ['ancestor_index', 'response', 'label'])\n","\n","for i in anc_train50.index:\n","  resp_train50 = resp_train50.append({\"ancestor_index\": int(i), \"response\": balanced_train_docs['responses'][i][0], \"label\": balanced_train_labels[i][0]}, ignore_index = True)\n","  resp_train50 = resp_train50.append({\"ancestor_index\": int(i), \"response\": balanced_train_docs['responses'][i][1], \"label\": balanced_train_labels[i][1]}, ignore_index = True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"tFPHopDxS8jH","colab_type":"code","colab":{}},"cell_type":"code","source":["#Save to CSV\n","resp_train50.to_csv(SARC_POL+'project_data/project_training_50.csv')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wbtkHeJ3TI9R","colab_type":"text"},"cell_type":"markdown","source":["### 25% project training set"]},{"metadata":{"id":"IlT-7UfjTDxj","colab_type":"code","colab":{}},"cell_type":"code","source":["#Perform a random split\n","anc_train25, _ = train_test_split(anc_train, test_size = 0.75, random_state = 25)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"2qwuj6b2TWt4","colab_type":"code","colab":{}},"cell_type":"code","source":["#Create a dataframe for the 25% project training set\n","resp_train25 = pd.DataFrame(columns = ['ancestor_index', 'response', 'label'])\n","\n","for i in anc_train25.index:\n","  resp_train25 = resp_train25.append({\"ancestor_index\": int(i), \"response\": balanced_train_docs['responses'][i][0], \"label\": balanced_train_labels[i][0]}, ignore_index = True)\n","  resp_train25 = resp_train25.append({\"ancestor_index\": int(i), \"response\": balanced_train_docs['responses'][i][1], \"label\": balanced_train_labels[i][1]}, ignore_index = True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"OGUpGWbZTcZL","colab_type":"code","colab":{}},"cell_type":"code","source":["#Save to CSV\n","resp_train25.to_csv(SARC_POL+'project_data/project_training_25.csv')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"EmrECgckTjSQ","colab_type":"text"},"cell_type":"markdown","source":["### 12.5% project training set"]},{"metadata":{"id":"dwqRXM7MTmk9","colab_type":"code","colab":{}},"cell_type":"code","source":["#Perform a random split\n","anc_train12, _ = train_test_split(anc_train, test_size = 0.875, random_state = 12)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"EIyLnT60Tmi7","colab_type":"code","colab":{}},"cell_type":"code","source":["#Create a dataframe for the 12.5% project training set\n","resp_train12 = pd.DataFrame(columns = ['ancestor_index', 'response', 'label'])\n","\n","for i in anc_train12.index:\n","  resp_train12 = resp_train12.append({\"ancestor_index\": int(i), \"response\": balanced_train_docs['responses'][i][0], \"label\": balanced_train_labels[i][0]}, ignore_index = True)\n","  resp_train12 = resp_train12.append({\"ancestor_index\": int(i), \"response\": balanced_train_docs['responses'][i][1], \"label\": balanced_train_labels[i][1]}, ignore_index = True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"1Ll9BwwKTmgX","colab_type":"code","colab":{}},"cell_type":"code","source":["#Save to CSV\n","resp_train12.to_csv(SARC_POL+'project_data/project_training_12.csv')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kM85Rf35g0pU","colab_type":"text"},"cell_type":"markdown","source":["### 6.25% training set"]},{"metadata":{"id":"HMtq6e5qgvz9","colab_type":"code","colab":{}},"cell_type":"code","source":["#Perform a random split\n","anc_train6, _ = train_test_split(anc_train, test_size = 0.9375, random_state = 6)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"6vhl_qoRgvx_","colab_type":"code","colab":{}},"cell_type":"code","source":["#Create a dataframe for the 6.25% project training set\n","resp_train6 = pd.DataFrame(columns = ['ancestor_index', 'response', 'label'])\n","\n","for i in anc_train6.index:\n","  resp_train6 = resp_train6.append({\"ancestor_index\": int(i), \"response\": balanced_train_docs['responses'][i][0], \"label\": balanced_train_labels[i][0]}, ignore_index = True)\n","  resp_train6 = resp_train6.append({\"ancestor_index\": int(i), \"response\": balanced_train_docs['responses'][i][1], \"label\": balanced_train_labels[i][1]}, ignore_index = True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"jSUmcrhFgymi","colab_type":"code","colab":{}},"cell_type":"code","source":["#Save to CSV\n","resp_train6.to_csv(SARC_POL+'project_data/project_training_6.csv')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"F3OiNahWUM3E","colab_type":"text"},"cell_type":"markdown","source":["## Balanced test set"]},{"metadata":{"id":"uKwMVOGxUX3u","colab_type":"code","colab":{}},"cell_type":"code","source":["#Create a dataframe of the ancestors, so that each has a unique index\n","test_anc_df = pd.DataFrame(balanced_test_docs['ancestors'])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8mj-HIeMUX1j","colab_type":"code","colab":{}},"cell_type":"code","source":["#Create a dataframe for the balanced test set\n","resp_test_balanced = pd.DataFrame(columns = ['ancestor_index', 'response', 'label'])\n","\n","for i in test_anc_df.index:\n","  resp_test_balanced = resp_test_balanced.append({\"ancestor_index\": int(i), \"response\": balanced_test_docs['responses'][i][0], \"label\": balanced_test_labels[i][0]}, ignore_index = True)\n","  resp_test_balanced = resp_test_balanced.append({\"ancestor_index\": int(i), \"response\": balanced_test_docs['responses'][i][1], \"label\": balanced_test_labels[i][1]}, ignore_index = True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Qwla8tArUXyr","colab_type":"code","colab":{}},"cell_type":"code","source":["#Save to CSV\n","resp_test_balanced.to_csv(SARC_POL+'project_data/balanced_test.csv')"],"execution_count":0,"outputs":[]}]}