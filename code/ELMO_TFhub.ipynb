{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T13:46:08.752079Z",
     "start_time": "2019-03-16T13:46:08.472253Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "#!pip install tensorflow_hub\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow_hub as hub\n",
    "import logging\n",
    "import os\n",
    "import pprint\n",
    "#import nltk\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import pickle\n",
    "from sklearn import metrics\n",
    "from keras.engine import Layer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Lambda, Dense, Dropout, LSTM\n",
    "from keras.models import Model, Sequential\n",
    "#from nltk import word_tokenize\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "    raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change working directory and CHOOSE DATA SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T13:36:48.728100Z",
     "start_time": "2019-03-16T13:36:48.724111Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training files: project_training_nn.csv, replace nn for [6,12,25,50,100]\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"D:\\Python Notebooks\\Term 2\\Statistical NLP\")\n",
    "\n",
    "print(\"training files: project_training_nn.csv, replace nn for [6,12,25,50,100]\")\n",
    "\n",
    "# training data path\n",
    "path = \"project_data\\project_training_6.csv\"\n",
    "\n",
    "# validation data path\n",
    "val_path = \"project_data\\project_validation.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Locate data and read data - CHOOSE DATA SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T13:36:48.759046Z",
     "start_time": "2019-03-16T13:36:48.729097Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training files: project_training_nn.csv, replace nn for [6,12,25,50,100]\n",
      "# Comments in training data: 682\n",
      "# Comments in validation data: 2734\n"
     ]
    }
   ],
   "source": [
    "print(\"training files: project_training_nn.csv, replace nn for [6,12,25,50,100]\")\n",
    "\n",
    "# Training set\n",
    "train = pd.read_csv(path, index_col = 0)\n",
    "\n",
    "# Validation set\n",
    "val = pd.read_csv(val_path, index_col = 0)\n",
    "\n",
    "# Testing set\n",
    "#test = pd.read_csv(\"\\project_data\\balanced_test.csv\", index_col = 0)\n",
    "\n",
    "\n",
    "print(\"# Comments in training data:\", len(train))\n",
    "print(\"# Comments in validation data:\", len(val))\n",
    "#print(\"# Comments in testing data:\", len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-processing - lowercasing & sentence capping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T13:36:48.778964Z",
     "start_time": "2019-03-16T13:36:48.761011Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def preprocess(df, token):\n",
    "  \"\"\"\n",
    "  Inputs: df: a DF with the following columns: ancestor_index, response, label\n",
    "          token: a boolean which leaves responses either tokenised (1) or untokenised (0)\n",
    "          \n",
    "  Output: lower case and sentence cap by 50 words response column \n",
    "  \"\"\"\n",
    "  # lower case sentence\n",
    "  \n",
    "  dataframe = df\n",
    "  \n",
    "  if token == 0:\n",
    "  \n",
    "    dataframe['response'] = dataframe['response'].str.lower()\n",
    "  \n",
    "    # 50 word sentence cap\n",
    "  \n",
    "    # split into tokens\n",
    "    dataframe['response'] = dataframe['response'].str.split()\n",
    "  \n",
    "    # Create loop which says if list element > 50 then return first 50 words else\n",
    "  \n",
    "    response = df['response'].tolist()\n",
    "    for i in range(len(response)):\n",
    "      if len(response[i]) > 50:\n",
    "        response[i] = (response[i][:50])\n",
    "      \n",
    "      else:\n",
    "        response[i] = (response[i])\n",
    "  \n",
    "    dataframe['response'] = response\n",
    "  \n",
    "    # Untokenize sentences\n",
    "    dataframe['response'] = dataframe['response'].str.join(' ')\n",
    "    \n",
    "    return dataframe\n",
    "    \n",
    "    \n",
    "  # Case where token = True\n",
    "  else:\n",
    "  \n",
    "    dataframe['response'] = dataframe['response'].str.lower()\n",
    "  \n",
    "    # 50 word sentence cap\n",
    "  \n",
    "    # split into tokens\n",
    "    dataframe['response'] = dataframe['response'].str.split()\n",
    "  \n",
    "    # Create loop which says if list element > 50 then return first 50 words else\n",
    "  \n",
    "    response = df['response'].tolist()\n",
    "    for i in range(len(response)):\n",
    "      if len(response[i]) > 50:\n",
    "        response[i] = (response[i][:50])\n",
    "      \n",
    "      else:\n",
    "        response[i] = (response[i])\n",
    "  \n",
    "    dataframe['response'] = response         \n",
    "      \n",
    "    return dataframe\n",
    "\n",
    "# Preprocess datasets\n",
    "\n",
    "train = preprocess(df = train, token = 0)\n",
    "val = preprocess(df = val, token = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separate features from labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T13:36:48.788970Z",
     "start_time": "2019-03-16T13:36:48.780959Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Separate comments and labels\n",
    "\n",
    "X_train = np.asarray(train.loc[:,'response'])\n",
    "\n",
    "y_train = np.asarray(train.loc[:,'label'])\n",
    "\n",
    "# Labels are a 2d vector 0 first col and 1 in the next col for categorical cross entropy\n",
    "y_train = to_categorical(y_train, num_classes=None)\n",
    "\n",
    "# View the  data\n",
    "#print(\"Validation data\")\n",
    "#print(val.head())\n",
    "\n",
    "# Separate comments and labels\n",
    "\n",
    "X_val = np.asarray(val.loc[:,'response'])\n",
    "y_val = np.asarray(val.loc[:,'label'])\n",
    "\n",
    "# Labels are a 2d vector 0 first col and 1 in the next col for categorical cross entropy\n",
    "y_val = to_categorical(y_val, num_classes=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calling Elmo from tfhub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T13:36:51.290724Z",
     "start_time": "2019-03-16T13:36:48.789934Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0316 13:36:51.215114 15480 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "elmo = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=False)\n",
    "embeddings = elmo(X_train, signature = 'default', as_dict = True)[\"default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T13:36:52.658974Z",
     "start_time": "2019-03-16T13:36:51.290724Z"
    },
    "code_folding": [
     2
    ]
   },
   "outputs": [],
   "source": [
    "# Define elmo embedding, uses the fully pretrained model from tfhub with their own corpus\n",
    "\n",
    "def ElmoEmbedding(x):\n",
    "  \"\"\"Inputs: x - a string / sentence\n",
    "             \n",
    "     Output: converts x to a tensor\n",
    "     \n",
    "     Choose [\"default\"] \n",
    "     \n",
    "  \"\"\"\n",
    "  return embed(tf.squeeze(tf.cast(x,tf.string)), signature = \"default\", as_dict = True)[\"default\"]\n",
    "\n",
    "\n",
    "url = \"https://tfhub.dev/google/elmo/2\"\n",
    "embed = hub.Module(url, trainable = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T13:37:27.365679Z",
     "start_time": "2019-03-16T13:36:52.659972Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0316 13:36:53.503872 15480 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat: 0 Epochs: 1 , Learning rate: 0.0001 , Regulariser: 0\n",
      "Train on 682 samples, validate on 2734 samples\n",
      "Epoch 1/1\n",
      "682/682 [==============================] - 33s 48ms/step - loss: 0.7315 - acc: 0.5279 - val_loss: 0.7232 - val_acc: 0.5282\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.52816, saving model to weights-best_0.0001_0.hdf5\n"
     ]
    }
   ],
   "source": [
    "# Elmo embeddings\n",
    "input_text = Input(shape = (1, ), dtype = \"string\")\n",
    "embedding = Lambda(ElmoEmbedding, output_shape = (1024,) )(input_text)\n",
    "\n",
    "# Tunable parameters\n",
    "\n",
    "epochs = [1] #[3, 32]\n",
    "\n",
    "learning_rate = [0.0001]#[0.001, 0.0001]\n",
    "\n",
    "reg = [0]#[0.01, 0.001]\n",
    "#dropout = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "\n",
    "# Execute tf session\n",
    "\n",
    "initializer = keras.initializers.glorot_normal(seed = 0)\n",
    "\n",
    "# placeholder to store validation accuracies\n",
    "accs = pd.DataFrame()\n",
    "\n",
    "with tf.device(\"/gpu:0\"):\n",
    "  with tf.Session() as sess:\n",
    "    \n",
    "    for rep in range(1):\n",
    "      for ep in epochs:\n",
    "        for lr in learning_rate:\n",
    "          for r in reg:\n",
    "            print(\"Repeat:\", rep,\"Epochs:\", ep,\",\", \"Learning rate:\", lr, \",\", \"Regulariser:\", r)\n",
    "            \n",
    "            # Dense layer to pass embeddings through      \n",
    "            dense = Dense(256, \n",
    "                          activation = 'relu', \n",
    "                          bias_initializer = initializer, \n",
    "                          kernel_initializer = initializer)(embedding)\n",
    "            # Regularisation to prevent overfitting\n",
    "            kernel_reg = keras.regularizers.l2(l = r)(embedding) # edit for hyperparam tune   \n",
    "            # Prediction layer      \n",
    "            pred = Dense(2, activation = 'softmax')(dense)\n",
    "            model = Model(inputs = [input_text], outputs = pred)\n",
    "            # Optimisation method      \n",
    "            opt = optimizers.adam(lr = lr) # edit for hyperparam tune\n",
    "            model.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics = ['accuracy'])\n",
    "\n",
    "            K.set_session(sess)\n",
    "\n",
    "            # Checkpointing\n",
    "                  \n",
    "            # Setting the name of the file so that we can load up the model with this file\n",
    "            filepath = f'weights-best_{lr}_{r}.hdf5' # old name f'weights-best_{lr}_{r}_'\n",
    "            # old checkpoint name filepath+'{epoch:02d}'+'_'+'{val_acc:02f}'+'.hdf5'\n",
    "            checkpoint = ModelCheckpoint(filepath, \n",
    "                                         monitor = 'val_acc', \n",
    "                                         verbose = 1, \n",
    "                                         save_best_only = True, \n",
    "                                         mode = 'max')\n",
    "\n",
    "            history = model.fit(X_train, \n",
    "                          y_train, \n",
    "                          epochs = ep, # edit for hyperparam tune\n",
    "                          batch_size = 32, # edit for hyperparam tune\n",
    "                          validation_data = [X_val,y_val], \n",
    "                          verbose = 1,\n",
    "                          callbacks = [checkpoint])\n",
    "\n",
    "       # Save the historical validation accuracies in df\n",
    "      accs[f'(rep:{rep}, lr:{lr}, reg:{r})'] = history.history['val_acc']\n",
    "            \n",
    "K.clear_session()   \n",
    "\n",
    "# dump output file \n",
    "#with open(\"accs.pickle\", 'wb') as f:\n",
    "#  pickle.dump(accs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open pickled files from ELMo_TFhub_accs.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T13:37:27.380640Z",
     "start_time": "2019-03-16T13:37:27.366691Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Averages \n",
    "a_pickle_in1 = open(\"avg_val_acc_6.pickle\",\"rb\")\n",
    "a_pickle_in2 = open(\"avg_val_acc_12.pickle\",\"rb\")\n",
    "a_pickle_in3 = open(\"avg_val_acc_25.pickle\",\"rb\")\n",
    "a_pickle_in4 = open(\"avg_val_acc_50.pickle\",\"rb\")\n",
    "a_pickle_in5 = open(\"avg_val_acc_100.pickle\",\"rb\")\n",
    "\n",
    "# Std devs\n",
    "s_pickle_in1 = open(\"stdv_acc_6.pickle\",\"rb\")\n",
    "s_pickle_in2 = open(\"stdv_acc_12.pickle\",\"rb\")\n",
    "s_pickle_in3 = open(\"stdv_acc_25.pickle\",\"rb\")\n",
    "s_pickle_in4 = open(\"stdv_acc_50.pickle\",\"rb\")\n",
    "s_pickle_in5 = open(\"stdv_acc_100.pickle\",\"rb\")\n",
    "\n",
    "# Averages\n",
    "\n",
    "acc1 = pickle.load(a_pickle_in1)\n",
    "acc2 = pickle.load(a_pickle_in2)\n",
    "acc3 = pickle.load(a_pickle_in3)\n",
    "acc4 = pickle.load(a_pickle_in4)\n",
    "acc5 = pickle.load(a_pickle_in5)\n",
    "\n",
    "# Std Devs\n",
    "\n",
    "std1 = pickle.load(s_pickle_in1)\n",
    "std2 = pickle.load(s_pickle_in2)\n",
    "std3 = pickle.load(s_pickle_in3)\n",
    "std4 = pickle.load(s_pickle_in4)\n",
    "std5 = pickle.load(s_pickle_in5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify best configuration for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T13:37:27.388619Z",
     "start_time": "2019-03-16T13:37:27.381637Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:0.001,reg:0.01       9\n",
      "lr:0.001,reg:0.001     20\n",
      "lr:0.0001,reg:0.01     30\n",
      "lr:0.0001,reg:0.001    31\n",
      "dtype: int64\n",
      "lr:0.001,reg:0.01      0.596050\n",
      "lr:0.001,reg:0.001     0.593489\n",
      "lr:0.0001,reg:0.01     0.594879\n",
      "lr:0.0001,reg:0.001    0.593489\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(acc1.idxmax())\n",
    "print(acc1.max())\n",
    "\n",
    "# Best model for 6% is with lr = 0.001, reg = 0.01 on epoch 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T13:37:27.399590Z",
     "start_time": "2019-03-16T13:37:27.389627Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:0.001,reg:0.01      26\n",
      "lr:0.001,reg:0.001     26\n",
      "lr:0.0001,reg:0.01     25\n",
      "lr:0.0001,reg:0.001    15\n",
      "dtype: int64\n",
      "lr:0.001,reg:0.01      0.606950\n",
      "lr:0.001,reg:0.001     0.605779\n",
      "lr:0.0001,reg:0.01     0.611339\n",
      "lr:0.0001,reg:0.001    0.610680\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(acc2.idxmax())\n",
    "print(acc2.max())\n",
    "\n",
    "# Best model for 12% is with lr = 0.0001, reg = 0.01, epoch 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T13:37:27.411584Z",
     "start_time": "2019-03-16T13:37:27.401584Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:0.001,reg:0.01      28\n",
      "lr:0.001,reg:0.001     12\n",
      "lr:0.0001,reg:0.01     24\n",
      "lr:0.0001,reg:0.001    28\n",
      "dtype: int64\n",
      "lr:0.001,reg:0.01      0.616533\n",
      "lr:0.001,reg:0.001     0.620629\n",
      "lr:0.0001,reg:0.01     0.626774\n",
      "lr:0.0001,reg:0.001    0.625969\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(acc3.idxmax())\n",
    "print(acc3.max())\n",
    "\n",
    "# Best model for 25% is with lr = 0.0001, reg = 0.01, epoch 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T13:37:27.424522Z",
     "start_time": "2019-03-16T13:37:27.412556Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:0.001,reg:0.01       5\n",
      "lr:0.001,reg:0.001      5\n",
      "lr:0.0001,reg:0.01     11\n",
      "lr:0.0001,reg:0.001    21\n",
      "dtype: int64\n",
      "lr:0.001,reg:0.01      0.638698\n",
      "lr:0.001,reg:0.001     0.638259\n",
      "lr:0.0001,reg:0.01     0.648866\n",
      "lr:0.0001,reg:0.001    0.651134\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(acc4.idxmax())\n",
    "print(acc4.max())\n",
    "\n",
    "# Best model for 50% is with lr = 0.0001, reg = 0.001, epoch 21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model architecture and load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T13:40:45.337521Z",
     "start_time": "2019-03-16T13:40:43.813127Z"
    },
    "code_folding": [
     0,
     16,
     28
    ]
   },
   "outputs": [],
   "source": [
    "def balanced_accuracy(out, labels):\n",
    "  \n",
    "  #'out' should be the logits\n",
    "  \n",
    "  paired_pred = []\n",
    "\n",
    "  for i in np.arange(0, len(out),2):\n",
    "    if out[i] > out[i+1]:\n",
    "      paired_pred.append(0)\n",
    "      paired_pred.append(1)\n",
    "    else:\n",
    "      paired_pred.append(1)\n",
    "      paired_pred.append(0)\n",
    "  \n",
    "  return np.sum(np.array(paired_pred) == labels)/len(out)\n",
    "\n",
    "def ElmoEmbedding(x):\n",
    "  \"\"\"Inputs: x - a string / sentence\n",
    "     Output: converts x to a tensor\n",
    "     \n",
    "     Choose [\"default\"] \n",
    "     \n",
    "  \"\"\"\n",
    "  return embed(tf.squeeze(tf.cast(x,tf.string)), signature = \"default\", as_dict = True)[\"default\"]\n",
    "\n",
    "url = \"https://tfhub.dev/google/elmo/2\"\n",
    "embed = hub.Module(url, trainable = True)\n",
    "\n",
    "def create_model(weights_file):\n",
    "  \n",
    "  # Obtain Elmo embeddings from tfhub\n",
    "  input_text = Input(shape = (1, ), dtype = \"string\")\n",
    "  embedding = Lambda(ElmoEmbedding, output_shape = (1024,) )(input_text)\n",
    "  \n",
    "  # Set initializer for weight and biases\n",
    "  initializer = keras.initializers.glorot_normal(seed = 0 )\n",
    "  \n",
    "  # Set optimizer\n",
    "  #opt = optimizers.adam(lr = 0.0001) \n",
    "  \n",
    "  # Create dense layer to do prediction after obtaining ELMO embeddings\n",
    "  dense = Dense(256, \n",
    "                activation = 'relu', \n",
    "                bias_initializer = initializer, \n",
    "                kernel_initializer = initializer)(embedding)\n",
    "  \n",
    "  # Regulariser\n",
    "  \n",
    "  #kernel_reg = keras.regularizers.l2(l = 0.01)(embedding)\n",
    "  \n",
    "  # Output layer\n",
    "  pred = Dense(2, activation = 'softmax')(dense)\n",
    "  \n",
    "  # Construct model\n",
    "  model = Model(inputs = [input_text], outputs = pred)\n",
    "  \n",
    "  # Load weights for model\n",
    "  wf = weights_file\n",
    "  model.load_weights(wf)\n",
    "  \n",
    "  return model\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unzip ELMo_TFhub_weights.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T13:40:53.839062Z",
     "start_time": "2019-03-16T13:40:47.112861Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0316 13:40:47.795001 15480 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0316 13:40:49.430770 15480 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0316 13:40:50.471816 15480 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0316 13:40:51.785653 15480 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0316 13:40:53.009681 15480 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "# Load best params\n",
    "\n",
    "Model6 = create_model(\"6weights-best_0.001_0.01.hdf5\")\n",
    "\n",
    "Model12 = create_model(\"12weights-best_0.0001_0.01.hdf5\")\n",
    "\n",
    "Model25 = create_model(\"25weights-best_0.0001_0.01.hdf5\")\n",
    "\n",
    "Model50 = create_model(\"50weights-best_0.0001_0.001.hdf5\")\n",
    "\n",
    "Model100 = create_model(\"100weights-best_0.0001_0.01.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T13:43:01.516202Z",
     "start_time": "2019-03-16T13:43:01.394027Z"
    }
   },
   "outputs": [],
   "source": [
    "# Locate test sets\n",
    "test_path = \"project_data\\\\balanced_test.csv\"\n",
    "u_test_path = \"project_data\\\\unbalanced_test.csv\"\n",
    "\n",
    "# Read csv's\n",
    "test = pd.read_csv(test_path)\n",
    "u_test = pd.read_csv(u_test_path)\n",
    "\n",
    "# Process test data\n",
    "\n",
    "X_test = np.asarray(test.loc[:,'response'])\n",
    "y_test = np.asarray(test.loc[:,'label'])\n",
    "\n",
    "y_test = to_categorical(y_test, num_classes=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T13:45:21.783581Z",
     "start_time": "2019-03-16T13:43:01.583419Z"
    },
    "code_folding": [
     5,
     8,
     11,
     14
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3406/3406 [==============================] - 29s 9ms/step\n",
      "3406/3406 [==============================] - 28s 8ms/step\n",
      "3406/3406 [==============================] - 28s 8ms/step\n",
      "3406/3406 [==============================] - 28s 8ms/step\n",
      "3406/3406 [==============================] - 28s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions \n",
    "\n",
    "preds6 = Model6.predict(x = X_test,\n",
    "              verbose = 1)\n",
    "\n",
    "preds12 = Model12.predict(x = X_test,\n",
    "              verbose = 1)\n",
    "\n",
    "preds25 = Model25.predict(x = X_test,\n",
    "              verbose = 1)\n",
    "\n",
    "preds50 = Model50.predict(x = X_test,\n",
    "              verbose = 1)\n",
    "\n",
    "preds100= Model100.predict(x = X_test,\n",
    "              verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T13:46:15.767780Z",
     "start_time": "2019-03-16T13:46:15.758800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Return accuracies\n",
    "\n",
    "accuracy_6 = metrics.accuracy_score(y_true = np.asarray(test.loc[:,'label']), \n",
    "                                  y_pred = np.asarray(np.round(preds6[:,1])))\n",
    "\n",
    "accuracy_12 = metrics.accuracy_score(y_true = np.asarray(test.loc[:,'label']), \n",
    "                                  y_pred = np.asarray(np.round(preds12[:,1])))\n",
    "\n",
    "accuracy_25 = metrics.accuracy_score(y_true = np.asarray(test.loc[:,'label']), \n",
    "                                  y_pred = np.asarray(np.round(preds25[:,1])))\n",
    "\n",
    "accuracy_50 = metrics.accuracy_score(y_true = np.asarray(test.loc[:,'label']), \n",
    "                                  y_pred = np.asarray(np.round(preds50[:,1])))\n",
    "\n",
    "accuracy_100 = metrics.accuracy_score(y_true = np.asarray(test.loc[:,'label']), \n",
    "                                  y_pred = np.asarray(np.round(preds100[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T13:49:15.607623Z",
     "start_time": "2019-03-16T13:49:15.561713Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy\n",
      "6% 60.217263652378165\n",
      "12% 60.011743981209634\n",
      "25% 63.27069876688197\n",
      "50% 64.32765707574868\n",
      "100% 66.88197298884322\n",
      "Balanced acc\n",
      "6% 0.6353493834409865\n",
      "12% 0.6341749853200235\n",
      "25% 0.6776277157956547\n",
      "50% 0.7028772753963594\n",
      "100% 0.7351732237228421\n",
      "F1 Scores\n",
      "6% 0.5599220526144852\n",
      "12% 0.5423387096774194\n",
      "25% 0.6219401631912965\n",
      "50% 0.6537475064120832\n",
      "100% 0.6361290322580645\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing accuracy\")\n",
    "print(\"6%\", accuracy_6*100, )\n",
    "print(\"12%\", accuracy_12*100)\n",
    "print(\"25%\", accuracy_25*100)\n",
    "print(\"50%\", accuracy_50*100)\n",
    "print(\"100%\", accuracy_100*100)\n",
    "\n",
    "a6 = accuracy_6*100\n",
    "a12 = accuracy_12*100\n",
    "a25 = accuracy_25*100\n",
    "a50 = accuracy_50*100\n",
    "a100 = accuracy_100*100\n",
    "\n",
    "print(\"Balanced acc\")\n",
    "print(\"6%\",1-balanced_accuracy(preds6[:,1], y_test[:,1]))\n",
    "print(\"12%\",1-balanced_accuracy(preds12[:,1], y_test[:,1]))\n",
    "print(\"25%\",1-balanced_accuracy(preds25[:,1], y_test[:,1]))\n",
    "print(\"50%\",1-balanced_accuracy(preds50[:,1], y_test[:,1]))\n",
    "print(\"100%\",1-balanced_accuracy(preds100[:,1], y_test[:,1]))\n",
    "\n",
    "b6 = (1-balanced_accuracy(preds6[:,1], y_test[:,1]))*100\n",
    "b12 = (1-balanced_accuracy(preds12[:,1], y_test[:,1]))*100\n",
    "b25 = (1-balanced_accuracy(preds25[:,1], y_test[:,1]))*100\n",
    "b50 = (1-balanced_accuracy(preds50[:,1], y_test[:,1]))*100\n",
    "b100 = (1-balanced_accuracy(preds100[:,1], y_test[:,1]))*100\n",
    "\n",
    "print(\"F1 Scores\")\n",
    "\n",
    "print(\"6%\", metrics.f1_score(y_true = np.asarray(test.loc[:,'label']), y_pred = np.asarray(np.round(preds6[:,1]))))\n",
    "print(\"12%\", metrics.f1_score(y_true = np.asarray(test.loc[:,'label']), y_pred = np.asarray(np.round(preds12[:,1]))))\n",
    "print(\"25%\", metrics.f1_score(y_true = np.asarray(test.loc[:,'label']), y_pred = np.asarray(np.round(preds25[:,1]))))\n",
    "print(\"50%\", metrics.f1_score(y_true = np.asarray(test.loc[:,'label']), y_pred = np.asarray(np.round(preds50[:,1]))))\n",
    "print(\"100%\", metrics.f1_score(y_true = np.asarray(test.loc[:,'label']), y_pred = np.asarray(np.round(preds100[:,1]))))\n",
    "\n",
    "f6 = metrics.f1_score(y_true = np.asarray(test.loc[:,'label']), y_pred = np.asarray(np.round(preds6[:,1])))\n",
    "f12 = metrics.f1_score(y_true = np.asarray(test.loc[:,'label']), y_pred = np.asarray(np.round(preds12[:,1])))\n",
    "f25 = metrics.f1_score(y_true = np.asarray(test.loc[:,'label']), y_pred = np.asarray(np.round(preds25[:,1])))\n",
    "f50 = metrics.f1_score(y_true = np.asarray(test.loc[:,'label']), y_pred = np.asarray(np.round(preds50[:,1])))\n",
    "f100 = metrics.f1_score(y_true = np.asarray(test.loc[:,'label']), y_pred = np.asarray(np.round(preds100[:,1])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T13:46:18.117244Z",
     "start_time": "2019-03-16T13:46:18.110268Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create dataframe with the summarised data and findings\n",
    "\n",
    "final_df = pd.DataFrame()\n",
    "\n",
    "final_df['Training size'] = [\"6%\",\"12%\",\"25%\",\"50%\",\"100%\"]\n",
    "final_df['Hyper-parameters-(LR,Reg)'] = [\"(0.001,0.01)\",\n",
    "                                       \"(0.0001,0.01)\",\n",
    "                                       \"(0.0001,0.01)\",\n",
    "                                       \"(0.0001,0.001)\",\n",
    "                                       \"(0.0001,0.01)\"]\n",
    "final_df['F1-Score'] = [f6,f12,f25,f50,f100]\n",
    "final_df['Test accuracy(%)'] = [a6,a12,a25,a50,a100]\n",
    "final_df['Balanced Test accuracy(%)'] = [b6,b12,b25,b50,b100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T13:46:49.593286Z",
     "start_time": "2019-03-16T13:46:49.566328Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training size</th>\n",
       "      <th>Hyper-parameters-(LR,Reg)</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Test accuracy(%)</th>\n",
       "      <th>Balanced Test accuracy(%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6%</td>\n",
       "      <td>(0.001,0.01)</td>\n",
       "      <td>0.559922</td>\n",
       "      <td>60.217264</td>\n",
       "      <td>63.534938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12%</td>\n",
       "      <td>(0.0001,0.01)</td>\n",
       "      <td>0.542339</td>\n",
       "      <td>60.011744</td>\n",
       "      <td>63.417499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25%</td>\n",
       "      <td>(0.0001,0.01)</td>\n",
       "      <td>0.621940</td>\n",
       "      <td>63.270699</td>\n",
       "      <td>67.762772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50%</td>\n",
       "      <td>(0.0001,0.001)</td>\n",
       "      <td>0.653748</td>\n",
       "      <td>64.327657</td>\n",
       "      <td>70.287728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100%</td>\n",
       "      <td>(0.0001,0.01)</td>\n",
       "      <td>0.636129</td>\n",
       "      <td>66.881973</td>\n",
       "      <td>73.517322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Training size Hyper-parameters-(LR,Reg)  F1-Score  Test accuracy(%)  \\\n",
       "0            6%              (0.001,0.01)  0.559922         60.217264   \n",
       "1           12%             (0.0001,0.01)  0.542339         60.011744   \n",
       "2           25%             (0.0001,0.01)  0.621940         63.270699   \n",
       "3           50%            (0.0001,0.001)  0.653748         64.327657   \n",
       "4          100%             (0.0001,0.01)  0.636129         66.881973   \n",
       "\n",
       "   Balanced Test accuracy(%)  \n",
       "0                  63.534938  \n",
       "1                  63.417499  \n",
       "2                  67.762772  \n",
       "3                  70.287728  \n",
       "4                  73.517322  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the table\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the dataframe\n",
    "\n",
    "final_df.to_csv('ELMO_Results.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
