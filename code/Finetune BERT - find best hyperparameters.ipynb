{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Finetune BERT - find best hyperparameters.ipynb","version":"0.3.2","provenance":[{"file_id":"1zjnnLFWeq4Ln7yGT8wL-yJHkk6fvk601","timestamp":1550943199879}],"collapsed_sections":["9JSPCPlhhP8b","kIotvvz9hmg0","oLuoNWS9jpDN","M0dqVa-wiIvw","YQmYjvjaiaOi","tSjMinL3kEoU","H1iZRlmolx2D","oSCY3DXCpeXD","cNhCs0JQfkuG"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"CF5L2PZhftCU","colab_type":"text"},"cell_type":"markdown","source":["# NLP assignment 3 - finetune BERT"]},{"metadata":{"id":"COLe8jfzMUnE","colab_type":"text"},"cell_type":"markdown","source":["We use to PyTorch implementation of BERT from: https://github.com/huggingface/pytorch-pretrained-BERT\n","\n","We have used this blog post (https://medium.com/huggingface/multi-label-text-classification-using-bert-the-mighty-transformer-69714fa3fb3d) and the supporting code (https://nbviewer.jupyter.org/github/kaushaltrivedi/bert-toxic-comments-multilabel/blob/master/toxic-bert-multilabel-classification.ipynb) as a model for implementing our classifier. We refer to this below as Trivedi 2019. "]},{"metadata":{"id":"9JSPCPlhhP8b","colab_type":"text"},"cell_type":"markdown","source":["## Imports - will need to authorise Google Drive"]},{"metadata":{"id":"2vrYXENJfmwl","colab_type":"code","outputId":"7b0e0ba1-ffc6-4d15-aa2a-7b4c08c15b0d","executionInfo":{"status":"ok","timestamp":1551824097539,"user_tz":0,"elapsed":9046,"user":{"displayName":"Joe Farrington","photoUrl":"https://lh5.googleusercontent.com/-bNEtdlkbGn8/AAAAAAAAAAI/AAAAAAAAAF4/7VpSGeR6wrY/s64/photo.jpg","userId":"09132137217736073231"}},"colab":{"base_uri":"https://localhost:8080/","height":489}},"cell_type":"code","source":["!pip install pytorch-pretrained-bert"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting pytorch-pretrained-bert\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/3c/d5fa084dd3a82ffc645aba78c417e6072ff48552e3301b1fa3bd711e03d4/pytorch_pretrained_bert-0.6.1-py3-none-any.whl (114kB)\n","\u001b[K    100% |████████████████████████████████| 122kB 7.7MB/s \n","\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2018.1.10)\n","Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.0.1.post2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.14.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.18.4)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.9.106)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.28.1)\n","Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.22)\n","Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2018.11.29)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.9.4)\n","Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.2.0)\n","Requirement already satisfied: botocore<1.13.0,>=1.12.106 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (1.12.106)\n","Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.106->boto3->pytorch-pretrained-bert) (0.14)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.106->boto3->pytorch-pretrained-bert) (2.5.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"->botocore<1.13.0,>=1.12.106->boto3->pytorch-pretrained-bert) (1.11.0)\n","Installing collected packages: pytorch-pretrained-bert\n","Successfully installed pytorch-pretrained-bert-0.6.1\n"],"name":"stdout"}]},{"metadata":{"id":"MG3RAjIZhT1w","colab_type":"code","colab":{}},"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","import pickle"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KUg_POWFhTzY","colab_type":"code","outputId":"12cf4c64-2cea-455f-8c4b-0498eb8dbcae","executionInfo":{"status":"ok","timestamp":1551824112190,"user_tz":0,"elapsed":4834,"user":{"displayName":"Joe Farrington","photoUrl":"https://lh5.googleusercontent.com/-bNEtdlkbGn8/AAAAAAAAAAI/AAAAAAAAAF4/7VpSGeR6wrY/s64/photo.jpg","userId":"09132137217736073231"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["from pytorch_pretrained_bert.tokenization import BertTokenizer, WordpieceTokenizer\n","from pytorch_pretrained_bert.modeling import BertForPreTraining, BertModel, BertConfig, BertForMaskedLM, BertForSequenceClassification #PretrainedBertModel\n","from pathlib import Path\n","import torch\n","import re\n","from torch import Tensor\n","from torch.nn import BCEWithLogitsLoss\n","from fastai.text import Tokenizer, Vocab\n","import collections\n","import os\n","import pdb\n","from tqdm import tqdm, trange\n","import sys\n","import random\n","from sklearn.model_selection import train_test_split\n","module_path = os.path.abspath(os.path.join('..'))\n","if module_path not in sys.path:\n","    sys.path.append(module_path)\n","\n","\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from torch.utils.data.distributed import DistributedSampler\n","from pytorch_pretrained_bert.optimization import BertAdam"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"],"name":"stdout"}]},{"metadata":{"id":"8fPxVghshTxB","colab_type":"code","colab":{}},"cell_type":"code","source":["import logging\n","logging.basicConfig(format='%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n","                    datefmt='%m/%d/%Y %H:%M:%S',\n","                    level=logging.INFO)\n","logger = logging.getLogger(__name__)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"QrUUrn1dhTuz","colab_type":"code","outputId":"c256a613-58c4-4ee3-b878-bd6e3204db62","executionInfo":{"status":"ok","timestamp":1551824149339,"user_tz":0,"elapsed":28473,"user":{"displayName":"Joe Farrington","photoUrl":"https://lh5.googleusercontent.com/-bNEtdlkbGn8/AAAAAAAAAAI/AAAAAAAAAF4/7VpSGeR6wrY/s64/photo.jpg","userId":"09132137217736073231"}},"colab":{"base_uri":"https://localhost:8080/","height":209}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"metadata":{"id":"HDcBU-9-M2w7","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"kIotvvz9hmg0","colab_type":"text"},"cell_type":"markdown","source":["## Define classes"]},{"metadata":{"id":"VQNj1zCET7KU","colab_type":"text"},"cell_type":"markdown","source":["These are all from the PyTorch BERT Github - copied in for reference when we were setting up the features."]},{"metadata":{"id":"P4CsPT76hlgy","colab_type":"code","colab":{}},"cell_type":"code","source":["class InputExample(object):\n","    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n","\n","    def __init__(self, guid, text_a, text_b=None, label=None):\n","        \"\"\"Constructs a InputExample.\n","        Args:\n","            guid: Unique id for the example.\n","            text_a: string. The untokenized text of the first sequence. For single\n","            sequence tasks, only this sequence must be specified.\n","            text_b: (Optional) string. The untokenized text of the second sequence.\n","            Only must be specified for sequence pair tasks.\n","            label: (Optional) string. The label of the example. This should be\n","            specified for train and dev examples, but not for test examples.\n","        \"\"\"\n","        self.guid = guid\n","        self.text_a = text_a\n","        self.text_b = text_b\n","        self.label = label"],"execution_count":0,"outputs":[]},{"metadata":{"id":"IU3MZbKChqxj","colab_type":"code","colab":{}},"cell_type":"code","source":["class InputFeatures(object):\n","    \"\"\"A single set of features of data.\"\"\"\n","\n","    def __init__(self, input_ids, input_mask, segment_ids, label_ids):\n","        self.input_ids = input_ids\n","        self.input_mask = input_mask\n","        self.segment_ids = segment_ids\n","        self.label_ids = label_ids"],"execution_count":0,"outputs":[]},{"metadata":{"id":"n-jx3tOhhqva","colab_type":"code","colab":{}},"cell_type":"code","source":["def convert_examples_to_features(examples, label_list, max_seq_length, tokenizer):\n","    \"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"\n","\n","    label_map = {label : i for i, label in enumerate(label_list)}\n","\n","    features = []\n","    for (ex_index, example) in enumerate(examples):\n","        tokens_a = tokenizer.tokenize(example.text_a)\n","\n","        tokens_b = None\n","        if example.text_b:\n","            tokens_b = tokenizer.tokenize(example.text_b)\n","            # Modifies `tokens_a` and `tokens_b` in place so that the total\n","            # length is less than the specified length.\n","            # Account for [CLS], [SEP], [SEP] with \"- 3\"\n","            _truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)\n","        else:\n","            # Account for [CLS] and [SEP] with \"- 2\"\n","            if len(tokens_a) > max_seq_length - 2:\n","                tokens_a = tokens_a[:(max_seq_length - 2)]\n","\n","        # The convention in BERT is:\n","        # (a) For sequence pairs:\n","        #  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\n","        #  type_ids: 0   0  0    0    0     0       0 0    1  1  1  1   1 1\n","        # (b) For single sequences:\n","        #  tokens:   [CLS] the dog is hairy . [SEP]\n","        #  type_ids: 0   0   0   0  0     0 0\n","        #\n","        # Where \"type_ids\" are used to indicate whether this is the first\n","        # sequence or the second sequence. The embedding vectors for `type=0` and\n","        # `type=1` were learned during pre-training and are added to the wordpiece\n","        # embedding vector (and position vector). This is not *strictly* necessary\n","        # since the [SEP] token unambigiously separates the sequences, but it makes\n","        # it easier for the model to learn the concept of sequences.\n","        #\n","        # For classification tasks, the first vector (corresponding to [CLS]) is\n","        # used as as the \"sentence vector\". Note that this only makes sense because\n","        # the entire model is fine-tuned.\n","        tokens = [\"[CLS]\"] + tokens_a + [\"[SEP]\"]\n","        segment_ids = [0] * len(tokens)\n","\n","        if tokens_b:\n","            tokens += tokens_b + [\"[SEP]\"]\n","            segment_ids += [1] * (len(tokens_b) + 1)\n","\n","        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n","\n","        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n","        # tokens are attended to.\n","        input_mask = [1] * len(input_ids)\n","\n","        # Zero-pad up to the sequence length.\n","        padding = [0] * (max_seq_length - len(input_ids))\n","        input_ids += padding\n","        input_mask += padding\n","        segment_ids += padding\n","\n","        assert len(input_ids) == max_seq_length\n","        assert len(input_mask) == max_seq_length\n","        assert len(segment_ids) == max_seq_length\n","\n","        label_ids = label_map[example.label]\n","        if ex_index < 5:\n","            logger.info(\"*** Example ***\")\n","            logger.info(\"guid: %s\" % (example.guid))\n","            logger.info(\"tokens: %s\" % \" \".join(\n","                    [str(x) for x in tokens]))\n","            logger.info(\"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))\n","            logger.info(\"input_mask: %s\" % \" \".join([str(x) for x in input_mask]))\n","            logger.info(\n","                    \"segment_ids: %s\" % \" \".join([str(x) for x in segment_ids]))\n","            logger.info(\"label: %s (id = %d)\" % (example.label, label_ids))\n","\n","        features.append(\n","                InputFeatures(input_ids=input_ids,\n","                              input_mask=input_mask,\n","                              segment_ids=segment_ids,\n","                              label_ids=label_ids))\n","    return features"],"execution_count":0,"outputs":[]},{"metadata":{"id":"oLuoNWS9jpDN","colab_type":"text"},"cell_type":"markdown","source":["## Training functions"]},{"metadata":{"id":"-DwIGQm9UJhC","colab_type":"text"},"cell_type":"markdown","source":["These functions are based on those from Trivedi 2019."]},{"metadata":{"id":"d3xOUO9Pj8Wh","colab_type":"code","colab":{}},"cell_type":"code","source":["def warmup_linear(x, warmup=0.002):\n","    if x < warmup:\n","        return x/warmup\n","    return 1.0 - x"],"execution_count":0,"outputs":[]},{"metadata":{"id":"1fnrlf3DjoiX","colab_type":"code","colab":{}},"cell_type":"code","source":["def fit(model, train_dataloader, device, optimizer, num_epochs):\n","    \n","    resultsdf = pd.DataFrame(columns = ['epoch', 'train loss', 'train accuracy', 'validation loss', 'validation accuracy'])\n","    batch_losses = []\n","    \n","    global_step = 0\n","    model.train()\n","    for i_ in (range(int(num_epochs))):\n","\n","        tr_loss = 0\n","        nb_tr_examples, nb_tr_steps = 0, 0\n","        for step, batch in enumerate(train_dataloader):\n","\n","            batch = tuple(t.to(device) for t in batch)\n","            input_ids, input_mask, segment_ids, label_ids = batch\n","            loss = model(input_ids, segment_ids, input_mask, label_ids)\n","            \n","            batch_losses.append(loss.item())\n","            \n","            if step % 50 ==0:\n","              logger.info(f\"Loss on batch {step}: {loss}\")\n","                      \n","            if args['fp16']:\n","              optimizer.backward(loss)\n","            else:\n","              loss.backward()\n","\n","            tr_loss += loss.item()\n","            nb_tr_examples += input_ids.size(0)\n","            nb_tr_steps += 1\n","\n","            if (step + 1) % args['gradient_accumulation_steps'] == 0:\n","              if args['fp16']:\n","                # modify learning rate with special warm up BERT uses\n","                # if args.fp16 is False, BertAdam is used that handles this automatically\n","                lr_this_step = args['learning_rate'] * warmup_linear(global_step/num_train_optimization_steps, args['warmup_proportion'])\n","                for param_group in optimizer.param_groups:\n","                  param_group['lr'] = lr_this_step\n","              optimizer.step()\n","              optimizer.zero_grad()\n","              global_step += 1\n","            \n","        logger.info('Training loss after epoch {}'.format(tr_loss / nb_tr_steps))\n","        train_tup = eval(train_examples, train_features, model=model, device=device)\n","        logger.info('Training accuracy after epoch {}'.format(train_tup[0]['accuracy']))\n","        logger.info(\"***** Running evaluation *****\")\n","        logger.info('Eval after epoch {}'.format(i_+1))\n","        eval_tup = eval(eval_examples, eval_features, model = model, device = device)\n","        logger.info(eval_tup[0])\n","        \n","        resultsdf = resultsdf.append({\"epoch\": i_+1, \"train loss\": train_tup[0]['loss'], \"train accuracy\": train_tup[0]['accuracy'],\n","                         \"validation loss\": eval_tup[0]['loss'], \"validation accuracy\": eval_tup[0]['accuracy']}, ignore_index=True)\n","    \n","    return resultsdf, batch_losses"],"execution_count":0,"outputs":[]},{"metadata":{"id":"M0dqVa-wiIvw","colab_type":"text"},"cell_type":"markdown","source":["## Evaluation functions"]},{"metadata":{"id":"T5vVFw2AVBGY","colab_type":"text"},"cell_type":"markdown","source":["The functions accuracy() and eval() are based on those from Trevedi 2019."]},{"metadata":{"id":"qvAztVqvhqte","colab_type":"code","colab":{}},"cell_type":"code","source":["def accuracy(out, labels):\n","    outputs = np.argmax(out, axis=1)\n","    return np.sum(outputs == labels)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"6nXRbONRiNae","colab_type":"text"},"cell_type":"markdown","source":["Use this function to caluclate the accuracy on the balanced task"]},{"metadata":{"id":"PPnkNhbuhqrK","colab_type":"code","colab":{}},"cell_type":"code","source":["def balanced_accuracy(out, labels):\n","  \n","  #'out' should be the logits put into a softmax\n","  paired_pred = []\n","  \n","  for i in np.arange(0, len(out),2):\n","    if out[i][1] < out[i+1][1]:\n","      paired_pred.append(0)\n","      paired_pred.append(1)\n","    else:\n","      paired_pred.append(1)\n","      paired_pred.append(0)\n","  \n","  return np.sum(np.array(paired_pred) == labels)/len(out)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"EJXrdfzDi0TF","colab_type":"code","colab":{}},"cell_type":"code","source":["def eval(eval_examples, eval_features, model, device):\n","        \n","    args['output_dir'].mkdir(exist_ok=True)\n","\n","    all_input_ids = torch.tensor([f.input_ids for f in eval_features], dtype=torch.long)\n","    all_input_mask = torch.tensor([f.input_mask for f in eval_features], dtype=torch.long)\n","    all_segment_ids = torch.tensor([f.segment_ids for f in eval_features], dtype=torch.long)\n","    all_label_ids = torch.tensor([f.label_ids for f in eval_features], dtype=torch.long)\n","    eval_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n","    # Run prediction for full data\n","    eval_sampler = SequentialSampler(eval_data)\n","    eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=args['eval_batch_size'])\n","    \n","    all_logits = None\n","    all_labels = None\n","    \n","    model.eval()\n","    eval_loss, eval_accuracy = 0, 0\n","    nb_eval_steps, nb_eval_examples = 0, 0\n","    for input_ids, input_mask, segment_ids, label_ids in eval_dataloader:\n","        input_ids = input_ids.to(device)\n","        input_mask = input_mask.to(device)\n","        segment_ids = segment_ids.to(device)\n","        label_ids = label_ids.to(device)\n","\n","        with torch.no_grad():\n","            tmp_eval_loss = model(input_ids, segment_ids, input_mask, label_ids)\n","            logits = model(input_ids, segment_ids, input_mask)\n","\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = label_ids.to('cpu').numpy()\n","        tmp_eval_accuracy = accuracy(logits, label_ids)\n","        \n","        if all_logits is None:\n","            all_logits = logits\n","        else:\n","            all_logits = np.concatenate((all_logits, logits), axis=0)\n","            \n","        if all_labels is None:\n","            all_labels = label_ids\n","        else:    \n","            all_labels = np.concatenate((all_labels, label_ids), axis=0)\n","\n","        eval_loss += tmp_eval_loss.mean().item()\n","        eval_accuracy += tmp_eval_accuracy\n","\n","        nb_eval_examples += input_ids.size(0)\n","        nb_eval_steps += 1\n","\n","    eval_loss = eval_loss / nb_eval_steps\n","    eval_accuracy = eval_accuracy / nb_eval_examples\n","    \n","    result = {'loss': eval_loss,\n","              'accuracy': eval_accuracy}\n","    \n","    return (result, all_logits, all_labels)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"YQmYjvjaiaOi","colab_type":"text"},"cell_type":"markdown","source":["## Set an output path and the default value of the arguments"]},{"metadata":{"id":"uGBJMlnDhqo4","colab_type":"code","colab":{}},"cell_type":"code","source":["OUTPUT_PATH = Path('gdrive/My Drive/tmp/output')\n","OUTPUT_PATH.mkdir(parents=True, exist_ok = True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dQP4w0nqVJiD","colab_type":"text"},"cell_type":"markdown","source":["The default arguments are based on those from Trivedi (2019)"]},{"metadata":{"id":"zTmr3r4Mhqmo","colab_type":"code","colab":{}},"cell_type":"code","source":["args = {\n","    \"train_size\": -1,\n","    \"val_size\": -1,\n","    \"task_name\": \"sarcpol\",\n","    \"no_cuda\": False,\n","    \"bert_model\": 'bert-base-uncased',\n","    \"output_dir\": OUTPUT_PATH,\n","    \"max_seq_length\": 50,\n","    \"do_train\": True,\n","    \"do_eval\": True,\n","    \"do_lower_case\": True,\n","    \"train_batch_size\": 32 ,\n","    \"eval_batch_size\": 32,\n","    \"learning_rate\": 3e-5,\n","    \"num_train_epochs\": 5,\n","    \"warmup_proportion\": 0.1,\n","    \"no_cuda\": False,\n","    \"local_rank\": -1,\n","    \"seed\": 42,\n","    \"gradient_accumulation_steps\": 1,\n","    \"optimize_on_cpu\": False,\n","    \"fp16\": False,\n","    \"loss_scale\": 128\n","}"],"execution_count":0,"outputs":[]},{"metadata":{"id":"tSjMinL3kEoU","colab_type":"text"},"cell_type":"markdown","source":["## Load in the training and validation sets"]},{"metadata":{"id":"TD4kY-K7hqkM","colab_type":"code","colab":{}},"cell_type":"code","source":["#Select the path contained the datasets\n","SARC_POL = '/content/gdrive/My Drive/SARC pol/'"],"execution_count":0,"outputs":[]},{"metadata":{"id":"AzbKi19HkdvW","colab_type":"code","colab":{}},"cell_type":"code","source":["#Load in the required training set\n","traindf = pd.read_csv(SARC_POL+'project_data/project_training_12.csv', index_col=0)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"nUUR7mTvkdrt","colab_type":"code","colab":{}},"cell_type":"code","source":["#Load in the validation set\n","validdf = pd.read_csv(SARC_POL+'project_data/project_validation.csv', index_col = 0)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"H1iZRlmolx2D","colab_type":"text"},"cell_type":"markdown","source":["## Process the training and validation sets\n","\n","\n"]},{"metadata":{"id":"s9fQp0_zlgcc","colab_type":"code","colab":{}},"cell_type":"code","source":["#Process the training examples\n","train_examples = []\n","\n","for i in range(0,len(traindf.index)):\n","        train_examples.append(InputExample(str(i), traindf.loc[i,'response'], None, str(traindf.loc[i,'label'])))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"L_kXjtBhmALo","colab_type":"code","colab":{}},"cell_type":"code","source":["#Process the validation examples\n","eval_examples = []\n","\n","for i in range(0,len(validdf.index)):\n","        eval_examples.append(InputExample(str(i), validdf.loc[i,'response'], None, str(validdf.loc[i,'label'])))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"afZIsxn5mGEZ","colab_type":"code","colab":{}},"cell_type":"code","source":["#Create a list of labels\n","label_list = ['0', '1']\n","num_labels = len(label_list)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"PGIigmlSmJX9","colab_type":"code","outputId":"feac9f80-9bfb-43d5-c830-574733042be0","executionInfo":{"status":"ok","timestamp":1551824431386,"user_tz":0,"elapsed":1861,"user":{"displayName":"Joe Farrington","photoUrl":"https://lh5.googleusercontent.com/-bNEtdlkbGn8/AAAAAAAAAAI/AAAAAAAAAF4/7VpSGeR6wrY/s64/photo.jpg","userId":"09132137217736073231"}},"colab":{"base_uri":"https://localhost:8080/","height":159}},"cell_type":"code","source":["#Instantiate the tokenizer\n","tokenizer = BertTokenizer.from_pretrained(args['bert_model'], do_lower_case=args['do_lower_case'])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["03/05/2019 22:20:30 - INFO - pytorch_pretrained_bert.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache, downloading to /tmp/tmpwxnp1pce\n","100%|██████████| 231508/231508 [00:00<00:00, 918957.81B/s]\n","03/05/2019 22:20:30 - INFO - pytorch_pretrained_bert.file_utils -   copying /tmp/tmpwxnp1pce to cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","03/05/2019 22:20:30 - INFO - pytorch_pretrained_bert.file_utils -   creating metadata file for /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","03/05/2019 22:20:30 - INFO - pytorch_pretrained_bert.file_utils -   removing temp file /tmp/tmpwxnp1pce\n","03/05/2019 22:20:30 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"],"name":"stderr"}]},{"metadata":{"id":"wnU3CIBTmNJe","colab_type":"code","outputId":"02167c3b-1524-42da-d5d1-196fe8a2c99a","executionInfo":{"status":"ok","timestamp":1551824435977,"user_tz":0,"elapsed":1502,"user":{"displayName":"Joe Farrington","photoUrl":"https://lh5.googleusercontent.com/-bNEtdlkbGn8/AAAAAAAAAAI/AAAAAAAAAF4/7VpSGeR6wrY/s64/photo.jpg","userId":"09132137217736073231"}},"colab":{"base_uri":"https://localhost:8080/","height":692}},"cell_type":"code","source":["#Create the features based on the training set\n","train_features = convert_examples_to_features(train_examples, label_list, args[\"max_seq_length\"], tokenizer)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["03/05/2019 22:20:34 - INFO - __main__ -   *** Example ***\n","03/05/2019 22:20:34 - INFO - __main__ -   guid: 0\n","03/05/2019 22:20:34 - INFO - __main__ -   tokens: [CLS] or anyone that ' s ever had to make an appeal . [SEP]\n","03/05/2019 22:20:34 - INFO - __main__ -   input_ids: 101 2030 3087 2008 1005 1055 2412 2018 2000 2191 2019 5574 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/05/2019 22:20:34 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/05/2019 22:20:34 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/05/2019 22:20:34 - INFO - __main__ -   label: 0 (id = 0)\n","03/05/2019 22:20:34 - INFO - __main__ -   *** Example ***\n","03/05/2019 22:20:34 - INFO - __main__ -   guid: 1\n","03/05/2019 22:20:34 - INFO - __main__ -   tokens: [CLS] trump is the health ##iest president to ever take office , so he doesn ' t have to worry about that . [SEP]\n","03/05/2019 22:20:34 - INFO - __main__ -   input_ids: 101 8398 2003 1996 2740 10458 2343 2000 2412 2202 2436 1010 2061 2002 2987 1005 1056 2031 2000 4737 2055 2008 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/05/2019 22:20:34 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/05/2019 22:20:34 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/05/2019 22:20:34 - INFO - __main__ -   label: 1 (id = 1)\n","03/05/2019 22:20:34 - INFO - __main__ -   *** Example ***\n","03/05/2019 22:20:34 - INFO - __main__ -   guid: 2\n","03/05/2019 22:20:34 - INFO - __main__ -   tokens: [CLS] i love sanders and everything he believes in but i think his policy ' s won ' t make it into or out of congress . [SEP]\n","03/05/2019 22:20:34 - INFO - __main__ -   input_ids: 101 1045 2293 12055 1998 2673 2002 7164 1999 2021 1045 2228 2010 3343 1005 1055 2180 1005 1056 2191 2009 2046 2030 2041 1997 3519 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/05/2019 22:20:34 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/05/2019 22:20:34 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/05/2019 22:20:34 - INFO - __main__ -   label: 0 (id = 0)\n","03/05/2019 22:20:34 - INFO - __main__ -   *** Example ***\n","03/05/2019 22:20:34 - INFO - __main__ -   guid: 3\n","03/05/2019 22:20:34 - INFO - __main__ -   tokens: [CLS] then don ' t forget to phone ##bank canvas ##sing dona ##ting your rent money for this month to him and we can make him president but we don ' t vote so it didn ' t matter lo ##l . [SEP]\n","03/05/2019 22:20:34 - INFO - __main__ -   input_ids: 101 2059 2123 1005 1056 5293 2000 3042 9299 10683 7741 24260 3436 2115 9278 2769 2005 2023 3204 2000 2032 1998 2057 2064 2191 2032 2343 2021 2057 2123 1005 1056 3789 2061 2009 2134 1005 1056 3043 8840 2140 1012 102 0 0 0 0 0 0 0\n","03/05/2019 22:20:34 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0\n","03/05/2019 22:20:34 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/05/2019 22:20:34 - INFO - __main__ -   label: 1 (id = 1)\n","03/05/2019 22:20:34 - INFO - __main__ -   *** Example ***\n","03/05/2019 22:20:34 - INFO - __main__ -   guid: 4\n","03/05/2019 22:20:34 - INFO - __main__ -   tokens: [CLS] totally not a perfect example of the racism inherent in the trump movement that makes ethnic minorities think that other candidates are a better path for america [SEP]\n","03/05/2019 22:20:34 - INFO - __main__ -   input_ids: 101 6135 2025 1037 3819 2742 1997 1996 14398 16112 1999 1996 8398 2929 2008 3084 5636 14302 2228 2008 2060 5347 2024 1037 2488 4130 2005 2637 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/05/2019 22:20:34 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/05/2019 22:20:34 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/05/2019 22:20:34 - INFO - __main__ -   label: 1 (id = 1)\n"],"name":"stderr"}]},{"metadata":{"id":"jQI47fFBmNHJ","colab_type":"code","outputId":"da233cdf-7776-41c0-d6a5-117ef38a33dd","executionInfo":{"status":"ok","timestamp":1551824439972,"user_tz":0,"elapsed":2667,"user":{"displayName":"Joe Farrington","photoUrl":"https://lh5.googleusercontent.com/-bNEtdlkbGn8/AAAAAAAAAAI/AAAAAAAAAF4/7VpSGeR6wrY/s64/photo.jpg","userId":"09132137217736073231"}},"colab":{"base_uri":"https://localhost:8080/","height":692}},"cell_type":"code","source":["#Create the features based on the validation set\n","eval_features = convert_examples_to_features(eval_examples, label_list, args[\"max_seq_length\"], tokenizer)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["03/05/2019 22:20:38 - INFO - __main__ -   *** Example ***\n","03/05/2019 22:20:38 - INFO - __main__ -   guid: 0\n","03/05/2019 22:20:38 - INFO - __main__ -   tokens: [CLS] and if trump builds that wall they will be stuck here . [SEP]\n","03/05/2019 22:20:38 - INFO - __main__ -   input_ids: 101 1998 2065 8398 16473 2008 2813 2027 2097 2022 5881 2182 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/05/2019 22:20:38 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/05/2019 22:20:38 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/05/2019 22:20:38 - INFO - __main__ -   label: 1 (id = 1)\n","03/05/2019 22:20:38 - INFO - __main__ -   *** Example ***\n","03/05/2019 22:20:38 - INFO - __main__ -   guid: 1\n","03/05/2019 22:20:38 - INFO - __main__ -   tokens: [CLS] says a voluntary survey . [SEP]\n","03/05/2019 22:20:38 - INFO - __main__ -   input_ids: 101 2758 1037 10758 5002 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/05/2019 22:20:38 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/05/2019 22:20:38 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/05/2019 22:20:38 - INFO - __main__ -   label: 0 (id = 0)\n","03/05/2019 22:20:38 - INFO - __main__ -   *** Example ***\n","03/05/2019 22:20:38 - INFO - __main__ -   guid: 2\n","03/05/2019 22:20:38 - INFO - __main__ -   tokens: [CLS] i demand an apology to all those poor nazis ! [SEP]\n","03/05/2019 22:20:38 - INFO - __main__ -   input_ids: 101 1045 5157 2019 12480 2000 2035 2216 3532 13157 999 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/05/2019 22:20:38 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/05/2019 22:20:38 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/05/2019 22:20:38 - INFO - __main__ -   label: 1 (id = 1)\n","03/05/2019 22:20:38 - INFO - __main__ -   *** Example ***\n","03/05/2019 22:20:38 - INFO - __main__ -   guid: 3\n","03/05/2019 22:20:38 - INFO - __main__ -   tokens: [CLS] why didn ##t hitler think of invalid ##ating nuremberg ? [SEP]\n","03/05/2019 22:20:38 - INFO - __main__ -   input_ids: 101 2339 2134 2102 8042 2228 1997 19528 5844 19346 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/05/2019 22:20:38 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/05/2019 22:20:38 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/05/2019 22:20:38 - INFO - __main__ -   label: 0 (id = 0)\n","03/05/2019 22:20:38 - INFO - __main__ -   *** Example ***\n","03/05/2019 22:20:38 - INFO - __main__ -   guid: 4\n","03/05/2019 22:20:38 - INFO - __main__ -   tokens: [CLS] the amount of ne ##gat ##ivity here is massive . [SEP]\n","03/05/2019 22:20:38 - INFO - __main__ -   input_ids: 101 1996 3815 1997 11265 20697 7730 2182 2003 5294 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/05/2019 22:20:38 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/05/2019 22:20:38 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/05/2019 22:20:38 - INFO - __main__ -   label: 0 (id = 0)\n"],"name":"stderr"}]},{"metadata":{"id":"oSCY3DXCpeXD","colab_type":"text"},"cell_type":"markdown","source":["## Define function to train the model"]},{"metadata":{"id":"XWHJf60DVXon","colab_type":"text"},"cell_type":"markdown","source":["This function is based on the training function from Trivedi (2019)"]},{"metadata":{"id":"i4keKOqwOEvb","colab_type":"code","colab":{}},"cell_type":"code","source":["def train():\n","\n","#Set up PyTorch options\n","\n","  num_train_optimization_steps = None\n","  if args[\"do_train\"]:\n","      num_train_optimization_steps = int(\n","          len(train_examples) / args['train_batch_size'] / args['gradient_accumulation_steps']) * args['num_train_epochs']\n","      if args[\"local_rank\"] != -1:\n","          num_train_optimization_steps = num_train_optimization_steps // torch.distributed.get_world_size()\n","  num_train_steps = int(\n","          len(train_examples) / args['train_batch_size'] / args['gradient_accumulation_steps'] * args['num_train_epochs'])\n","\n","  if args[\"local_rank\"] == -1 or args[\"no_cuda\"]:\n","      device = torch.device(\"cuda\" if torch.cuda.is_available() and not args[\"no_cuda\"] else \"cpu\")\n","      n_gpu = torch.cuda.device_count()\n","  #     n_gpu = 1\n","  else:\n","      torch.cuda.set_device(args['local_rank'])\n","      device = torch.device(\"cuda\", args['local_rank'])\n","      n_gpu = 1\n","      # Initializes the distributed backend which will take care of sychronizing nodes/GPUs\n","      torch.distributed.init_process_group(backend='nccl')\n","  logger.info(\"device: {} n_gpu: {}, distributed training: {}, 16-bits training: {}\".format(\n","          device, n_gpu, bool(args['local_rank'] != -1), args['fp16']))\n","\n","  #Instantiate the model\n","\n","  model = BertForSequenceClassification.from_pretrained(args[\"bert_model\"],\n","            num_labels = num_labels)\n","  if args[\"fp16\"]:\n","      model.half()\n","  model.to(device)\n","  if args[\"local_rank\"] != -1:\n","      try:\n","          from apex.parallel import DistributedDataParallel as DDP\n","      except ImportError:\n","          raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use distributed and fp16 training.\")\n","\n","      model = DDP(model)\n","  elif n_gpu > 1:\n","      model = torch.nn.DataParallel(model)\n","\n","\n","  #Instantiate the optimizer\n","  param_optimizer = list(model.named_parameters())\n","  no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","  optimizer_grouped_parameters = [\n","      {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n","      {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n","      ]\n","  if args[\"fp16\"]:\n","      try:\n","          from apex.optimizers import FP16_Optimizer\n","          from apex.optimizers import FusedAdam\n","      except ImportError:\n","          raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use distributed and fp16 training.\")\n","\n","      optimizer = FusedAdam(optimizer_grouped_parameters,\n","                            lr=args[\"learning_rate\"],\n","                            bias_correction=False,\n","                            max_grad_norm=1.0)\n","      if args[\"loss_scale\"]== 0:\n","          optimizer = FP16_Optimizer(optimizer, dynamic_loss_scale=True)\n","      else:\n","          optimizer = FP16_Optimizer(optimizer, static_loss_scale=args[\"loss_scale\"])\n","\n","  else:\n","      optimizer = BertAdam(optimizer_grouped_parameters,\n","                           lr=args[\"learning_rate\"],\n","                           warmup=args[\"warmup_proportion\"],\n","                           t_total=num_train_optimization_steps)\n","\n","\n","  #Instantiate the PyTorch datasets and print key details\n","  logger.info(\"  Num examples = %d\", len(train_examples))\n","  logger.info(\"  Batch size = %d\", args['train_batch_size'])\n","  logger.info(\"  Num steps = %d\", num_train_steps)\n","  all_input_ids = torch.tensor([f.input_ids for f in train_features], dtype=torch.long)\n","  all_input_mask = torch.tensor([f.input_mask for f in train_features], dtype=torch.long)\n","  all_segment_ids = torch.tensor([f.segment_ids for f in train_features], dtype=torch.long)\n","  all_label_ids = torch.tensor([f.label_ids for f in train_features], dtype=torch.long)\n","  train_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n","  if args['local_rank'] == -1:\n","      train_sampler = RandomSampler(train_data)\n","  else:\n","      train_sampler = DistributedSampler(train_data)\n","  train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=args['train_batch_size'])\n","\n","  resultsdf, batch_losses = fit(model = model, train_dataloader = train_dataloader, device = device, optimizer = optimizer, num_epochs = args[\"num_train_epochs\"])\n","  \n","  return resultsdf, batch_losses"],"execution_count":0,"outputs":[]},{"metadata":{"id":"cNhCs0JQfkuG","colab_type":"text"},"cell_type":"markdown","source":["## Set hyperparameters for cross-validation and run training"]},{"metadata":{"id":"vSlDTs8tOEob","colab_type":"code","colab":{}},"cell_type":"code","source":["learning_rates = [5e-5, 3e-5, 2e-5]\n","batch_sizes = [16, 32]\n","nrepeats = 5\n","args[\"num_train_epochs\"] = 10"],"execution_count":0,"outputs":[]},{"metadata":{"id":"DaaF34dKfpHV","colab_type":"code","outputId":"6aa61230-05ab-4176-849a-6582aed5f4c7","executionInfo":{"status":"ok","timestamp":1551850317434,"user_tz":0,"elapsed":25854533,"user":{"displayName":"Joe Farrington","photoUrl":"https://lh5.googleusercontent.com/-bNEtdlkbGn8/AAAAAAAAAAI/AAAAAAAAAF4/7VpSGeR6wrY/s64/photo.jpg","userId":"09132137217736073231"}},"colab":{"base_uri":"https://localhost:8080/","height":44492}},"cell_type":"code","source":["#Not explicitly setting seed, each run because each lopp will generate a different random number from the seed set in args\n","for lr in learning_rates:\n","  args[\"learning_rate\"] = lr\n","  \n","  for bs in batch_sizes:\n","    args[\"train_batch_size\"] = bs\n","    \n","    for n in range(0, nrepeats):\n","      resultsdf, batch_losses = train()\n","      \n","      #May need to update save location here\n","      with open(SARC_POL+f\"CVruns/results_train12_{lr}_{bs}_{n}_10epochs.pickle\", 'wb') as handle:\n","        pickle.dump(resultsdf, handle)\n","        \n","      with open(SARC_POL+f\"CVruns/batchlosses_train12_{lr}_{bs}_{n}_10epochs.pickle\", 'wb') as handle:\n","        pickle.dump(batch_losses, handle)\n","      \n","      \n","  "],"execution_count":0,"outputs":[{"output_type":"stream","text":["03/05/2019 22:21:03 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n","03/05/2019 22:21:03 - INFO - pytorch_pretrained_bert.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz not found in cache, downloading to /tmp/tmp3pzjqb3u\n","100%|██████████| 407873900/407873900 [00:14<00:00, 28678243.49B/s]\n","03/05/2019 22:21:18 - INFO - pytorch_pretrained_bert.file_utils -   copying /tmp/tmp3pzjqb3u to cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n","03/05/2019 22:21:19 - INFO - pytorch_pretrained_bert.file_utils -   creating metadata file for /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n","03/05/2019 22:21:19 - INFO - pytorch_pretrained_bert.file_utils -   removing temp file /tmp/tmp3pzjqb3u\n","03/05/2019 22:21:19 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n","03/05/2019 22:21:19 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpgd06rwgz\n","03/05/2019 22:21:24 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"max_position_embeddings\": 512,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","03/05/2019 22:21:29 - INFO - pytorch_pretrained_bert.modeling -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","03/05/2019 22:21:29 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","03/05/2019 22:21:44 - INFO - __main__ -     Num examples = 1366\n","03/05/2019 22:21:44 - INFO - __main__ -     Batch size = 16\n","03/05/2019 22:21:44 - INFO - __main__ -     Num steps = 853\n","03/05/2019 22:21:44 - INFO - __main__ -   Loss on batch 0: 0.670548677444458\n","03/05/2019 22:22:06 - INFO - __main__ -   Loss on batch 50: 0.6276699900627136\n","03/05/2019 22:22:22 - INFO - __main__ -   Training loss after epoch 0.6960134811179582\n","03/05/2019 22:22:39 - INFO - __main__ -   Training accuracy after epoch 0.712298682284041\n","03/05/2019 22:22:39 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 22:22:39 - INFO - __main__ -   Eval after epoch 1\n","03/05/2019 22:23:14 - INFO - __main__ -   {'loss': 0.6497185278770535, 'accuracy': 0.6316752011704463}\n","03/05/2019 22:23:14 - INFO - __main__ -   Loss on batch 0: 0.5640341639518738\n","03/05/2019 22:23:36 - INFO - __main__ -   Loss on batch 50: 0.663409411907196\n","03/05/2019 22:23:51 - INFO - __main__ -   Training loss after epoch 0.5622867487890776\n","03/05/2019 22:24:08 - INFO - __main__ -   Training accuracy after epoch 0.9253294289897511\n","03/05/2019 22:24:08 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 22:24:08 - INFO - __main__ -   Eval after epoch 2\n","03/05/2019 22:24:43 - INFO - __main__ -   {'loss': 0.6475645265606946, 'accuracy': 0.6302121433796635}\n","03/05/2019 22:24:43 - INFO - __main__ -   Loss on batch 0: 0.29292017221450806\n","03/05/2019 22:25:05 - INFO - __main__ -   Loss on batch 50: 0.3454710841178894\n","03/05/2019 22:25:21 - INFO - __main__ -   Training loss after epoch 0.2182692580011695\n","03/05/2019 22:25:38 - INFO - __main__ -   Training accuracy after epoch 0.9751098096632503\n","03/05/2019 22:25:38 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 22:25:38 - INFO - __main__ -   Eval after epoch 3\n","03/05/2019 22:26:13 - INFO - __main__ -   {'loss': 1.0017115411370299, 'accuracy': 0.6382589612289685}\n","03/05/2019 22:26:13 - INFO - __main__ -   Loss on batch 0: 0.025253016501665115\n","03/05/2019 22:26:35 - INFO - __main__ -   Loss on batch 50: 0.18757939338684082\n","03/05/2019 22:26:51 - INFO - __main__ -   Training loss after epoch 0.0756798478731409\n","03/05/2019 22:27:08 - INFO - __main__ -   Training accuracy after epoch 0.9934114202049781\n","03/05/2019 22:27:08 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 22:27:08 - INFO - __main__ -   Eval after epoch 4\n","03/05/2019 22:27:43 - INFO - __main__ -   {'loss': 1.5023284214873647, 'accuracy': 0.6528895391367959}\n","03/05/2019 22:27:43 - INFO - __main__ -   Loss on batch 0: 0.0043268948793411255\n","03/05/2019 22:28:05 - INFO - __main__ -   Loss on batch 50: 0.0009171962738037109\n","03/05/2019 22:28:21 - INFO - __main__ -   Training loss after epoch 0.016644398573526117\n","03/05/2019 22:28:38 - INFO - __main__ -   Training accuracy after epoch 0.9985358711566618\n","03/05/2019 22:28:38 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 22:28:38 - INFO - __main__ -   Eval after epoch 5\n","03/05/2019 22:29:13 - INFO - __main__ -   {'loss': 1.701762660991314, 'accuracy': 0.6514264813460132}\n","03/05/2019 22:29:13 - INFO - __main__ -   Loss on batch 0: 0.0016023069620132446\n","03/05/2019 22:29:35 - INFO - __main__ -   Loss on batch 50: 0.0007660537958145142\n","03/05/2019 22:29:50 - INFO - __main__ -   Training loss after epoch 0.007400027454592461\n","03/05/2019 22:30:08 - INFO - __main__ -   Training accuracy after epoch 0.9985358711566618\n","03/05/2019 22:30:08 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 22:30:08 - INFO - __main__ -   Eval after epoch 6\n","03/05/2019 22:30:42 - INFO - __main__ -   {'loss': 1.7278227341729542, 'accuracy': 0.6554498902706657}\n","03/05/2019 22:30:42 - INFO - __main__ -   Loss on batch 0: 0.0009401887655258179\n","03/05/2019 22:31:05 - INFO - __main__ -   Loss on batch 50: 0.001026153564453125\n","03/05/2019 22:31:20 - INFO - __main__ -   Training loss after epoch 0.00660293570213388\n","03/05/2019 22:31:38 - INFO - __main__ -   Training accuracy after epoch 0.9985358711566618\n","03/05/2019 22:31:38 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 22:31:38 - INFO - __main__ -   Eval after epoch 7\n","03/05/2019 22:32:12 - INFO - __main__ -   {'loss': 1.7588665325974309, 'accuracy': 0.6521580102414045}\n","03/05/2019 22:32:12 - INFO - __main__ -   Loss on batch 0: 0.0012734830379486084\n","03/05/2019 22:32:35 - INFO - __main__ -   Loss on batch 50: 0.02021780237555504\n","03/05/2019 22:32:50 - INFO - __main__ -   Training loss after epoch 0.006099353385696642\n","03/05/2019 22:33:07 - INFO - __main__ -   Training accuracy after epoch 0.9985358711566618\n","03/05/2019 22:33:07 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 22:33:07 - INFO - __main__ -   Eval after epoch 8\n","03/05/2019 22:33:42 - INFO - __main__ -   {'loss': 1.775764224141143, 'accuracy': 0.6514264813460132}\n","03/05/2019 22:33:42 - INFO - __main__ -   Loss on batch 0: 0.0006192773580551147\n","03/05/2019 22:34:04 - INFO - __main__ -   Loss on batch 50: 0.0005974173545837402\n","03/05/2019 22:34:20 - INFO - __main__ -   Training loss after epoch 0.005527357895706975\n","03/05/2019 22:34:37 - INFO - __main__ -   Training accuracy after epoch 0.9985358711566618\n","03/05/2019 22:34:37 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 22:34:37 - INFO - __main__ -   Eval after epoch 9\n","03/05/2019 22:35:11 - INFO - __main__ -   {'loss': 1.7871918193129606, 'accuracy': 0.6525237746891002}\n","03/05/2019 22:35:11 - INFO - __main__ -   Loss on batch 0: 0.0006569325923919678\n","03/05/2019 22:35:33 - INFO - __main__ -   Loss on batch 50: 0.0007674545049667358\n","03/05/2019 22:35:49 - INFO - __main__ -   Training loss after epoch 0.004891911398708756\n","03/05/2019 22:36:06 - INFO - __main__ -   Training accuracy after epoch 0.9985358711566618\n","03/05/2019 22:36:06 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 22:36:06 - INFO - __main__ -   Eval after epoch 10\n","03/05/2019 22:36:41 - INFO - __main__ -   {'loss': 1.8013106127117955, 'accuracy': 0.6521580102414045}\n","03/05/2019 22:36:41 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n","03/05/2019 22:36:41 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n","03/05/2019 22:36:41 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpcrsr7xou\n","03/05/2019 22:36:46 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"max_position_embeddings\": 512,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","03/05/2019 22:36:50 - INFO - pytorch_pretrained_bert.modeling -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","03/05/2019 22:36:50 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","03/05/2019 22:36:50 - INFO - __main__ -     Num examples = 1366\n","03/05/2019 22:36:50 - INFO - __main__ -     Batch size = 16\n","03/05/2019 22:36:50 - INFO - __main__ -     Num steps = 853\n","03/05/2019 22:36:50 - INFO - __main__ -   Loss on batch 0: 0.7003803253173828\n","03/05/2019 22:37:13 - INFO - __main__ -   Loss on batch 50: 0.6551284193992615\n","03/05/2019 22:37:29 - INFO - __main__ -   Training loss after epoch 0.6943840322106384\n","03/05/2019 22:37:46 - INFO - __main__ -   Training accuracy after epoch 0.5622254758418741\n","03/05/2019 22:37:46 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 22:37:46 - INFO - __main__ -   Eval after epoch 1\n","03/05/2019 22:38:20 - INFO - __main__ -   {'loss': 0.6798364166603532, 'accuracy': 0.570592538405267}\n","03/05/2019 22:38:20 - INFO - __main__ -   Loss on batch 0: 0.7977942824363708\n","03/05/2019 22:38:42 - INFO - __main__ -   Loss on batch 50: 0.5335789918899536\n","03/05/2019 22:38:58 - INFO - __main__ -   Training loss after epoch 0.6015159234751103\n","03/05/2019 22:39:15 - INFO - __main__ -   Training accuracy after epoch 0.8338213762811127\n","03/05/2019 22:39:15 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 22:39:15 - INFO - __main__ -   Eval after epoch 2\n","03/05/2019 22:39:49 - INFO - __main__ -   {'loss': 0.6357231382713762, 'accuracy': 0.6554498902706657}\n","03/05/2019 22:39:50 - INFO - __main__ -   Loss on batch 0: 0.39244669675827026\n","03/05/2019 22:40:12 - INFO - __main__ -   Loss on batch 50: 0.46656620502471924\n","03/05/2019 22:40:27 - INFO - __main__ -   Training loss after epoch 0.3370191046404977\n","03/05/2019 22:40:45 - INFO - __main__ -   Training accuracy after epoch 0.9802342606149341\n","03/05/2019 22:40:45 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 22:40:45 - INFO - __main__ -   Eval after epoch 3\n","03/05/2019 22:41:19 - INFO - __main__ -   {'loss': 0.7191245417262233, 'accuracy': 0.6671543525969276}\n","03/05/2019 22:41:19 - INFO - __main__ -   Loss on batch 0: 0.26831308007240295\n","03/05/2019 22:41:41 - INFO - __main__ -   Loss on batch 50: 0.010244213044643402\n","03/05/2019 22:41:57 - INFO - __main__ -   Training loss after epoch 0.07139031199175258\n","03/05/2019 22:42:14 - INFO - __main__ -   Training accuracy after epoch 0.9934114202049781\n","03/05/2019 22:42:14 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 22:42:14 - INFO - __main__ -   Eval after epoch 4\n","03/05/2019 22:42:48 - INFO - __main__ -   {'loss': 1.2699056953884835, 'accuracy': 0.6536210680321872}\n","03/05/2019 22:42:48 - INFO - __main__ -   Loss on batch 0: 0.015713520348072052\n","03/05/2019 22:43:11 - INFO - __main__ -   Loss on batch 50: 0.0032598525285720825\n","03/05/2019 22:43:26 - INFO - __main__ -   Training loss after epoch 0.027752523786973123\n","03/05/2019 22:43:43 - INFO - __main__ -   Training accuracy after epoch 0.9985358711566618\n","03/05/2019 22:43:43 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 22:43:43 - INFO - __main__ -   Eval after epoch 5\n","03/05/2019 22:44:18 - INFO - __main__ -   {'loss': 1.51210123647091, 'accuracy': 0.6730065837600585}\n","03/05/2019 22:44:18 - INFO - __main__ -   Loss on batch 0: 0.0022774934768676758\n","03/05/2019 22:44:40 - INFO - __main__ -   Loss on batch 50: 0.0012157708406448364\n","03/05/2019 22:44:55 - INFO - __main__ -   Training loss after epoch 0.0035911083162551054\n","03/05/2019 22:45:13 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/05/2019 22:45:13 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 22:45:13 - INFO - __main__ -   Eval after epoch 6\n","03/05/2019 22:45:47 - INFO - __main__ -   {'loss': 1.7942305241906367, 'accuracy': 0.6726408193123629}\n","03/05/2019 22:45:47 - INFO - __main__ -   Loss on batch 0: 0.00047409534454345703\n","03/05/2019 22:46:09 - INFO - __main__ -   Loss on batch 50: 0.0005405247211456299\n","03/05/2019 22:46:25 - INFO - __main__ -   Training loss after epoch 0.001701866759821166\n","03/05/2019 22:46:42 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/05/2019 22:46:42 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 22:46:42 - INFO - __main__ -   Eval after epoch 7\n","03/05/2019 22:47:17 - INFO - __main__ -   {'loss': 1.862566590309143, 'accuracy': 0.6737381126554499}\n","03/05/2019 22:47:17 - INFO - __main__ -   Loss on batch 0: 0.00027008354663848877\n","03/05/2019 22:47:39 - INFO - __main__ -   Loss on batch 50: 0.0002559870481491089\n","03/05/2019 22:47:55 - INFO - __main__ -   Training loss after epoch 0.0016052886379373714\n","03/05/2019 22:48:12 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/05/2019 22:48:12 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 22:48:12 - INFO - __main__ -   Eval after epoch 8\n","03/05/2019 22:48:47 - INFO - __main__ -   {'loss': 1.9056575478509414, 'accuracy': 0.6744696415508412}\n","03/05/2019 22:48:47 - INFO - __main__ -   Loss on batch 0: 0.0002722889184951782\n","03/05/2019 22:49:09 - INFO - __main__ -   Loss on batch 50: 0.0003834962844848633\n","03/05/2019 22:49:24 - INFO - __main__ -   Training loss after epoch 0.0014428651147470593\n","03/05/2019 22:49:41 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/05/2019 22:49:41 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 22:49:41 - INFO - __main__ -   Eval after epoch 9\n","03/05/2019 22:50:16 - INFO - __main__ -   {'loss': 1.9292910667352898, 'accuracy': 0.6737381126554499}\n","03/05/2019 22:50:16 - INFO - __main__ -   Loss on batch 0: 0.00024081766605377197\n","03/05/2019 22:50:38 - INFO - __main__ -   Loss on batch 50: 0.000244826078414917\n","03/05/2019 22:50:54 - INFO - __main__ -   Training loss after epoch 0.0013349040939004248\n","03/05/2019 22:51:11 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/05/2019 22:51:11 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 22:51:11 - INFO - __main__ -   Eval after epoch 10\n","03/05/2019 22:51:45 - INFO - __main__ -   {'loss': 1.9359402441701223, 'accuracy': 0.6733723482077542}\n","03/05/2019 22:51:45 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n","03/05/2019 22:51:46 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n","03/05/2019 22:51:46 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpypsss6ky\n","03/05/2019 22:51:50 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"max_position_embeddings\": 512,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","03/05/2019 22:51:55 - INFO - pytorch_pretrained_bert.modeling -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","03/05/2019 22:51:55 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","03/05/2019 22:51:55 - INFO - __main__ -     Num examples = 1366\n","03/05/2019 22:51:55 - INFO - __main__ -     Batch size = 16\n","03/05/2019 22:51:55 - INFO - __main__ -     Num steps = 853\n","03/05/2019 22:51:55 - INFO - __main__ -   Loss on batch 0: 0.7248131036758423\n","03/05/2019 22:52:18 - INFO - __main__ -   Loss on batch 50: 0.7423512935638428\n","03/05/2019 22:52:33 - INFO - __main__ -   Training loss after epoch 0.7045635996862899\n","03/05/2019 22:52:50 - INFO - __main__ -   Training accuracy after epoch 0.6024890190336749\n","03/05/2019 22:52:50 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 22:52:50 - INFO - __main__ -   Eval after epoch 1\n","03/05/2019 22:53:25 - INFO - __main__ -   {'loss': 0.6549682721149089, 'accuracy': 0.5618141916605706}\n","03/05/2019 22:53:25 - INFO - __main__ -   Loss on batch 0: 0.6431795358657837\n","03/05/2019 22:53:47 - INFO - __main__ -   Loss on batch 50: 0.684838593006134\n","03/05/2019 22:54:03 - INFO - __main__ -   Training loss after epoch 0.5917006758756416\n","03/05/2019 22:54:20 - INFO - __main__ -   Training accuracy after epoch 0.9363103953147877\n","03/05/2019 22:54:20 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 22:54:20 - INFO - __main__ -   Eval after epoch 2\n","03/05/2019 22:54:54 - INFO - __main__ -   {'loss': 0.6167181096104688, 'accuracy': 0.6642282370153622}\n","03/05/2019 22:54:54 - INFO - __main__ -   Loss on batch 0: 0.3321326673030853\n","03/05/2019 22:55:17 - INFO - __main__ -   Loss on batch 50: 0.21523626148700714\n","03/05/2019 22:55:32 - INFO - __main__ -   Training loss after epoch 0.26664415207626513\n","03/05/2019 22:55:50 - INFO - __main__ -   Training accuracy after epoch 0.9780380673499268\n","03/05/2019 22:55:50 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 22:55:50 - INFO - __main__ -   Eval after epoch 3\n","03/05/2019 22:56:24 - INFO - __main__ -   {'loss': 1.0698883692885555, 'accuracy': 0.6561814191660571}\n","03/05/2019 22:56:24 - INFO - __main__ -   Loss on batch 0: 0.021210825070738792\n","03/05/2019 22:56:46 - INFO - __main__ -   Loss on batch 50: 0.009524524211883545\n","03/05/2019 22:57:02 - INFO - __main__ -   Training loss after epoch 0.11128363095570443\n","03/05/2019 22:57:19 - INFO - __main__ -   Training accuracy after epoch 0.9956076134699854\n","03/05/2019 22:57:19 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 22:57:19 - INFO - __main__ -   Eval after epoch 4\n","03/05/2019 22:57:54 - INFO - __main__ -   {'loss': 1.0235160474860392, 'accuracy': 0.6700804681784931}\n","03/05/2019 22:57:54 - INFO - __main__ -   Loss on batch 0: 0.007665589451789856\n","03/05/2019 22:58:16 - INFO - __main__ -   Loss on batch 50: 0.006428278982639313\n","03/05/2019 22:58:32 - INFO - __main__ -   Training loss after epoch 0.02082038026703738\n","03/05/2019 22:58:49 - INFO - __main__ -   Training accuracy after epoch 0.9985358711566618\n","03/05/2019 22:58:49 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 22:58:49 - INFO - __main__ -   Eval after epoch 5\n","03/05/2019 22:59:23 - INFO - __main__ -   {'loss': 1.2958172830038293, 'accuracy': 0.6697147037307973}\n","03/05/2019 22:59:23 - INFO - __main__ -   Loss on batch 0: 0.0018225312232971191\n","03/05/2019 22:59:45 - INFO - __main__ -   Loss on batch 50: 0.002195097506046295\n","03/05/2019 23:00:01 - INFO - __main__ -   Training loss after epoch 0.004896856656265553\n","03/05/2019 23:00:18 - INFO - __main__ -   Training accuracy after epoch 0.9985358711566618\n","03/05/2019 23:00:18 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 23:00:18 - INFO - __main__ -   Eval after epoch 6\n","03/05/2019 23:00:53 - INFO - __main__ -   {'loss': 1.5052531562572302, 'accuracy': 0.662033650329188}\n","03/05/2019 23:00:53 - INFO - __main__ -   Loss on batch 0: 0.002105511724948883\n","03/05/2019 23:01:15 - INFO - __main__ -   Loss on batch 50: 0.000902324914932251\n","03/05/2019 23:01:31 - INFO - __main__ -   Training loss after epoch 0.004777424470629803\n","03/05/2019 23:01:48 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/05/2019 23:01:48 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 23:01:48 - INFO - __main__ -   Eval after epoch 7\n","03/05/2019 23:02:22 - INFO - __main__ -   {'loss': 1.520954406538675, 'accuracy': 0.65508412582297}\n","03/05/2019 23:02:23 - INFO - __main__ -   Loss on batch 0: 0.0013299956917762756\n","03/05/2019 23:02:45 - INFO - __main__ -   Loss on batch 50: 0.000813797116279602\n","03/05/2019 23:03:00 - INFO - __main__ -   Training loss after epoch 0.0026122299564439195\n","03/05/2019 23:03:17 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/05/2019 23:03:17 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 23:03:17 - INFO - __main__ -   Eval after epoch 8\n","03/05/2019 23:03:52 - INFO - __main__ -   {'loss': 1.5583952055420986, 'accuracy': 0.6616678858814923}\n","03/05/2019 23:03:52 - INFO - __main__ -   Loss on batch 0: 0.000722050666809082\n","03/05/2019 23:04:14 - INFO - __main__ -   Loss on batch 50: 0.0008336454629898071\n","03/05/2019 23:04:29 - INFO - __main__ -   Training loss after epoch 0.0021334724544092667\n","03/05/2019 23:04:47 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/05/2019 23:04:47 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 23:04:47 - INFO - __main__ -   Eval after epoch 9\n","03/05/2019 23:05:21 - INFO - __main__ -   {'loss': 1.581404743499534, 'accuracy': 0.6613021214337966}\n","03/05/2019 23:05:21 - INFO - __main__ -   Loss on batch 0: 0.0007217973470687866\n","03/05/2019 23:05:43 - INFO - __main__ -   Loss on batch 50: 0.0006459057331085205\n","03/05/2019 23:05:59 - INFO - __main__ -   Training loss after epoch 0.0017771539677660046\n","03/05/2019 23:06:16 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/05/2019 23:06:16 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 23:06:16 - INFO - __main__ -   Eval after epoch 10\n","03/05/2019 23:06:50 - INFO - __main__ -   {'loss': 1.5890996975954188, 'accuracy': 0.662033650329188}\n","03/05/2019 23:06:50 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n","03/05/2019 23:06:51 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n","03/05/2019 23:06:51 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpy56_hj5m\n","03/05/2019 23:06:55 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"max_position_embeddings\": 512,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","03/05/2019 23:07:00 - INFO - pytorch_pretrained_bert.modeling -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","03/05/2019 23:07:00 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","03/05/2019 23:07:00 - INFO - __main__ -     Num examples = 1366\n","03/05/2019 23:07:00 - INFO - __main__ -     Batch size = 16\n","03/05/2019 23:07:00 - INFO - __main__ -     Num steps = 853\n","03/05/2019 23:07:00 - INFO - __main__ -   Loss on batch 0: 0.6802799105644226\n","03/05/2019 23:07:23 - INFO - __main__ -   Loss on batch 50: 0.5990232825279236\n","03/05/2019 23:07:39 - INFO - __main__ -   Training loss after epoch 0.6772109637426775\n","03/05/2019 23:07:56 - INFO - __main__ -   Training accuracy after epoch 0.6991215226939971\n","03/05/2019 23:07:56 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 23:07:56 - INFO - __main__ -   Eval after epoch 1\n","03/05/2019 23:08:30 - INFO - __main__ -   {'loss': 0.6452165897502455, 'accuracy': 0.6163130943672275}\n","03/05/2019 23:08:30 - INFO - __main__ -   Loss on batch 0: 0.6167079210281372\n","03/05/2019 23:08:52 - INFO - __main__ -   Loss on batch 50: 0.6354057788848877\n","03/05/2019 23:09:08 - INFO - __main__ -   Training loss after epoch 0.5387195672753246\n","03/05/2019 23:09:25 - INFO - __main__ -   Training accuracy after epoch 0.9084919472913616\n","03/05/2019 23:09:25 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 23:09:25 - INFO - __main__ -   Eval after epoch 2\n","03/05/2019 23:10:00 - INFO - __main__ -   {'loss': 0.600598261106846, 'accuracy': 0.6752011704462326}\n","03/05/2019 23:10:00 - INFO - __main__ -   Loss on batch 0: 0.39007842540740967\n","03/05/2019 23:10:22 - INFO - __main__ -   Loss on batch 50: 0.6502530574798584\n","03/05/2019 23:10:38 - INFO - __main__ -   Training loss after epoch 0.24229198958464834\n","03/05/2019 23:10:55 - INFO - __main__ -   Training accuracy after epoch 0.9773060029282576\n","03/05/2019 23:10:55 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 23:10:55 - INFO - __main__ -   Eval after epoch 3\n","03/05/2019 23:11:29 - INFO - __main__ -   {'loss': 0.805418593592422, 'accuracy': 0.6675201170446232}\n","03/05/2019 23:11:29 - INFO - __main__ -   Loss on batch 0: 0.05002790316939354\n","03/05/2019 23:11:52 - INFO - __main__ -   Loss on batch 50: 0.0606248714029789\n","03/05/2019 23:12:07 - INFO - __main__ -   Training loss after epoch 0.09198913143861086\n","03/05/2019 23:12:24 - INFO - __main__ -   Training accuracy after epoch 0.9897510980966325\n","03/05/2019 23:12:24 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 23:12:24 - INFO - __main__ -   Eval after epoch 4\n","03/05/2019 23:12:59 - INFO - __main__ -   {'loss': 1.0186174976271252, 'accuracy': 0.6656912948061449}\n","03/05/2019 23:12:59 - INFO - __main__ -   Loss on batch 0: 0.0109030082821846\n","03/05/2019 23:13:21 - INFO - __main__ -   Loss on batch 50: 0.011807423084974289\n","03/05/2019 23:13:37 - INFO - __main__ -   Training loss after epoch 0.051230921496658824\n","03/05/2019 23:13:54 - INFO - __main__ -   Training accuracy after epoch 0.9934114202049781\n","03/05/2019 23:13:54 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 23:13:54 - INFO - __main__ -   Eval after epoch 5\n","03/05/2019 23:14:28 - INFO - __main__ -   {'loss': 1.4096397189206855, 'accuracy': 0.6448427212874909}\n","03/05/2019 23:14:28 - INFO - __main__ -   Loss on batch 0: 0.0038050413131713867\n","03/05/2019 23:14:51 - INFO - __main__ -   Loss on batch 50: 0.0033620446920394897\n","03/05/2019 23:15:06 - INFO - __main__ -   Training loss after epoch 0.025386977875821812\n","03/05/2019 23:15:23 - INFO - __main__ -   Training accuracy after epoch 0.9970717423133236\n","03/05/2019 23:15:23 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 23:15:23 - INFO - __main__ -   Eval after epoch 6\n","03/05/2019 23:15:58 - INFO - __main__ -   {'loss': 1.3352787834267283, 'accuracy': 0.6675201170446232}\n","03/05/2019 23:15:58 - INFO - __main__ -   Loss on batch 0: 0.0023905932903289795\n","03/05/2019 23:16:20 - INFO - __main__ -   Loss on batch 50: 0.0023536086082458496\n","03/05/2019 23:16:35 - INFO - __main__ -   Training loss after epoch 0.018954759536765863\n","03/05/2019 23:16:53 - INFO - __main__ -   Training accuracy after epoch 0.9970717423133236\n","03/05/2019 23:16:53 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 23:16:53 - INFO - __main__ -   Eval after epoch 7\n","03/05/2019 23:17:27 - INFO - __main__ -   {'loss': 1.3776229377402816, 'accuracy': 0.6730065837600585}\n","03/05/2019 23:17:27 - INFO - __main__ -   Loss on batch 0: 0.0022120922803878784\n","03/05/2019 23:17:49 - INFO - __main__ -   Loss on batch 50: 0.0026083439588546753\n","03/05/2019 23:18:05 - INFO - __main__ -   Training loss after epoch 0.01597068425495351\n","03/05/2019 23:18:22 - INFO - __main__ -   Training accuracy after epoch 0.9970717423133236\n","03/05/2019 23:18:22 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 23:18:22 - INFO - __main__ -   Eval after epoch 8\n","03/05/2019 23:18:57 - INFO - __main__ -   {'loss': 1.4131701214368952, 'accuracy': 0.6737381126554499}\n","03/05/2019 23:18:57 - INFO - __main__ -   Loss on batch 0: 0.0019028186798095703\n","03/05/2019 23:19:19 - INFO - __main__ -   Loss on batch 50: 0.0021023452281951904\n","03/05/2019 23:19:35 - INFO - __main__ -   Training loss after epoch 0.015678167632824286\n","03/05/2019 23:19:52 - INFO - __main__ -   Training accuracy after epoch 0.9970717423133236\n","03/05/2019 23:19:52 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 23:19:52 - INFO - __main__ -   Eval after epoch 9\n","03/05/2019 23:20:26 - INFO - __main__ -   {'loss': 1.4229015728761985, 'accuracy': 0.6708119970738844}\n","03/05/2019 23:20:27 - INFO - __main__ -   Loss on batch 0: 0.001659199595451355\n","03/05/2019 23:20:49 - INFO - __main__ -   Loss on batch 50: 0.001960650086402893\n","03/05/2019 23:21:04 - INFO - __main__ -   Training loss after epoch 0.01461368856875789\n","03/05/2019 23:21:21 - INFO - __main__ -   Training accuracy after epoch 0.9970717423133236\n","03/05/2019 23:21:21 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 23:21:21 - INFO - __main__ -   Eval after epoch 10\n","03/05/2019 23:21:56 - INFO - __main__ -   {'loss': 1.4234892947729243, 'accuracy': 0.6704462326261887}\n","03/05/2019 23:21:56 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n","03/05/2019 23:21:56 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n","03/05/2019 23:21:56 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpdj20w_xh\n","03/05/2019 23:22:01 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"max_position_embeddings\": 512,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","03/05/2019 23:22:05 - INFO - pytorch_pretrained_bert.modeling -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","03/05/2019 23:22:05 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","03/05/2019 23:22:05 - INFO - __main__ -     Num examples = 1366\n","03/05/2019 23:22:05 - INFO - __main__ -     Batch size = 16\n","03/05/2019 23:22:05 - INFO - __main__ -     Num steps = 853\n","03/05/2019 23:22:06 - INFO - __main__ -   Loss on batch 0: 0.8133158087730408\n","03/05/2019 23:22:28 - INFO - __main__ -   Loss on batch 50: 0.8080358505249023\n","03/05/2019 23:22:44 - INFO - __main__ -   Training loss after epoch 0.700973782775014\n","03/05/2019 23:23:01 - INFO - __main__ -   Training accuracy after epoch 0.7210834553440703\n","03/05/2019 23:23:01 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 23:23:01 - INFO - __main__ -   Eval after epoch 1\n","03/05/2019 23:23:35 - INFO - __main__ -   {'loss': 0.6317840731421183, 'accuracy': 0.6700804681784931}\n","03/05/2019 23:23:35 - INFO - __main__ -   Loss on batch 0: 0.6086558699607849\n","03/05/2019 23:23:57 - INFO - __main__ -   Loss on batch 50: 0.7542697191238403\n","03/05/2019 23:24:13 - INFO - __main__ -   Training loss after epoch 0.6407987076875775\n","03/05/2019 23:24:30 - INFO - __main__ -   Training accuracy after epoch 0.7174231332357247\n","03/05/2019 23:24:30 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 23:24:30 - INFO - __main__ -   Eval after epoch 2\n","03/05/2019 23:25:05 - INFO - __main__ -   {'loss': 0.6787497772033825, 'accuracy': 0.6320409656181419}\n","03/05/2019 23:25:05 - INFO - __main__ -   Loss on batch 0: 0.5260099172592163\n","03/05/2019 23:25:27 - INFO - __main__ -   Loss on batch 50: 0.4875846803188324\n","03/05/2019 23:25:43 - INFO - __main__ -   Training loss after epoch 0.4783191949475643\n","03/05/2019 23:26:00 - INFO - __main__ -   Training accuracy after epoch 0.9282576866764275\n","03/05/2019 23:26:00 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 23:26:00 - INFO - __main__ -   Eval after epoch 3\n","03/05/2019 23:26:34 - INFO - __main__ -   {'loss': 0.7898066705742548, 'accuracy': 0.6485003657644477}\n","03/05/2019 23:26:34 - INFO - __main__ -   Loss on batch 0: 0.18750643730163574\n","03/05/2019 23:26:56 - INFO - __main__ -   Loss on batch 50: 0.23371198773384094\n","03/05/2019 23:27:12 - INFO - __main__ -   Training loss after epoch 0.1906290544673454\n","03/05/2019 23:27:29 - INFO - __main__ -   Training accuracy after epoch 0.9809663250366032\n","03/05/2019 23:27:29 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 23:27:29 - INFO - __main__ -   Eval after epoch 4\n","03/05/2019 23:28:04 - INFO - __main__ -   {'loss': 0.8605954574291096, 'accuracy': 0.6744696415508412}\n","03/05/2019 23:28:04 - INFO - __main__ -   Loss on batch 0: 0.017928697168827057\n","03/05/2019 23:28:26 - INFO - __main__ -   Loss on batch 50: 0.017133615911006927\n","03/05/2019 23:28:42 - INFO - __main__ -   Training loss after epoch 0.058681079871454385\n","03/05/2019 23:28:59 - INFO - __main__ -   Training accuracy after epoch 0.9926793557833089\n","03/05/2019 23:28:59 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 23:28:59 - INFO - __main__ -   Eval after epoch 5\n","03/05/2019 23:29:33 - INFO - __main__ -   {'loss': 1.2429532096829525, 'accuracy': 0.6554498902706657}\n","03/05/2019 23:29:33 - INFO - __main__ -   Loss on batch 0: 0.011608675122261047\n","03/05/2019 23:29:55 - INFO - __main__ -   Loss on batch 50: 0.0030365288257598877\n","03/05/2019 23:30:11 - INFO - __main__ -   Training loss after epoch 0.030153456885844122\n","03/05/2019 23:30:28 - INFO - __main__ -   Training accuracy after epoch 0.9890190336749634\n","03/05/2019 23:30:28 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 23:30:28 - INFO - __main__ -   Eval after epoch 6\n","03/05/2019 23:31:03 - INFO - __main__ -   {'loss': 1.8187891757765482, 'accuracy': 0.6382589612289685}\n","03/05/2019 23:31:03 - INFO - __main__ -   Loss on batch 0: 0.0026377886533737183\n","03/05/2019 23:31:25 - INFO - __main__ -   Loss on batch 50: 0.005832791328430176\n","03/05/2019 23:31:41 - INFO - __main__ -   Training loss after epoch 0.024940826637713714\n","03/05/2019 23:31:58 - INFO - __main__ -   Training accuracy after epoch 0.9956076134699854\n","03/05/2019 23:31:58 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 23:31:58 - INFO - __main__ -   Eval after epoch 7\n","03/05/2019 23:32:33 - INFO - __main__ -   {'loss': 1.4086541838424151, 'accuracy': 0.6580102414045355}\n","03/05/2019 23:32:33 - INFO - __main__ -   Loss on batch 0: 0.0014622360467910767\n","03/05/2019 23:32:55 - INFO - __main__ -   Loss on batch 50: 0.14519141614437103\n","03/05/2019 23:33:11 - INFO - __main__ -   Training loss after epoch 0.016294821851811005\n","03/05/2019 23:33:28 - INFO - __main__ -   Training accuracy after epoch 0.9963396778916545\n","03/05/2019 23:33:28 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 23:33:28 - INFO - __main__ -   Eval after epoch 8\n","03/05/2019 23:34:02 - INFO - __main__ -   {'loss': 1.4356595700563386, 'accuracy': 0.6660570592538405}\n","03/05/2019 23:34:03 - INFO - __main__ -   Loss on batch 0: 0.001963317394256592\n","03/05/2019 23:34:25 - INFO - __main__ -   Loss on batch 50: 0.0015338510274887085\n","03/05/2019 23:34:40 - INFO - __main__ -   Training loss after epoch 0.0063961105310184835\n","03/05/2019 23:34:58 - INFO - __main__ -   Training accuracy after epoch 0.9985358711566618\n","03/05/2019 23:34:58 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 23:34:58 - INFO - __main__ -   Eval after epoch 9\n","03/05/2019 23:35:32 - INFO - __main__ -   {'loss': 1.46848647469698, 'accuracy': 0.6682516459400146}\n","03/05/2019 23:35:32 - INFO - __main__ -   Loss on batch 0: 0.001356169581413269\n","03/05/2019 23:35:54 - INFO - __main__ -   Loss on batch 50: 0.0007197409868240356\n","03/05/2019 23:36:10 - INFO - __main__ -   Training loss after epoch 0.004121667178900002\n","03/05/2019 23:36:27 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/05/2019 23:36:27 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 23:36:27 - INFO - __main__ -   Eval after epoch 10\n","03/05/2019 23:37:01 - INFO - __main__ -   {'loss': 1.4776104896567588, 'accuracy': 0.6686174103877103}\n","03/05/2019 23:37:01 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n","03/05/2019 23:37:02 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n","03/05/2019 23:37:02 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpk11me8cw\n","03/05/2019 23:37:06 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"max_position_embeddings\": 512,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","03/05/2019 23:37:11 - INFO - pytorch_pretrained_bert.modeling -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","03/05/2019 23:37:11 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","03/05/2019 23:37:11 - INFO - __main__ -     Num examples = 1366\n","03/05/2019 23:37:11 - INFO - __main__ -     Batch size = 32\n","03/05/2019 23:37:11 - INFO - __main__ -     Num steps = 426\n","03/05/2019 23:37:11 - INFO - __main__ -   Loss on batch 0: 0.7901525497436523\n","03/05/2019 23:37:40 - INFO - __main__ -   Training loss after epoch 0.7105646327484486\n","03/05/2019 23:37:58 - INFO - __main__ -   Training accuracy after epoch 0.7159590043923866\n","03/05/2019 23:37:58 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 23:37:58 - INFO - __main__ -   Eval after epoch 1\n","03/05/2019 23:38:32 - INFO - __main__ -   {'loss': 0.6242510794207107, 'accuracy': 0.6682516459400146}\n","03/05/2019 23:38:32 - INFO - __main__ -   Loss on batch 0: 0.53377765417099\n","03/05/2019 23:39:01 - INFO - __main__ -   Training loss after epoch 0.5933630910030631\n","03/05/2019 23:39:18 - INFO - __main__ -   Training accuracy after epoch 0.8997071742313324\n","03/05/2019 23:39:18 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 23:39:18 - INFO - __main__ -   Eval after epoch 2\n","03/05/2019 23:39:53 - INFO - __main__ -   {'loss': 0.6202825470719227, 'accuracy': 0.6700804681784931}\n","03/05/2019 23:39:53 - INFO - __main__ -   Loss on batch 0: 0.3573681712150574\n","03/05/2019 23:40:22 - INFO - __main__ -   Training loss after epoch 0.30759996193092926\n","03/05/2019 23:40:39 - INFO - __main__ -   Training accuracy after epoch 0.9685212298682284\n","03/05/2019 23:40:39 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 23:40:39 - INFO - __main__ -   Eval after epoch 3\n","03/05/2019 23:41:13 - INFO - __main__ -   {'loss': 0.7336366013732067, 'accuracy': 0.6532553035844916}\n","03/05/2019 23:41:13 - INFO - __main__ -   Loss on batch 0: 0.06419601291418076\n","03/05/2019 23:41:42 - INFO - __main__ -   Training loss after epoch 0.09181661169629457\n","03/05/2019 23:41:59 - INFO - __main__ -   Training accuracy after epoch 0.9897510980966325\n","03/05/2019 23:41:59 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 23:41:59 - INFO - __main__ -   Eval after epoch 4\n","03/05/2019 23:42:34 - INFO - __main__ -   {'loss': 1.1570743842180384, 'accuracy': 0.65508412582297}\n","03/05/2019 23:42:34 - INFO - __main__ -   Loss on batch 0: 0.03435930609703064\n","03/05/2019 23:43:03 - INFO - __main__ -   Training loss after epoch 0.04526575059131827\n","03/05/2019 23:43:20 - INFO - __main__ -   Training accuracy after epoch 0.9934114202049781\n","03/05/2019 23:43:20 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 23:43:20 - INFO - __main__ -   Eval after epoch 5\n","03/05/2019 23:43:54 - INFO - __main__ -   {'loss': 1.4576270081276117, 'accuracy': 0.6433796634967082}\n","03/05/2019 23:43:54 - INFO - __main__ -   Loss on batch 0: 0.007866360247135162\n","03/05/2019 23:44:23 - INFO - __main__ -   Training loss after epoch 0.0267070890404284\n","03/05/2019 23:44:40 - INFO - __main__ -   Training accuracy after epoch 0.9985358711566618\n","03/05/2019 23:44:40 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 23:44:40 - INFO - __main__ -   Eval after epoch 6\n","03/05/2019 23:45:15 - INFO - __main__ -   {'loss': 1.516823369403218, 'accuracy': 0.6660570592538405}\n","03/05/2019 23:45:15 - INFO - __main__ -   Loss on batch 0: 0.002923484891653061\n","03/05/2019 23:45:44 - INFO - __main__ -   Training loss after epoch 0.008205272384572687\n","03/05/2019 23:46:01 - INFO - __main__ -   Training accuracy after epoch 0.9985358711566618\n","03/05/2019 23:46:01 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 23:46:01 - INFO - __main__ -   Eval after epoch 7\n","03/05/2019 23:46:35 - INFO - __main__ -   {'loss': 1.5706987048304357, 'accuracy': 0.6675201170446232}\n","03/05/2019 23:46:35 - INFO - __main__ -   Loss on batch 0: 0.001214679330587387\n","03/05/2019 23:47:04 - INFO - __main__ -   Training loss after epoch 0.007117268661860117\n","03/05/2019 23:47:21 - INFO - __main__ -   Training accuracy after epoch 0.9985358711566618\n","03/05/2019 23:47:21 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 23:47:21 - INFO - __main__ -   Eval after epoch 8\n","03/05/2019 23:47:55 - INFO - __main__ -   {'loss': 1.6100886270057324, 'accuracy': 0.6649597659107535}\n","03/05/2019 23:47:56 - INFO - __main__ -   Loss on batch 0: 0.01549106277525425\n","03/05/2019 23:48:24 - INFO - __main__ -   Training loss after epoch 0.006880660863528245\n","03/05/2019 23:48:42 - INFO - __main__ -   Training accuracy after epoch 0.9985358711566618\n","03/05/2019 23:48:42 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 23:48:42 - INFO - __main__ -   Eval after epoch 9\n","03/05/2019 23:49:16 - INFO - __main__ -   {'loss': 1.6050563523935717, 'accuracy': 0.6623994147768837}\n","03/05/2019 23:49:16 - INFO - __main__ -   Loss on batch 0: 0.0013336986303329468\n","03/05/2019 23:49:45 - INFO - __main__ -   Training loss after epoch 0.006474822585005313\n","03/05/2019 23:50:02 - INFO - __main__ -   Training accuracy after epoch 0.9985358711566618\n","03/05/2019 23:50:02 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 23:50:02 - INFO - __main__ -   Eval after epoch 10\n","03/05/2019 23:50:36 - INFO - __main__ -   {'loss': 1.6126399754091751, 'accuracy': 0.6616678858814923}\n","03/05/2019 23:50:36 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n","03/05/2019 23:50:37 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n","03/05/2019 23:50:37 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpjf4kv1t9\n","03/05/2019 23:50:41 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"max_position_embeddings\": 512,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","03/05/2019 23:50:46 - INFO - pytorch_pretrained_bert.modeling -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","03/05/2019 23:50:46 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","03/05/2019 23:50:46 - INFO - __main__ -     Num examples = 1366\n","03/05/2019 23:50:46 - INFO - __main__ -     Batch size = 32\n","03/05/2019 23:50:46 - INFO - __main__ -     Num steps = 426\n","03/05/2019 23:50:46 - INFO - __main__ -   Loss on batch 0: 0.6891389489173889\n","03/05/2019 23:51:15 - INFO - __main__ -   Training loss after epoch 0.692633377951245\n","03/05/2019 23:51:33 - INFO - __main__ -   Training accuracy after epoch 0.6720351390922401\n","03/05/2019 23:51:33 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 23:51:33 - INFO - __main__ -   Eval after epoch 1\n","03/05/2019 23:52:07 - INFO - __main__ -   {'loss': 0.6620100473248681, 'accuracy': 0.584491587417703}\n","03/05/2019 23:52:07 - INFO - __main__ -   Loss on batch 0: 0.5362294912338257\n","03/05/2019 23:52:36 - INFO - __main__ -   Training loss after epoch 0.5931584141975226\n","03/05/2019 23:52:53 - INFO - __main__ -   Training accuracy after epoch 0.9158125915080527\n","03/05/2019 23:52:53 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 23:52:53 - INFO - __main__ -   Eval after epoch 2\n","03/05/2019 23:53:28 - INFO - __main__ -   {'loss': 0.6364362860141799, 'accuracy': 0.6649597659107535}\n","03/05/2019 23:53:28 - INFO - __main__ -   Loss on batch 0: 0.33220627903938293\n","03/05/2019 23:53:57 - INFO - __main__ -   Training loss after epoch 0.2541290111839771\n","03/05/2019 23:54:14 - INFO - __main__ -   Training accuracy after epoch 0.9816983894582724\n","03/05/2019 23:54:14 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 23:54:14 - INFO - __main__ -   Eval after epoch 3\n","03/05/2019 23:54:48 - INFO - __main__ -   {'loss': 1.0110488977543144, 'accuracy': 0.633138258961229}\n","03/05/2019 23:54:48 - INFO - __main__ -   Loss on batch 0: 0.09717553108930588\n","03/05/2019 23:55:17 - INFO - __main__ -   Training loss after epoch 0.05996438406061295\n","03/05/2019 23:55:34 - INFO - __main__ -   Training accuracy after epoch 0.9985358711566618\n","03/05/2019 23:55:34 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 23:55:34 - INFO - __main__ -   Eval after epoch 4\n","03/05/2019 23:56:09 - INFO - __main__ -   {'loss': 1.2426473865675371, 'accuracy': 0.6466715435259692}\n","03/05/2019 23:56:09 - INFO - __main__ -   Loss on batch 0: 0.007273603230714798\n","03/05/2019 23:56:38 - INFO - __main__ -   Training loss after epoch 0.011982090516708965\n","03/05/2019 23:56:55 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/05/2019 23:56:55 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 23:56:55 - INFO - __main__ -   Eval after epoch 5\n","03/05/2019 23:57:29 - INFO - __main__ -   {'loss': 1.6137104062146919, 'accuracy': 0.6598390636430139}\n","03/05/2019 23:57:29 - INFO - __main__ -   Loss on batch 0: 0.0007892102003097534\n","03/05/2019 23:57:58 - INFO - __main__ -   Training loss after epoch 0.0024600340483905097\n","03/05/2019 23:58:15 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/05/2019 23:58:15 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 23:58:15 - INFO - __main__ -   Eval after epoch 6\n","03/05/2019 23:58:50 - INFO - __main__ -   {'loss': 1.7313286287840022, 'accuracy': 0.6605705925384052}\n","03/05/2019 23:58:50 - INFO - __main__ -   Loss on batch 0: 0.0003167465329170227\n","03/05/2019 23:59:19 - INFO - __main__ -   Training loss after epoch 0.001781615562639524\n","03/05/2019 23:59:36 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/05/2019 23:59:36 - INFO - __main__ -   ***** Running evaluation *****\n","03/05/2019 23:59:36 - INFO - __main__ -   Eval after epoch 7\n","03/06/2019 00:00:10 - INFO - __main__ -   {'loss': 1.7898535291815914, 'accuracy': 0.6587417702999269}\n","03/06/2019 00:00:11 - INFO - __main__ -   Loss on batch 0: 0.00043544918298721313\n","03/06/2019 00:00:40 - INFO - __main__ -   Training loss after epoch 0.0015725609365861517\n","03/06/2019 00:00:57 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 00:00:57 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 00:00:57 - INFO - __main__ -   Eval after epoch 8\n","03/06/2019 00:01:31 - INFO - __main__ -   {'loss': 1.8177590072154999, 'accuracy': 0.6598390636430139}\n","03/06/2019 00:01:32 - INFO - __main__ -   Loss on batch 0: 0.0002292543649673462\n","03/06/2019 00:02:00 - INFO - __main__ -   Training loss after epoch 0.0015121507235033827\n","03/06/2019 00:02:18 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 00:02:18 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 00:02:18 - INFO - __main__ -   Eval after epoch 9\n","03/06/2019 00:02:52 - INFO - __main__ -   {'loss': 1.8337753387384637, 'accuracy': 0.6591075347476225}\n","03/06/2019 00:02:52 - INFO - __main__ -   Loss on batch 0: 0.0002303197979927063\n","03/06/2019 00:03:21 - INFO - __main__ -   Training loss after epoch 0.0014463110487139242\n","03/06/2019 00:03:38 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 00:03:38 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 00:03:38 - INFO - __main__ -   Eval after epoch 10\n","03/06/2019 00:04:13 - INFO - __main__ -   {'loss': 1.8368441705093828, 'accuracy': 0.6594732991953182}\n","03/06/2019 00:04:13 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n","03/06/2019 00:04:13 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n","03/06/2019 00:04:13 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmp_zjvz9o8\n","03/06/2019 00:04:17 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"max_position_embeddings\": 512,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","03/06/2019 00:04:22 - INFO - pytorch_pretrained_bert.modeling -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","03/06/2019 00:04:22 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","03/06/2019 00:04:22 - INFO - __main__ -     Num examples = 1366\n","03/06/2019 00:04:22 - INFO - __main__ -     Batch size = 32\n","03/06/2019 00:04:22 - INFO - __main__ -     Num steps = 426\n","03/06/2019 00:04:22 - INFO - __main__ -   Loss on batch 0: 0.6939926743507385\n","03/06/2019 00:04:52 - INFO - __main__ -   Training loss after epoch 0.7037972447484039\n","03/06/2019 00:05:09 - INFO - __main__ -   Training accuracy after epoch 0.6398243045387995\n","03/06/2019 00:05:09 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 00:05:09 - INFO - __main__ -   Eval after epoch 1\n","03/06/2019 00:05:43 - INFO - __main__ -   {'loss': 0.6690921007200729, 'accuracy': 0.6027798098024872}\n","03/06/2019 00:05:43 - INFO - __main__ -   Loss on batch 0: 0.655063807964325\n","03/06/2019 00:06:12 - INFO - __main__ -   Training loss after epoch 0.5955459447794182\n","03/06/2019 00:06:29 - INFO - __main__ -   Training accuracy after epoch 0.8879941434846267\n","03/06/2019 00:06:29 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 00:06:29 - INFO - __main__ -   Eval after epoch 2\n","03/06/2019 00:07:04 - INFO - __main__ -   {'loss': 0.6315855785857799, 'accuracy': 0.6704462326261887}\n","03/06/2019 00:07:04 - INFO - __main__ -   Loss on batch 0: 0.44768837094306946\n","03/06/2019 00:07:33 - INFO - __main__ -   Training loss after epoch 0.2871430918227795\n","03/06/2019 00:07:50 - INFO - __main__ -   Training accuracy after epoch 0.9685212298682284\n","03/06/2019 00:07:50 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 00:07:50 - INFO - __main__ -   Eval after epoch 3\n","03/06/2019 00:08:24 - INFO - __main__ -   {'loss': 0.842657953154209, 'accuracy': 0.6667885881492319}\n","03/06/2019 00:08:25 - INFO - __main__ -   Loss on batch 0: 0.060506466776132584\n","03/06/2019 00:08:53 - INFO - __main__ -   Training loss after epoch 0.12199195296785166\n","03/06/2019 00:09:11 - INFO - __main__ -   Training accuracy after epoch 0.9897510980966325\n","03/06/2019 00:09:11 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 00:09:11 - INFO - __main__ -   Eval after epoch 4\n","03/06/2019 00:09:45 - INFO - __main__ -   {'loss': 0.965683844546939, 'accuracy': 0.6631309436722751}\n","03/06/2019 00:09:45 - INFO - __main__ -   Loss on batch 0: 0.015875160694122314\n","03/06/2019 00:10:14 - INFO - __main__ -   Training loss after epoch 0.028139280588474383\n","03/06/2019 00:10:31 - INFO - __main__ -   Training accuracy after epoch 0.9970717423133236\n","03/06/2019 00:10:31 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 00:10:31 - INFO - __main__ -   Eval after epoch 5\n","03/06/2019 00:11:06 - INFO - __main__ -   {'loss': 1.353587147108344, 'accuracy': 0.6792245793708851}\n","03/06/2019 00:11:06 - INFO - __main__ -   Loss on batch 0: 0.0013524740934371948\n","03/06/2019 00:11:35 - INFO - __main__ -   Training loss after epoch 0.016399262288888525\n","03/06/2019 00:11:52 - INFO - __main__ -   Training accuracy after epoch 0.9978038067349927\n","03/06/2019 00:11:52 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 00:11:52 - INFO - __main__ -   Eval after epoch 6\n","03/06/2019 00:12:26 - INFO - __main__ -   {'loss': 1.1976196668868841, 'accuracy': 0.6752011704462326}\n","03/06/2019 00:12:26 - INFO - __main__ -   Loss on batch 0: 0.0023263096809387207\n","03/06/2019 00:12:55 - INFO - __main__ -   Training loss after epoch 0.0070175792762013365\n","03/06/2019 00:13:12 - INFO - __main__ -   Training accuracy after epoch 0.9985358711566618\n","03/06/2019 00:13:12 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 00:13:12 - INFO - __main__ -   Eval after epoch 7\n","03/06/2019 00:13:47 - INFO - __main__ -   {'loss': 1.2904754835505818, 'accuracy': 0.6744696415508412}\n","03/06/2019 00:13:47 - INFO - __main__ -   Loss on batch 0: 0.0009498000144958496\n","03/06/2019 00:14:16 - INFO - __main__ -   Training loss after epoch 0.005389252213252232\n","03/06/2019 00:14:33 - INFO - __main__ -   Training accuracy after epoch 0.9985358711566618\n","03/06/2019 00:14:33 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 00:14:33 - INFO - __main__ -   Eval after epoch 8\n","03/06/2019 00:15:08 - INFO - __main__ -   {'loss': 1.3452787839396054, 'accuracy': 0.674835405998537}\n","03/06/2019 00:15:08 - INFO - __main__ -   Loss on batch 0: 0.0006778240203857422\n","03/06/2019 00:15:37 - INFO - __main__ -   Training loss after epoch 0.004145839308431849\n","03/06/2019 00:15:54 - INFO - __main__ -   Training accuracy after epoch 0.9985358711566618\n","03/06/2019 00:15:54 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 00:15:54 - INFO - __main__ -   Eval after epoch 9\n","03/06/2019 00:16:28 - INFO - __main__ -   {'loss': 1.3630048559848653, 'accuracy': 0.6744696415508412}\n","03/06/2019 00:16:28 - INFO - __main__ -   Loss on batch 0: 0.0009052306413650513\n","03/06/2019 00:16:57 - INFO - __main__ -   Training loss after epoch 0.0034960922622663338\n","03/06/2019 00:17:14 - INFO - __main__ -   Training accuracy after epoch 0.9985358711566618\n","03/06/2019 00:17:14 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 00:17:14 - INFO - __main__ -   Eval after epoch 10\n","03/06/2019 00:17:49 - INFO - __main__ -   {'loss': 1.363096719910932, 'accuracy': 0.6744696415508412}\n","03/06/2019 00:17:49 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n","03/06/2019 00:17:49 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n","03/06/2019 00:17:49 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpd622a53u\n","03/06/2019 00:17:54 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"max_position_embeddings\": 512,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","03/06/2019 00:17:58 - INFO - pytorch_pretrained_bert.modeling -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","03/06/2019 00:17:58 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","03/06/2019 00:17:58 - INFO - __main__ -     Num examples = 1366\n","03/06/2019 00:17:58 - INFO - __main__ -     Batch size = 32\n","03/06/2019 00:17:58 - INFO - __main__ -     Num steps = 426\n","03/06/2019 00:17:59 - INFO - __main__ -   Loss on batch 0: 0.6905394792556763\n","03/06/2019 00:18:28 - INFO - __main__ -   Training loss after epoch 0.7063094599302425\n","03/06/2019 00:18:45 - INFO - __main__ -   Training accuracy after epoch 0.5\n","03/06/2019 00:18:45 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 00:18:45 - INFO - __main__ -   Eval after epoch 1\n","03/06/2019 00:19:20 - INFO - __main__ -   {'loss': 0.6922433341658393, 'accuracy': 0.5}\n","03/06/2019 00:19:20 - INFO - __main__ -   Loss on batch 0: 0.7027822136878967\n","03/06/2019 00:19:49 - INFO - __main__ -   Training loss after epoch 0.6569847131884375\n","03/06/2019 00:20:06 - INFO - __main__ -   Training accuracy after epoch 0.5\n","03/06/2019 00:20:06 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 00:20:06 - INFO - __main__ -   Eval after epoch 2\n","03/06/2019 00:20:40 - INFO - __main__ -   {'loss': 0.6938992433769758, 'accuracy': 0.5}\n","03/06/2019 00:20:40 - INFO - __main__ -   Loss on batch 0: 0.6994843482971191\n","03/06/2019 00:21:09 - INFO - __main__ -   Training loss after epoch 0.5222805315671966\n","03/06/2019 00:21:26 - INFO - __main__ -   Training accuracy after epoch 0.9165446559297218\n","03/06/2019 00:21:26 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 00:21:26 - INFO - __main__ -   Eval after epoch 3\n","03/06/2019 00:22:01 - INFO - __main__ -   {'loss': 0.7654010528741881, 'accuracy': 0.6514264813460132}\n","03/06/2019 00:22:01 - INFO - __main__ -   Loss on batch 0: 0.20675432682037354\n","03/06/2019 00:22:30 - INFO - __main__ -   Training loss after epoch 0.22505070442377134\n","03/06/2019 00:22:47 - INFO - __main__ -   Training accuracy after epoch 0.9773060029282576\n","03/06/2019 00:22:47 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 00:22:47 - INFO - __main__ -   Eval after epoch 4\n","03/06/2019 00:23:22 - INFO - __main__ -   {'loss': 0.9798392608415248, 'accuracy': 0.6645940014630578}\n","03/06/2019 00:23:22 - INFO - __main__ -   Loss on batch 0: 0.11623875796794891\n","03/06/2019 00:23:51 - INFO - __main__ -   Training loss after epoch 0.07454823457830867\n","03/06/2019 00:24:08 - INFO - __main__ -   Training accuracy after epoch 0.9904831625183016\n","03/06/2019 00:24:08 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 00:24:08 - INFO - __main__ -   Eval after epoch 5\n","03/06/2019 00:24:42 - INFO - __main__ -   {'loss': 1.324334060036859, 'accuracy': 0.6415508412582297}\n","03/06/2019 00:24:42 - INFO - __main__ -   Loss on batch 0: 0.011247538030147552\n","03/06/2019 00:25:11 - INFO - __main__ -   Training loss after epoch 0.039415358035110454\n","03/06/2019 00:25:28 - INFO - __main__ -   Training accuracy after epoch 0.9948755490483162\n","03/06/2019 00:25:28 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 00:25:28 - INFO - __main__ -   Eval after epoch 6\n","03/06/2019 00:26:03 - INFO - __main__ -   {'loss': 1.3494623753913613, 'accuracy': 0.65508412582297}\n","03/06/2019 00:26:03 - INFO - __main__ -   Loss on batch 0: 0.003436259925365448\n","03/06/2019 00:26:32 - INFO - __main__ -   Training loss after epoch 0.019741621902645674\n","03/06/2019 00:26:49 - INFO - __main__ -   Training accuracy after epoch 0.9970717423133236\n","03/06/2019 00:26:49 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 00:26:49 - INFO - __main__ -   Eval after epoch 7\n","03/06/2019 00:27:23 - INFO - __main__ -   {'loss': 1.4049906086089998, 'accuracy': 0.6543525969275786}\n","03/06/2019 00:27:23 - INFO - __main__ -   Loss on batch 0: 0.029740633442997932\n","03/06/2019 00:27:52 - INFO - __main__ -   Training loss after epoch 0.010581179933492528\n","03/06/2019 00:28:09 - INFO - __main__ -   Training accuracy after epoch 0.9985358711566618\n","03/06/2019 00:28:09 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 00:28:09 - INFO - __main__ -   Eval after epoch 8\n","03/06/2019 00:28:44 - INFO - __main__ -   {'loss': 1.4622489671374477, 'accuracy': 0.6561814191660571}\n","03/06/2019 00:28:44 - INFO - __main__ -   Loss on batch 0: 0.001879274845123291\n","03/06/2019 00:29:13 - INFO - __main__ -   Training loss after epoch 0.009227809371686605\n","03/06/2019 00:29:30 - INFO - __main__ -   Training accuracy after epoch 0.9985358711566618\n","03/06/2019 00:29:30 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 00:29:30 - INFO - __main__ -   Eval after epoch 9\n","03/06/2019 00:30:04 - INFO - __main__ -   {'loss': 1.4613894910313363, 'accuracy': 0.6532553035844916}\n","03/06/2019 00:30:05 - INFO - __main__ -   Loss on batch 0: 0.0016778483986854553\n","03/06/2019 00:30:33 - INFO - __main__ -   Training loss after epoch 0.008306473344672731\n","03/06/2019 00:30:51 - INFO - __main__ -   Training accuracy after epoch 0.9985358711566618\n","03/06/2019 00:30:51 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 00:30:51 - INFO - __main__ -   Eval after epoch 10\n","03/06/2019 00:31:25 - INFO - __main__ -   {'loss': 1.4666156373744788, 'accuracy': 0.6528895391367959}\n","03/06/2019 00:31:25 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n","03/06/2019 00:31:26 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n","03/06/2019 00:31:26 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpecar860x\n","03/06/2019 00:31:30 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"max_position_embeddings\": 512,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","03/06/2019 00:31:35 - INFO - pytorch_pretrained_bert.modeling -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","03/06/2019 00:31:35 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","03/06/2019 00:31:35 - INFO - __main__ -     Num examples = 1366\n","03/06/2019 00:31:35 - INFO - __main__ -     Batch size = 32\n","03/06/2019 00:31:35 - INFO - __main__ -     Num steps = 426\n","03/06/2019 00:31:35 - INFO - __main__ -   Loss on batch 0: 0.7205159068107605\n","03/06/2019 00:32:05 - INFO - __main__ -   Training loss after epoch 0.6836410844048788\n","03/06/2019 00:32:22 - INFO - __main__ -   Training accuracy after epoch 0.6390922401171303\n","03/06/2019 00:32:22 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 00:32:22 - INFO - __main__ -   Eval after epoch 1\n","03/06/2019 00:32:56 - INFO - __main__ -   {'loss': 0.6510180435901465, 'accuracy': 0.5998536942209217}\n","03/06/2019 00:32:56 - INFO - __main__ -   Loss on batch 0: 0.7106701135635376\n","03/06/2019 00:33:25 - INFO - __main__ -   Training loss after epoch 0.5589753631935563\n","03/06/2019 00:33:42 - INFO - __main__ -   Training accuracy after epoch 0.8301610541727672\n","03/06/2019 00:33:42 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 00:33:42 - INFO - __main__ -   Eval after epoch 2\n","03/06/2019 00:34:17 - INFO - __main__ -   {'loss': 0.6919795035622841, 'accuracy': 0.6155815654718362}\n","03/06/2019 00:34:17 - INFO - __main__ -   Loss on batch 0: 0.3460743725299835\n","03/06/2019 00:34:46 - INFO - __main__ -   Training loss after epoch 0.3016200004968532\n","03/06/2019 00:35:03 - INFO - __main__ -   Training accuracy after epoch 0.9238653001464129\n","03/06/2019 00:35:03 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 00:35:03 - INFO - __main__ -   Eval after epoch 3\n","03/06/2019 00:35:37 - INFO - __main__ -   {'loss': 0.9436746884224027, 'accuracy': 0.6408193123628383}\n","03/06/2019 00:35:38 - INFO - __main__ -   Loss on batch 0: 0.1289345622062683\n","03/06/2019 00:36:07 - INFO - __main__ -   Training loss after epoch 0.09818505703709847\n","03/06/2019 00:36:24 - INFO - __main__ -   Training accuracy after epoch 0.9948755490483162\n","03/06/2019 00:36:24 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 00:36:24 - INFO - __main__ -   Eval after epoch 4\n","03/06/2019 00:36:58 - INFO - __main__ -   {'loss': 1.2163058782732763, 'accuracy': 0.6444769568397952}\n","03/06/2019 00:36:59 - INFO - __main__ -   Loss on batch 0: 0.01782941073179245\n","03/06/2019 00:37:27 - INFO - __main__ -   Training loss after epoch 0.017582099332452514\n","03/06/2019 00:37:45 - INFO - __main__ -   Training accuracy after epoch 0.9970717423133236\n","03/06/2019 00:37:45 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 00:37:45 - INFO - __main__ -   Eval after epoch 5\n","03/06/2019 00:38:19 - INFO - __main__ -   {'loss': 1.5713591464730197, 'accuracy': 0.6616678858814923}\n","03/06/2019 00:38:19 - INFO - __main__ -   Loss on batch 0: 0.0018818974494934082\n","03/06/2019 00:38:48 - INFO - __main__ -   Training loss after epoch 0.013811254308039193\n","03/06/2019 00:39:05 - INFO - __main__ -   Training accuracy after epoch 0.9985358711566618\n","03/06/2019 00:39:05 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 00:39:05 - INFO - __main__ -   Eval after epoch 6\n","03/06/2019 00:39:40 - INFO - __main__ -   {'loss': 1.557701988275661, 'accuracy': 0.6521580102414045}\n","03/06/2019 00:39:40 - INFO - __main__ -   Loss on batch 0: 0.001230590045452118\n","03/06/2019 00:40:09 - INFO - __main__ -   Training loss after epoch 0.005323693543390999\n","03/06/2019 00:40:26 - INFO - __main__ -   Training accuracy after epoch 0.9985358711566618\n","03/06/2019 00:40:26 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 00:40:26 - INFO - __main__ -   Eval after epoch 7\n","03/06/2019 00:41:00 - INFO - __main__ -   {'loss': 1.6175177277520645, 'accuracy': 0.653986832479883}\n","03/06/2019 00:41:00 - INFO - __main__ -   Loss on batch 0: 0.0011298730969429016\n","03/06/2019 00:41:29 - INFO - __main__ -   Training loss after epoch 0.0037470625843419587\n","03/06/2019 00:41:46 - INFO - __main__ -   Training accuracy after epoch 0.9985358711566618\n","03/06/2019 00:41:46 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 00:41:46 - INFO - __main__ -   Eval after epoch 8\n","03/06/2019 00:42:21 - INFO - __main__ -   {'loss': 1.6528555723123772, 'accuracy': 0.65508412582297}\n","03/06/2019 00:42:21 - INFO - __main__ -   Loss on batch 0: 0.001011386513710022\n","03/06/2019 00:42:50 - INFO - __main__ -   Training loss after epoch 0.0031257796691470715\n","03/06/2019 00:43:07 - INFO - __main__ -   Training accuracy after epoch 0.9985358711566618\n","03/06/2019 00:43:07 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 00:43:07 - INFO - __main__ -   Eval after epoch 9\n","03/06/2019 00:43:41 - INFO - __main__ -   {'loss': 1.6689044264859931, 'accuracy': 0.65508412582297}\n","03/06/2019 00:43:41 - INFO - __main__ -   Loss on batch 0: 0.0006950646638870239\n","03/06/2019 00:44:10 - INFO - __main__ -   Training loss after epoch 0.0029780683879264045\n","03/06/2019 00:44:27 - INFO - __main__ -   Training accuracy after epoch 0.9985358711566618\n","03/06/2019 00:44:27 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 00:44:27 - INFO - __main__ -   Eval after epoch 10\n","03/06/2019 00:45:01 - INFO - __main__ -   {'loss': 1.672235343345376, 'accuracy': 0.6554498902706657}\n","03/06/2019 00:45:01 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n","03/06/2019 00:45:02 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n","03/06/2019 00:45:02 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpc8txn5ar\n","03/06/2019 00:45:06 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"max_position_embeddings\": 512,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","03/06/2019 00:45:11 - INFO - pytorch_pretrained_bert.modeling -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","03/06/2019 00:45:11 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","03/06/2019 00:45:11 - INFO - __main__ -     Num examples = 1366\n","03/06/2019 00:45:11 - INFO - __main__ -     Batch size = 16\n","03/06/2019 00:45:11 - INFO - __main__ -     Num steps = 853\n","03/06/2019 00:45:11 - INFO - __main__ -   Loss on batch 0: 0.6482577919960022\n","03/06/2019 00:45:34 - INFO - __main__ -   Loss on batch 50: 0.8329734802246094\n","03/06/2019 00:45:49 - INFO - __main__ -   Training loss after epoch 0.6927506071190501\n","03/06/2019 00:46:07 - INFO - __main__ -   Training accuracy after epoch 0.6493411420204978\n","03/06/2019 00:46:07 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 00:46:07 - INFO - __main__ -   Eval after epoch 1\n","03/06/2019 00:46:41 - INFO - __main__ -   {'loss': 0.652156399433003, 'accuracy': 0.612289685442575}\n","03/06/2019 00:46:41 - INFO - __main__ -   Loss on batch 0: 0.6095701456069946\n","03/06/2019 00:47:03 - INFO - __main__ -   Loss on batch 50: 0.7655924558639526\n","03/06/2019 00:47:19 - INFO - __main__ -   Training loss after epoch 0.688211897431418\n","03/06/2019 00:47:36 - INFO - __main__ -   Training accuracy after epoch 0.5\n","03/06/2019 00:47:36 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 00:47:36 - INFO - __main__ -   Eval after epoch 2\n","03/06/2019 00:48:10 - INFO - __main__ -   {'loss': 0.6933038116887559, 'accuracy': 0.5}\n","03/06/2019 00:48:10 - INFO - __main__ -   Loss on batch 0: 0.6933076977729797\n","03/06/2019 00:48:32 - INFO - __main__ -   Loss on batch 50: 0.6737285852432251\n","03/06/2019 00:48:48 - INFO - __main__ -   Training loss after epoch 0.6968110085919846\n","03/06/2019 00:49:05 - INFO - __main__ -   Training accuracy after epoch 0.5\n","03/06/2019 00:49:05 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 00:49:05 - INFO - __main__ -   Eval after epoch 3\n","03/06/2019 00:49:40 - INFO - __main__ -   {'loss': 0.6931481416835341, 'accuracy': 0.5}\n","03/06/2019 00:49:40 - INFO - __main__ -   Loss on batch 0: 0.6925390362739563\n","03/06/2019 00:50:02 - INFO - __main__ -   Loss on batch 50: 0.6963273286819458\n","03/06/2019 00:50:17 - INFO - __main__ -   Training loss after epoch 0.6962195225926333\n","03/06/2019 00:50:35 - INFO - __main__ -   Training accuracy after epoch 0.5\n","03/06/2019 00:50:35 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 00:50:35 - INFO - __main__ -   Eval after epoch 4\n","03/06/2019 00:51:09 - INFO - __main__ -   {'loss': 0.6943904002045476, 'accuracy': 0.5}\n","03/06/2019 00:51:09 - INFO - __main__ -   Loss on batch 0: 0.6819129586219788\n","03/06/2019 00:51:31 - INFO - __main__ -   Loss on batch 50: 0.7007882595062256\n","03/06/2019 00:51:47 - INFO - __main__ -   Training loss after epoch 0.6945645136888637\n","03/06/2019 00:52:04 - INFO - __main__ -   Training accuracy after epoch 0.5\n","03/06/2019 00:52:04 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 00:52:04 - INFO - __main__ -   Eval after epoch 5\n","03/06/2019 00:52:38 - INFO - __main__ -   {'loss': 0.6934485179047252, 'accuracy': 0.5}\n","03/06/2019 00:52:38 - INFO - __main__ -   Loss on batch 0: 0.6965250372886658\n","03/06/2019 00:53:00 - INFO - __main__ -   Loss on batch 50: 0.7203599214553833\n","03/06/2019 00:53:16 - INFO - __main__ -   Training loss after epoch 0.6938084156014198\n","03/06/2019 00:53:33 - INFO - __main__ -   Training accuracy after epoch 0.5\n","03/06/2019 00:53:33 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 00:53:33 - INFO - __main__ -   Eval after epoch 6\n","03/06/2019 00:54:07 - INFO - __main__ -   {'loss': 0.694963216088539, 'accuracy': 0.5}\n","03/06/2019 00:54:08 - INFO - __main__ -   Loss on batch 0: 0.6949620842933655\n","03/06/2019 00:54:30 - INFO - __main__ -   Loss on batch 50: 0.6895821690559387\n","03/06/2019 00:54:45 - INFO - __main__ -   Training loss after epoch 0.694212022215821\n","03/06/2019 00:55:02 - INFO - __main__ -   Training accuracy after epoch 0.5\n","03/06/2019 00:55:02 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 00:55:02 - INFO - __main__ -   Eval after epoch 7\n","03/06/2019 00:55:37 - INFO - __main__ -   {'loss': 0.6951409107030824, 'accuracy': 0.5}\n","03/06/2019 00:55:37 - INFO - __main__ -   Loss on batch 0: 0.6951413750648499\n","03/06/2019 00:55:59 - INFO - __main__ -   Loss on batch 50: 0.6870161294937134\n","03/06/2019 00:56:15 - INFO - __main__ -   Training loss after epoch 0.6941612709400266\n","03/06/2019 00:56:32 - INFO - __main__ -   Training accuracy after epoch 0.5\n","03/06/2019 00:56:32 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 00:56:32 - INFO - __main__ -   Eval after epoch 8\n","03/06/2019 00:57:06 - INFO - __main__ -   {'loss': 0.6932068626547969, 'accuracy': 0.5}\n","03/06/2019 00:57:06 - INFO - __main__ -   Loss on batch 0: 0.6890640258789062\n","03/06/2019 00:57:28 - INFO - __main__ -   Loss on batch 50: 0.7005881071090698\n","03/06/2019 00:57:44 - INFO - __main__ -   Training loss after epoch 0.6937623883402625\n","03/06/2019 00:58:01 - INFO - __main__ -   Training accuracy after epoch 0.5\n","03/06/2019 00:58:01 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 00:58:01 - INFO - __main__ -   Eval after epoch 9\n","03/06/2019 00:58:35 - INFO - __main__ -   {'loss': 0.6931487224822821, 'accuracy': 0.5}\n","03/06/2019 00:58:36 - INFO - __main__ -   Loss on batch 0: 0.6934460997581482\n","03/06/2019 00:58:58 - INFO - __main__ -   Loss on batch 50: 0.692023515701294\n","03/06/2019 00:59:13 - INFO - __main__ -   Training loss after epoch 0.6933590416298356\n","03/06/2019 00:59:31 - INFO - __main__ -   Training accuracy after epoch 0.5\n","03/06/2019 00:59:31 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 00:59:31 - INFO - __main__ -   Eval after epoch 10\n","03/06/2019 01:00:05 - INFO - __main__ -   {'loss': 0.6932685513829075, 'accuracy': 0.5}\n","03/06/2019 01:00:05 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n","03/06/2019 01:00:05 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n","03/06/2019 01:00:05 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpy420xxcn\n","03/06/2019 01:00:10 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"max_position_embeddings\": 512,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","03/06/2019 01:00:14 - INFO - pytorch_pretrained_bert.modeling -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","03/06/2019 01:00:14 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","03/06/2019 01:00:15 - INFO - __main__ -     Num examples = 1366\n","03/06/2019 01:00:15 - INFO - __main__ -     Batch size = 16\n","03/06/2019 01:00:15 - INFO - __main__ -     Num steps = 853\n","03/06/2019 01:00:15 - INFO - __main__ -   Loss on batch 0: 0.6930404305458069\n","03/06/2019 01:00:37 - INFO - __main__ -   Loss on batch 50: 0.6930052638053894\n","03/06/2019 01:00:53 - INFO - __main__ -   Training loss after epoch 0.7048635607541993\n","03/06/2019 01:01:10 - INFO - __main__ -   Training accuracy after epoch 0.5878477306002928\n","03/06/2019 01:01:10 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 01:01:10 - INFO - __main__ -   Eval after epoch 1\n","03/06/2019 01:01:44 - INFO - __main__ -   {'loss': 0.677442059267399, 'accuracy': 0.5563277249451354}\n","03/06/2019 01:01:45 - INFO - __main__ -   Loss on batch 0: 0.7477092742919922\n","03/06/2019 01:02:07 - INFO - __main__ -   Loss on batch 50: 0.6317592859268188\n","03/06/2019 01:02:22 - INFO - __main__ -   Training loss after epoch 0.6137989374787308\n","03/06/2019 01:02:39 - INFO - __main__ -   Training accuracy after epoch 0.8733528550512445\n","03/06/2019 01:02:39 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 01:02:39 - INFO - __main__ -   Eval after epoch 2\n","03/06/2019 01:03:14 - INFO - __main__ -   {'loss': 0.6483272799225741, 'accuracy': 0.6558156547183613}\n","03/06/2019 01:03:14 - INFO - __main__ -   Loss on batch 0: 0.33367544412612915\n","03/06/2019 01:03:36 - INFO - __main__ -   Loss on batch 50: 0.1824035793542862\n","03/06/2019 01:03:52 - INFO - __main__ -   Training loss after epoch 0.2508836241742206\n","03/06/2019 01:04:09 - INFO - __main__ -   Training accuracy after epoch 0.9890190336749634\n","03/06/2019 01:04:09 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 01:04:09 - INFO - __main__ -   Eval after epoch 3\n","03/06/2019 01:04:43 - INFO - __main__ -   {'loss': 0.822137852047765, 'accuracy': 0.6715435259692758}\n","03/06/2019 01:04:44 - INFO - __main__ -   Loss on batch 0: 0.023060090839862823\n","03/06/2019 01:05:06 - INFO - __main__ -   Loss on batch 50: 0.005877256393432617\n","03/06/2019 01:05:21 - INFO - __main__ -   Training loss after epoch 0.03343654034096141\n","03/06/2019 01:05:38 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 01:05:38 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 01:05:38 - INFO - __main__ -   Eval after epoch 4\n","03/06/2019 01:06:13 - INFO - __main__ -   {'loss': 1.2793163778476937, 'accuracy': 0.6664228237015362}\n","03/06/2019 01:06:13 - INFO - __main__ -   Loss on batch 0: 0.003342568874359131\n","03/06/2019 01:06:35 - INFO - __main__ -   Loss on batch 50: 0.0011565536260604858\n","03/06/2019 01:06:51 - INFO - __main__ -   Training loss after epoch 0.003822027352302833\n","03/06/2019 01:07:08 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 01:07:08 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 01:07:08 - INFO - __main__ -   Eval after epoch 5\n","03/06/2019 01:07:42 - INFO - __main__ -   {'loss': 1.5644318211910337, 'accuracy': 0.6653255303584492}\n","03/06/2019 01:07:42 - INFO - __main__ -   Loss on batch 0: 0.0009222179651260376\n","03/06/2019 01:08:04 - INFO - __main__ -   Loss on batch 50: 0.0006790608167648315\n","03/06/2019 01:08:20 - INFO - __main__ -   Training loss after epoch 0.002527297676817059\n","03/06/2019 01:08:37 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 01:08:37 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 01:08:37 - INFO - __main__ -   Eval after epoch 6\n","03/06/2019 01:09:12 - INFO - __main__ -   {'loss': 1.6618932166764901, 'accuracy': 0.6660570592538405}\n","03/06/2019 01:09:12 - INFO - __main__ -   Loss on batch 0: 0.0008296370506286621\n","03/06/2019 01:09:34 - INFO - __main__ -   Loss on batch 50: 0.0006559193134307861\n","03/06/2019 01:09:49 - INFO - __main__ -   Training loss after epoch 0.00219660839282496\n","03/06/2019 01:10:07 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 01:10:07 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 01:10:07 - INFO - __main__ -   Eval after epoch 7\n","03/06/2019 01:10:41 - INFO - __main__ -   {'loss': 1.7087409683438235, 'accuracy': 0.6638624725676664}\n","03/06/2019 01:10:41 - INFO - __main__ -   Loss on batch 0: 0.0006653070449829102\n","03/06/2019 01:11:03 - INFO - __main__ -   Loss on batch 50: 0.0004866868257522583\n","03/06/2019 01:11:19 - INFO - __main__ -   Training loss after epoch 0.0019723573018699276\n","03/06/2019 01:11:36 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 01:11:36 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 01:11:36 - INFO - __main__ -   Eval after epoch 8\n","03/06/2019 01:12:10 - INFO - __main__ -   {'loss': 1.7394971001979918, 'accuracy': 0.6638624725676664}\n","03/06/2019 01:12:11 - INFO - __main__ -   Loss on batch 0: 0.00047691166400909424\n","03/06/2019 01:12:33 - INFO - __main__ -   Loss on batch 50: 0.0004273355007171631\n","03/06/2019 01:12:48 - INFO - __main__ -   Training loss after epoch 0.0018474857446732172\n","03/06/2019 01:13:06 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 01:13:06 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 01:13:06 - INFO - __main__ -   Eval after epoch 9\n","03/06/2019 01:13:40 - INFO - __main__ -   {'loss': 1.7584500839543897, 'accuracy': 0.6634967081199707}\n","03/06/2019 01:13:40 - INFO - __main__ -   Loss on batch 0: 0.00047463178634643555\n","03/06/2019 01:14:02 - INFO - __main__ -   Loss on batch 50: 0.0281512551009655\n","03/06/2019 01:14:18 - INFO - __main__ -   Training loss after epoch 0.0017755307083906129\n","03/06/2019 01:14:35 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 01:14:35 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 01:14:35 - INFO - __main__ -   Eval after epoch 10\n","03/06/2019 01:15:09 - INFO - __main__ -   {'loss': 1.763956093510916, 'accuracy': 0.6634967081199707}\n","03/06/2019 01:15:09 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n","03/06/2019 01:15:10 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n","03/06/2019 01:15:10 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpjnbnntrr\n","03/06/2019 01:15:14 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"max_position_embeddings\": 512,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","03/06/2019 01:15:19 - INFO - pytorch_pretrained_bert.modeling -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","03/06/2019 01:15:19 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","03/06/2019 01:15:19 - INFO - __main__ -     Num examples = 1366\n","03/06/2019 01:15:19 - INFO - __main__ -     Batch size = 16\n","03/06/2019 01:15:19 - INFO - __main__ -     Num steps = 853\n","03/06/2019 01:15:19 - INFO - __main__ -   Loss on batch 0: 0.7019652128219604\n","03/06/2019 01:15:41 - INFO - __main__ -   Loss on batch 50: 0.6096776127815247\n","03/06/2019 01:15:57 - INFO - __main__ -   Training loss after epoch 0.6765240472416545\n","03/06/2019 01:16:14 - INFO - __main__ -   Training accuracy after epoch 0.6244509516837482\n","03/06/2019 01:16:14 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 01:16:14 - INFO - __main__ -   Eval after epoch 1\n","03/06/2019 01:16:49 - INFO - __main__ -   {'loss': 0.673240696274957, 'accuracy': 0.5603511338697879}\n","03/06/2019 01:16:49 - INFO - __main__ -   Loss on batch 0: 0.4461933374404907\n","03/06/2019 01:17:11 - INFO - __main__ -   Loss on batch 50: 0.5642719268798828\n","03/06/2019 01:17:27 - INFO - __main__ -   Training loss after epoch 0.5303771426511366\n","03/06/2019 01:17:44 - INFO - __main__ -   Training accuracy after epoch 0.8696925329428989\n","03/06/2019 01:17:44 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 01:17:44 - INFO - __main__ -   Eval after epoch 2\n","03/06/2019 01:18:18 - INFO - __main__ -   {'loss': 0.8073173220767531, 'accuracy': 0.6089978054133138}\n","03/06/2019 01:18:18 - INFO - __main__ -   Loss on batch 0: 0.18393605947494507\n","03/06/2019 01:18:41 - INFO - __main__ -   Loss on batch 50: 0.08376189321279526\n","03/06/2019 01:18:57 - INFO - __main__ -   Training loss after epoch 0.16615887382609207\n","03/06/2019 01:19:14 - INFO - __main__ -   Training accuracy after epoch 0.9846266471449487\n","03/06/2019 01:19:14 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 01:19:14 - INFO - __main__ -   Eval after epoch 3\n","03/06/2019 01:19:48 - INFO - __main__ -   {'loss': 0.9997233568235885, 'accuracy': 0.6602048280907096}\n","03/06/2019 01:19:48 - INFO - __main__ -   Loss on batch 0: 0.026569921523332596\n","03/06/2019 01:20:11 - INFO - __main__ -   Loss on batch 50: 0.003774799406528473\n","03/06/2019 01:20:26 - INFO - __main__ -   Training loss after epoch 0.035918579624998274\n","03/06/2019 01:20:44 - INFO - __main__ -   Training accuracy after epoch 0.9985358711566618\n","03/06/2019 01:20:44 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 01:20:44 - INFO - __main__ -   Eval after epoch 4\n","03/06/2019 01:21:18 - INFO - __main__ -   {'loss': 1.3179454041081806, 'accuracy': 0.6872713972201902}\n","03/06/2019 01:21:18 - INFO - __main__ -   Loss on batch 0: 0.0018958598375320435\n","03/06/2019 01:21:40 - INFO - __main__ -   Loss on batch 50: 0.0024984627962112427\n","03/06/2019 01:21:56 - INFO - __main__ -   Training loss after epoch 0.007893013501225775\n","03/06/2019 01:22:13 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 01:22:13 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 01:22:13 - INFO - __main__ -   Eval after epoch 5\n","03/06/2019 01:22:48 - INFO - __main__ -   {'loss': 1.4166071373362874, 'accuracy': 0.6839795171909291}\n","03/06/2019 01:22:48 - INFO - __main__ -   Loss on batch 0: 0.0013683587312698364\n","03/06/2019 01:23:10 - INFO - __main__ -   Loss on batch 50: 0.0009364485740661621\n","03/06/2019 01:23:25 - INFO - __main__ -   Training loss after epoch 0.0047880310942906195\n","03/06/2019 01:23:43 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 01:23:43 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 01:23:43 - INFO - __main__ -   Eval after epoch 6\n","03/06/2019 01:24:17 - INFO - __main__ -   {'loss': 1.4724902323512143, 'accuracy': 0.6883686905632772}\n","03/06/2019 01:24:17 - INFO - __main__ -   Loss on batch 0: 0.0010585039854049683\n","03/06/2019 01:24:39 - INFO - __main__ -   Loss on batch 50: 0.0011606067419052124\n","03/06/2019 01:24:55 - INFO - __main__ -   Training loss after epoch 0.0027521975957084622\n","03/06/2019 01:25:12 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 01:25:12 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 01:25:12 - INFO - __main__ -   Eval after epoch 7\n","03/06/2019 01:25:46 - INFO - __main__ -   {'loss': 1.4880995861319608, 'accuracy': 0.6931236283833211}\n","03/06/2019 01:25:46 - INFO - __main__ -   Loss on batch 0: 0.0008336156606674194\n","03/06/2019 01:26:09 - INFO - __main__ -   Loss on batch 50: 0.0007985234260559082\n","03/06/2019 01:26:24 - INFO - __main__ -   Training loss after epoch 0.004720635380498458\n","03/06/2019 01:26:41 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 01:26:41 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 01:26:41 - INFO - __main__ -   Eval after epoch 8\n","03/06/2019 01:27:16 - INFO - __main__ -   {'loss': 1.4927405513996301, 'accuracy': 0.6872713972201902}\n","03/06/2019 01:27:16 - INFO - __main__ -   Loss on batch 0: 0.0008972287178039551\n","03/06/2019 01:27:38 - INFO - __main__ -   Loss on batch 50: 0.0010651051998138428\n","03/06/2019 01:27:54 - INFO - __main__ -   Training loss after epoch 0.00236591509053332\n","03/06/2019 01:28:11 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 01:28:11 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 01:28:11 - INFO - __main__ -   Eval after epoch 9\n","03/06/2019 01:28:45 - INFO - __main__ -   {'loss': 1.507481412832127, 'accuracy': 0.6912948061448427}\n","03/06/2019 01:28:45 - INFO - __main__ -   Loss on batch 0: 0.0008376240730285645\n","03/06/2019 01:29:07 - INFO - __main__ -   Loss on batch 50: 0.00077018141746521\n","03/06/2019 01:29:23 - INFO - __main__ -   Training loss after epoch 0.0020993501232222244\n","03/06/2019 01:29:40 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 01:29:40 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 01:29:40 - INFO - __main__ -   Eval after epoch 10\n","03/06/2019 01:30:15 - INFO - __main__ -   {'loss': 1.5115912535855935, 'accuracy': 0.6912948061448427}\n","03/06/2019 01:30:15 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n","03/06/2019 01:30:15 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n","03/06/2019 01:30:15 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmph24gmc0q\n","03/06/2019 01:30:20 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"max_position_embeddings\": 512,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","03/06/2019 01:30:24 - INFO - pytorch_pretrained_bert.modeling -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","03/06/2019 01:30:24 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","03/06/2019 01:30:24 - INFO - __main__ -     Num examples = 1366\n","03/06/2019 01:30:24 - INFO - __main__ -     Batch size = 16\n","03/06/2019 01:30:24 - INFO - __main__ -     Num steps = 853\n","03/06/2019 01:30:24 - INFO - __main__ -   Loss on batch 0: 0.8765743970870972\n","03/06/2019 01:30:47 - INFO - __main__ -   Loss on batch 50: 0.6999014616012573\n","03/06/2019 01:31:03 - INFO - __main__ -   Training loss after epoch 0.7083877740904342\n","03/06/2019 01:31:20 - INFO - __main__ -   Training accuracy after epoch 0.5\n","03/06/2019 01:31:20 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 01:31:20 - INFO - __main__ -   Eval after epoch 1\n","03/06/2019 01:31:54 - INFO - __main__ -   {'loss': 0.702551931142807, 'accuracy': 0.5}\n","03/06/2019 01:31:54 - INFO - __main__ -   Loss on batch 0: 0.7446320652961731\n","03/06/2019 01:32:17 - INFO - __main__ -   Loss on batch 50: 0.6140201687812805\n","03/06/2019 01:32:32 - INFO - __main__ -   Training loss after epoch 0.6491910960785178\n","03/06/2019 01:32:49 - INFO - __main__ -   Training accuracy after epoch 0.781112737920937\n","03/06/2019 01:32:49 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 01:32:49 - INFO - __main__ -   Eval after epoch 2\n","03/06/2019 01:33:24 - INFO - __main__ -   {'loss': 0.6215391280346139, 'accuracy': 0.6499634235552304}\n","03/06/2019 01:33:24 - INFO - __main__ -   Loss on batch 0: 0.37473997473716736\n","03/06/2019 01:33:46 - INFO - __main__ -   Loss on batch 50: 0.2674000561237335\n","03/06/2019 01:34:02 - INFO - __main__ -   Training loss after epoch 0.3408474385478469\n","03/06/2019 01:34:19 - INFO - __main__ -   Training accuracy after epoch 0.9736456808199122\n","03/06/2019 01:34:19 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 01:34:19 - INFO - __main__ -   Eval after epoch 3\n","03/06/2019 01:34:53 - INFO - __main__ -   {'loss': 0.7257672617601794, 'accuracy': 0.6664228237015362}\n","03/06/2019 01:34:53 - INFO - __main__ -   Loss on batch 0: 0.06569933891296387\n","03/06/2019 01:35:15 - INFO - __main__ -   Loss on batch 50: 0.16769766807556152\n","03/06/2019 01:35:31 - INFO - __main__ -   Training loss after epoch 0.07269319095973704\n","03/06/2019 01:35:48 - INFO - __main__ -   Training accuracy after epoch 0.9912152269399708\n","03/06/2019 01:35:48 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 01:35:48 - INFO - __main__ -   Eval after epoch 4\n","03/06/2019 01:36:22 - INFO - __main__ -   {'loss': 1.447769546231558, 'accuracy': 0.6517922457937089}\n","03/06/2019 01:36:23 - INFO - __main__ -   Loss on batch 0: 0.007343955338001251\n","03/06/2019 01:36:45 - INFO - __main__ -   Loss on batch 50: 0.001476883888244629\n","03/06/2019 01:37:01 - INFO - __main__ -   Training loss after epoch 0.013124901706591075\n","03/06/2019 01:37:18 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 01:37:18 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 01:37:18 - INFO - __main__ -   Eval after epoch 5\n","03/06/2019 01:37:53 - INFO - __main__ -   {'loss': 1.3506510306236357, 'accuracy': 0.6675201170446232}\n","03/06/2019 01:37:53 - INFO - __main__ -   Loss on batch 0: 0.002432793378829956\n","03/06/2019 01:38:15 - INFO - __main__ -   Loss on batch 50: 0.0012579113245010376\n","03/06/2019 01:38:31 - INFO - __main__ -   Training loss after epoch 0.002864897915102585\n","03/06/2019 01:38:48 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 01:38:48 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 01:38:48 - INFO - __main__ -   Eval after epoch 6\n","03/06/2019 01:39:23 - INFO - __main__ -   {'loss': 1.500999898411507, 'accuracy': 0.6649597659107535}\n","03/06/2019 01:39:23 - INFO - __main__ -   Loss on batch 0: 0.0018051937222480774\n","03/06/2019 01:39:45 - INFO - __main__ -   Loss on batch 50: 0.0006756484508514404\n","03/06/2019 01:40:01 - INFO - __main__ -   Training loss after epoch 0.0024303533570017924\n","03/06/2019 01:40:18 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 01:40:18 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 01:40:18 - INFO - __main__ -   Eval after epoch 7\n","03/06/2019 01:40:52 - INFO - __main__ -   {'loss': 1.5753006075703821, 'accuracy': 0.6653255303584492}\n","03/06/2019 01:40:52 - INFO - __main__ -   Loss on batch 0: 0.0008348524570465088\n","03/06/2019 01:41:15 - INFO - __main__ -   Loss on batch 50: 0.0005573630332946777\n","03/06/2019 01:41:30 - INFO - __main__ -   Training loss after epoch 0.0019379165240151937\n","03/06/2019 01:41:47 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 01:41:47 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 01:41:47 - INFO - __main__ -   Eval after epoch 8\n","03/06/2019 01:42:22 - INFO - __main__ -   {'loss': 1.6180546172829562, 'accuracy': 0.6645940014630578}\n","03/06/2019 01:42:22 - INFO - __main__ -   Loss on batch 0: 0.0005344897508621216\n","03/06/2019 01:42:44 - INFO - __main__ -   Loss on batch 50: 0.022585168480873108\n","03/06/2019 01:43:00 - INFO - __main__ -   Training loss after epoch 0.0019090666414000267\n","03/06/2019 01:43:17 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 01:43:17 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 01:43:17 - INFO - __main__ -   Eval after epoch 9\n","03/06/2019 01:43:51 - INFO - __main__ -   {'loss': 1.6395390699076098, 'accuracy': 0.6649597659107535}\n","03/06/2019 01:43:51 - INFO - __main__ -   Loss on batch 0: 0.0007774829864501953\n","03/06/2019 01:44:14 - INFO - __main__ -   Loss on batch 50: 0.000547751784324646\n","03/06/2019 01:44:29 - INFO - __main__ -   Training loss after epoch 0.001762879203915661\n","03/06/2019 01:44:46 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 01:44:46 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 01:44:46 - INFO - __main__ -   Eval after epoch 10\n","03/06/2019 01:45:21 - INFO - __main__ -   {'loss': 1.645853992811469, 'accuracy': 0.6649597659107535}\n","03/06/2019 01:45:21 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n","03/06/2019 01:45:21 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n","03/06/2019 01:45:21 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpn8tuirq8\n","03/06/2019 01:45:25 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"max_position_embeddings\": 512,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","03/06/2019 01:45:30 - INFO - pytorch_pretrained_bert.modeling -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","03/06/2019 01:45:30 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","03/06/2019 01:45:30 - INFO - __main__ -     Num examples = 1366\n","03/06/2019 01:45:30 - INFO - __main__ -     Batch size = 16\n","03/06/2019 01:45:30 - INFO - __main__ -     Num steps = 853\n","03/06/2019 01:45:30 - INFO - __main__ -   Loss on batch 0: 0.6688758134841919\n","03/06/2019 01:45:53 - INFO - __main__ -   Loss on batch 50: 0.6791549921035767\n","03/06/2019 01:46:08 - INFO - __main__ -   Training loss after epoch 0.6818799646787865\n","03/06/2019 01:46:26 - INFO - __main__ -   Training accuracy after epoch 0.6288433382137628\n","03/06/2019 01:46:26 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 01:46:26 - INFO - __main__ -   Eval after epoch 1\n","03/06/2019 01:47:00 - INFO - __main__ -   {'loss': 0.6713515492372735, 'accuracy': 0.5885149963423555}\n","03/06/2019 01:47:00 - INFO - __main__ -   Loss on batch 0: 0.597940981388092\n","03/06/2019 01:47:23 - INFO - __main__ -   Loss on batch 50: 0.6762276887893677\n","03/06/2019 01:47:38 - INFO - __main__ -   Training loss after epoch 0.5492597678026487\n","03/06/2019 01:47:56 - INFO - __main__ -   Training accuracy after epoch 0.9407027818448024\n","03/06/2019 01:47:56 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 01:47:56 - INFO - __main__ -   Eval after epoch 2\n","03/06/2019 01:48:30 - INFO - __main__ -   {'loss': 0.7166221058645914, 'accuracy': 0.6561814191660571}\n","03/06/2019 01:48:30 - INFO - __main__ -   Loss on batch 0: 0.2208499014377594\n","03/06/2019 01:48:53 - INFO - __main__ -   Loss on batch 50: 0.14794594049453735\n","03/06/2019 01:49:08 - INFO - __main__ -   Training loss after epoch 0.2026032003855636\n","03/06/2019 01:49:26 - INFO - __main__ -   Training accuracy after epoch 0.986090775988287\n","03/06/2019 01:49:26 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 01:49:26 - INFO - __main__ -   Eval after epoch 3\n","03/06/2019 01:50:00 - INFO - __main__ -   {'loss': 0.942312243372895, 'accuracy': 0.675932699341624}\n","03/06/2019 01:50:00 - INFO - __main__ -   Loss on batch 0: 0.010794684290885925\n","03/06/2019 01:50:22 - INFO - __main__ -   Loss on batch 50: 0.12793664634227753\n","03/06/2019 01:50:38 - INFO - __main__ -   Training loss after epoch 0.046304769776111775\n","03/06/2019 01:50:55 - INFO - __main__ -   Training accuracy after epoch 0.9970717423133236\n","03/06/2019 01:50:55 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 01:50:55 - INFO - __main__ -   Eval after epoch 4\n","03/06/2019 01:51:30 - INFO - __main__ -   {'loss': 1.2384333832319392, 'accuracy': 0.674835405998537}\n","03/06/2019 01:51:30 - INFO - __main__ -   Loss on batch 0: 0.006693102419376373\n","03/06/2019 01:51:52 - INFO - __main__ -   Loss on batch 50: 0.0019173398613929749\n","03/06/2019 01:52:08 - INFO - __main__ -   Training loss after epoch 0.008473399998132833\n","03/06/2019 01:52:25 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 01:52:25 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 01:52:25 - INFO - __main__ -   Eval after epoch 5\n","03/06/2019 01:53:00 - INFO - __main__ -   {'loss': 1.3967618685822154, 'accuracy': 0.6777615215801024}\n","03/06/2019 01:53:00 - INFO - __main__ -   Loss on batch 0: 0.0013585090637207031\n","03/06/2019 01:53:22 - INFO - __main__ -   Loss on batch 50: 0.0006447136402130127\n","03/06/2019 01:53:38 - INFO - __main__ -   Training loss after epoch 0.00247812457382679\n","03/06/2019 01:53:55 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 01:53:55 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 01:53:55 - INFO - __main__ -   Eval after epoch 6\n","03/06/2019 01:54:30 - INFO - __main__ -   {'loss': 1.5029346658739933, 'accuracy': 0.6803218727139722}\n","03/06/2019 01:54:30 - INFO - __main__ -   Loss on batch 0: 0.00054168701171875\n","03/06/2019 01:54:52 - INFO - __main__ -   Loss on batch 50: 0.00149613618850708\n","03/06/2019 01:55:08 - INFO - __main__ -   Training loss after epoch 0.0021150931428311134\n","03/06/2019 01:55:25 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 01:55:25 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 01:55:25 - INFO - __main__ -   Eval after epoch 7\n","03/06/2019 01:55:59 - INFO - __main__ -   {'loss': 1.5605100233887517, 'accuracy': 0.6795903438185809}\n","03/06/2019 01:55:59 - INFO - __main__ -   Loss on batch 0: 0.00048479437828063965\n","03/06/2019 01:56:21 - INFO - __main__ -   Loss on batch 50: 0.00048579275608062744\n","03/06/2019 01:56:37 - INFO - __main__ -   Training loss after epoch 0.0019225195164624385\n","03/06/2019 01:56:54 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 01:56:54 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 01:56:54 - INFO - __main__ -   Eval after epoch 8\n","03/06/2019 01:57:28 - INFO - __main__ -   {'loss': 1.5956750345784565, 'accuracy': 0.6799561082662765}\n","03/06/2019 01:57:28 - INFO - __main__ -   Loss on batch 0: 0.0003486722707748413\n","03/06/2019 01:57:51 - INFO - __main__ -   Loss on batch 50: 0.0005098581314086914\n","03/06/2019 01:58:06 - INFO - __main__ -   Training loss after epoch 0.0018356767619099078\n","03/06/2019 01:58:23 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 01:58:23 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 01:58:23 - INFO - __main__ -   Eval after epoch 9\n","03/06/2019 01:58:58 - INFO - __main__ -   {'loss': 1.6136503850304804, 'accuracy': 0.6795903438185809}\n","03/06/2019 01:58:58 - INFO - __main__ -   Loss on batch 0: 0.00033621490001678467\n","03/06/2019 01:59:20 - INFO - __main__ -   Loss on batch 50: 0.0002968311309814453\n","03/06/2019 01:59:36 - INFO - __main__ -   Training loss after epoch 0.0017613799403946803\n","03/06/2019 01:59:53 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 01:59:53 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 01:59:53 - INFO - __main__ -   Eval after epoch 10\n","03/06/2019 02:00:27 - INFO - __main__ -   {'loss': 1.6187237979367721, 'accuracy': 0.6773957571324067}\n","03/06/2019 02:00:27 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n","03/06/2019 02:00:27 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n","03/06/2019 02:00:27 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmp04uar4ec\n","03/06/2019 02:00:32 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"max_position_embeddings\": 512,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","03/06/2019 02:00:37 - INFO - pytorch_pretrained_bert.modeling -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","03/06/2019 02:00:37 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","03/06/2019 02:00:37 - INFO - __main__ -     Num examples = 1366\n","03/06/2019 02:00:37 - INFO - __main__ -     Batch size = 32\n","03/06/2019 02:00:37 - INFO - __main__ -     Num steps = 426\n","03/06/2019 02:00:37 - INFO - __main__ -   Loss on batch 0: 0.632570207118988\n","03/06/2019 02:01:06 - INFO - __main__ -   Training loss after epoch 0.6805495384127594\n","03/06/2019 02:01:23 - INFO - __main__ -   Training accuracy after epoch 0.7679355783308931\n","03/06/2019 02:01:23 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 02:01:23 - INFO - __main__ -   Eval after epoch 1\n","03/06/2019 02:01:57 - INFO - __main__ -   {'loss': 0.6326376872007237, 'accuracy': 0.6492318946598391}\n","03/06/2019 02:01:58 - INFO - __main__ -   Loss on batch 0: 0.561562180519104\n","03/06/2019 02:02:27 - INFO - __main__ -   Training loss after epoch 0.5340394987616428\n","03/06/2019 02:02:44 - INFO - __main__ -   Training accuracy after epoch 0.8755490483162518\n","03/06/2019 02:02:44 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 02:02:44 - INFO - __main__ -   Eval after epoch 2\n","03/06/2019 02:03:18 - INFO - __main__ -   {'loss': 0.6592967156753984, 'accuracy': 0.6166788588149232}\n","03/06/2019 02:03:19 - INFO - __main__ -   Loss on batch 0: 0.3491753041744232\n","03/06/2019 02:03:48 - INFO - __main__ -   Training loss after epoch 0.1733144322453543\n","03/06/2019 02:04:05 - INFO - __main__ -   Training accuracy after epoch 0.9926793557833089\n","03/06/2019 02:04:05 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 02:04:05 - INFO - __main__ -   Eval after epoch 3\n","03/06/2019 02:04:40 - INFO - __main__ -   {'loss': 0.9485468632260035, 'accuracy': 0.6649597659107535}\n","03/06/2019 02:04:40 - INFO - __main__ -   Loss on batch 0: 0.026415934786200523\n","03/06/2019 02:05:09 - INFO - __main__ -   Training loss after epoch 0.03677223674779714\n","03/06/2019 02:05:26 - INFO - __main__ -   Training accuracy after epoch 0.9956076134699854\n","03/06/2019 02:05:26 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 02:05:26 - INFO - __main__ -   Eval after epoch 4\n","03/06/2019 02:06:00 - INFO - __main__ -   {'loss': 1.429487420375957, 'accuracy': 0.6503291880029262}\n","03/06/2019 02:06:01 - INFO - __main__ -   Loss on batch 0: 0.004751928150653839\n","03/06/2019 02:06:29 - INFO - __main__ -   Training loss after epoch 0.011917106552742595\n","03/06/2019 02:06:47 - INFO - __main__ -   Training accuracy after epoch 0.9985358711566618\n","03/06/2019 02:06:47 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 02:06:47 - INFO - __main__ -   Eval after epoch 5\n","03/06/2019 02:07:21 - INFO - __main__ -   {'loss': 1.4011772184870963, 'accuracy': 0.6656912948061449}\n","03/06/2019 02:07:21 - INFO - __main__ -   Loss on batch 0: 0.002119295299053192\n","03/06/2019 02:07:50 - INFO - __main__ -   Training loss after epoch 0.008290528143799408\n","03/06/2019 02:08:07 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 02:08:07 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 02:08:07 - INFO - __main__ -   Eval after epoch 6\n","03/06/2019 02:08:42 - INFO - __main__ -   {'loss': 1.5584997437721075, 'accuracy': 0.660936356986101}\n","03/06/2019 02:08:42 - INFO - __main__ -   Loss on batch 0: 0.0017747282981872559\n","03/06/2019 02:09:10 - INFO - __main__ -   Training loss after epoch 0.0041351947976752765\n","03/06/2019 02:09:28 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 02:09:28 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 02:09:28 - INFO - __main__ -   Eval after epoch 7\n","03/06/2019 02:10:02 - INFO - __main__ -   {'loss': 1.5780046443606532, 'accuracy': 0.660936356986101}\n","03/06/2019 02:10:02 - INFO - __main__ -   Loss on batch 0: 0.001263342797756195\n","03/06/2019 02:10:31 - INFO - __main__ -   Training loss after epoch 0.003181085117746058\n","03/06/2019 02:10:48 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 02:10:48 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 02:10:48 - INFO - __main__ -   Eval after epoch 8\n","03/06/2019 02:11:22 - INFO - __main__ -   {'loss': 1.6060542942479599, 'accuracy': 0.6627651792245793}\n","03/06/2019 02:11:22 - INFO - __main__ -   Loss on batch 0: 0.0009903982281684875\n","03/06/2019 02:11:51 - INFO - __main__ -   Training loss after epoch 0.0024796912113616114\n","03/06/2019 02:12:08 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 02:12:08 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 02:12:08 - INFO - __main__ -   Eval after epoch 9\n","03/06/2019 02:12:43 - INFO - __main__ -   {'loss': 1.624520969945331, 'accuracy': 0.6634967081199707}\n","03/06/2019 02:12:43 - INFO - __main__ -   Loss on batch 0: 0.0012686476111412048\n","03/06/2019 02:13:11 - INFO - __main__ -   Training loss after epoch 0.002242579886982174\n","03/06/2019 02:13:29 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 02:13:29 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 02:13:29 - INFO - __main__ -   Eval after epoch 10\n","03/06/2019 02:14:03 - INFO - __main__ -   {'loss': 1.6280383613220482, 'accuracy': 0.6649597659107535}\n","03/06/2019 02:14:03 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n","03/06/2019 02:14:03 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n","03/06/2019 02:14:03 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmprb5vi563\n","03/06/2019 02:14:08 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"max_position_embeddings\": 512,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","03/06/2019 02:14:12 - INFO - pytorch_pretrained_bert.modeling -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","03/06/2019 02:14:12 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","03/06/2019 02:14:13 - INFO - __main__ -     Num examples = 1366\n","03/06/2019 02:14:13 - INFO - __main__ -     Batch size = 32\n","03/06/2019 02:14:13 - INFO - __main__ -     Num steps = 426\n","03/06/2019 02:14:13 - INFO - __main__ -   Loss on batch 0: 0.8430590629577637\n","03/06/2019 02:14:42 - INFO - __main__ -   Training loss after epoch 0.7173284264497979\n","03/06/2019 02:14:59 - INFO - __main__ -   Training accuracy after epoch 0.5\n","03/06/2019 02:14:59 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 02:14:59 - INFO - __main__ -   Eval after epoch 1\n","03/06/2019 02:15:33 - INFO - __main__ -   {'loss': 0.6999047086682431, 'accuracy': 0.5}\n","03/06/2019 02:15:33 - INFO - __main__ -   Loss on batch 0: 0.6799403429031372\n","03/06/2019 02:16:02 - INFO - __main__ -   Training loss after epoch 0.6614258213098659\n","03/06/2019 02:16:19 - INFO - __main__ -   Training accuracy after epoch 0.7489019033674963\n","03/06/2019 02:16:19 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 02:16:19 - INFO - __main__ -   Eval after epoch 2\n","03/06/2019 02:16:54 - INFO - __main__ -   {'loss': 0.6388049624687018, 'accuracy': 0.660936356986101}\n","03/06/2019 02:16:54 - INFO - __main__ -   Loss on batch 0: 0.5976678133010864\n","03/06/2019 02:17:22 - INFO - __main__ -   Training loss after epoch 0.4793324096258296\n","03/06/2019 02:17:40 - INFO - __main__ -   Training accuracy after epoch 0.9568081991215227\n","03/06/2019 02:17:40 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 02:17:40 - INFO - __main__ -   Eval after epoch 3\n","03/06/2019 02:18:14 - INFO - __main__ -   {'loss': 0.6523068890322087, 'accuracy': 0.6667885881492319}\n","03/06/2019 02:18:14 - INFO - __main__ -   Loss on batch 0: 0.2135033756494522\n","03/06/2019 02:18:43 - INFO - __main__ -   Training loss after epoch 0.15369902330255786\n","03/06/2019 02:19:00 - INFO - __main__ -   Training accuracy after epoch 0.9904831625183016\n","03/06/2019 02:19:00 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 02:19:00 - INFO - __main__ -   Eval after epoch 4\n","03/06/2019 02:19:35 - INFO - __main__ -   {'loss': 0.9044147230858026, 'accuracy': 0.65508412582297}\n","03/06/2019 02:19:35 - INFO - __main__ -   Loss on batch 0: 0.021743249148130417\n","03/06/2019 02:20:04 - INFO - __main__ -   Training loss after epoch 0.03421403545626374\n","03/06/2019 02:20:21 - INFO - __main__ -   Training accuracy after epoch 0.9963396778916545\n","03/06/2019 02:20:21 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 02:20:21 - INFO - __main__ -   Eval after epoch 5\n","03/06/2019 02:20:56 - INFO - __main__ -   {'loss': 1.243303583804951, 'accuracy': 0.6708119970738844}\n","03/06/2019 02:20:56 - INFO - __main__ -   Loss on batch 0: 0.01683255098760128\n","03/06/2019 02:21:24 - INFO - __main__ -   Training loss after epoch 0.013629291212012949\n","03/06/2019 02:21:42 - INFO - __main__ -   Training accuracy after epoch 0.9978038067349927\n","03/06/2019 02:21:42 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 02:21:42 - INFO - __main__ -   Eval after epoch 6\n","03/06/2019 02:22:16 - INFO - __main__ -   {'loss': 1.4438968037450037, 'accuracy': 0.6686174103877103}\n","03/06/2019 02:22:16 - INFO - __main__ -   Loss on batch 0: 0.003573816269636154\n","03/06/2019 02:22:45 - INFO - __main__ -   Training loss after epoch 0.010516515960050531\n","03/06/2019 02:23:02 - INFO - __main__ -   Training accuracy after epoch 0.9985358711566618\n","03/06/2019 02:23:02 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 02:23:02 - INFO - __main__ -   Eval after epoch 7\n","03/06/2019 02:23:37 - INFO - __main__ -   {'loss': 1.485265432402145, 'accuracy': 0.6700804681784931}\n","03/06/2019 02:23:37 - INFO - __main__ -   Loss on batch 0: 0.0019527524709701538\n","03/06/2019 02:24:06 - INFO - __main__ -   Training loss after epoch 0.00609754478331482\n","03/06/2019 02:24:23 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 02:24:23 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 02:24:23 - INFO - __main__ -   Eval after epoch 8\n","03/06/2019 02:24:57 - INFO - __main__ -   {'loss': 1.5429220899593, 'accuracy': 0.6693489392831017}\n","03/06/2019 02:24:58 - INFO - __main__ -   Loss on batch 0: 0.00115310400724411\n","03/06/2019 02:25:26 - INFO - __main__ -   Training loss after epoch 0.0029322906954993688\n","03/06/2019 02:25:44 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 02:25:44 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 02:25:44 - INFO - __main__ -   Eval after epoch 9\n","03/06/2019 02:26:18 - INFO - __main__ -   {'loss': 1.5711470960184586, 'accuracy': 0.668983174835406}\n","03/06/2019 02:26:18 - INFO - __main__ -   Loss on batch 0: 0.0013298839330673218\n","03/06/2019 02:26:47 - INFO - __main__ -   Training loss after epoch 0.0027067500334449633\n","03/06/2019 02:27:04 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 02:27:04 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 02:27:04 - INFO - __main__ -   Eval after epoch 10\n","03/06/2019 02:27:39 - INFO - __main__ -   {'loss': 1.5759725480578666, 'accuracy': 0.667885881492319}\n","03/06/2019 02:27:39 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n","03/06/2019 02:27:39 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n","03/06/2019 02:27:39 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmp66qys7jj\n","03/06/2019 02:27:44 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"max_position_embeddings\": 512,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","03/06/2019 02:27:48 - INFO - pytorch_pretrained_bert.modeling -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","03/06/2019 02:27:48 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","03/06/2019 02:27:48 - INFO - __main__ -     Num examples = 1366\n","03/06/2019 02:27:48 - INFO - __main__ -     Batch size = 32\n","03/06/2019 02:27:48 - INFO - __main__ -     Num steps = 426\n","03/06/2019 02:27:49 - INFO - __main__ -   Loss on batch 0: 0.6840466260910034\n","03/06/2019 02:28:18 - INFO - __main__ -   Training loss after epoch 0.697380987710731\n","03/06/2019 02:28:35 - INFO - __main__ -   Training accuracy after epoch 0.5900439238653001\n","03/06/2019 02:28:35 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 02:28:35 - INFO - __main__ -   Eval after epoch 1\n","03/06/2019 02:29:09 - INFO - __main__ -   {'loss': 0.680648873018664, 'accuracy': 0.5815654718361375}\n","03/06/2019 02:29:09 - INFO - __main__ -   Loss on batch 0: 0.6255887150764465\n","03/06/2019 02:29:38 - INFO - __main__ -   Training loss after epoch 0.609559484692507\n","03/06/2019 02:29:55 - INFO - __main__ -   Training accuracy after epoch 0.9202049780380673\n","03/06/2019 02:29:55 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 02:29:55 - INFO - __main__ -   Eval after epoch 2\n","03/06/2019 02:30:29 - INFO - __main__ -   {'loss': 0.6176204331392465, 'accuracy': 0.6803218727139722}\n","03/06/2019 02:30:30 - INFO - __main__ -   Loss on batch 0: 0.275280237197876\n","03/06/2019 02:30:58 - INFO - __main__ -   Training loss after epoch 0.21121852390121582\n","03/06/2019 02:31:16 - INFO - __main__ -   Training accuracy after epoch 0.9787701317715959\n","03/06/2019 02:31:16 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 02:31:16 - INFO - __main__ -   Eval after epoch 3\n","03/06/2019 02:31:50 - INFO - __main__ -   {'loss': 0.850639766385389, 'accuracy': 0.6583760058522312}\n","03/06/2019 02:31:50 - INFO - __main__ -   Loss on batch 0: 0.05500510334968567\n","03/06/2019 02:32:19 - INFO - __main__ -   Training loss after epoch 0.06692981594350449\n","03/06/2019 02:32:36 - INFO - __main__ -   Training accuracy after epoch 0.9890190336749634\n","03/06/2019 02:32:36 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 02:32:36 - INFO - __main__ -   Eval after epoch 4\n","03/06/2019 02:33:10 - INFO - __main__ -   {'loss': 1.2720169175502867, 'accuracy': 0.6474030724213606}\n","03/06/2019 02:33:11 - INFO - __main__ -   Loss on batch 0: 0.016396980732679367\n","03/06/2019 02:33:39 - INFO - __main__ -   Training loss after epoch 0.026648591597412907\n","03/06/2019 02:33:56 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 02:33:56 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 02:33:56 - INFO - __main__ -   Eval after epoch 5\n","03/06/2019 02:34:31 - INFO - __main__ -   {'loss': 1.4393149510372516, 'accuracy': 0.6605705925384052}\n","03/06/2019 02:34:31 - INFO - __main__ -   Loss on batch 0: 0.0029358267784118652\n","03/06/2019 02:35:00 - INFO - __main__ -   Training loss after epoch 0.0032223874451267685\n","03/06/2019 02:35:17 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 02:35:17 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 02:35:17 - INFO - __main__ -   Eval after epoch 6\n","03/06/2019 02:35:51 - INFO - __main__ -   {'loss': 1.5202640468298003, 'accuracy': 0.6528895391367959}\n","03/06/2019 02:35:52 - INFO - __main__ -   Loss on batch 0: 0.000550583004951477\n","03/06/2019 02:36:21 - INFO - __main__ -   Training loss after epoch 0.0028755613007084573\n","03/06/2019 02:36:38 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 02:36:38 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 02:36:38 - INFO - __main__ -   Eval after epoch 7\n","03/06/2019 02:37:12 - INFO - __main__ -   {'loss': 1.592391856881075, 'accuracy': 0.653986832479883}\n","03/06/2019 02:37:12 - INFO - __main__ -   Loss on batch 0: 0.0004935786128044128\n","03/06/2019 02:37:41 - INFO - __main__ -   Training loss after epoch 0.0025434593296458207\n","03/06/2019 02:37:58 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 02:37:58 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 02:37:58 - INFO - __main__ -   Eval after epoch 8\n","03/06/2019 02:38:32 - INFO - __main__ -   {'loss': 1.6227842714897422, 'accuracy': 0.6532553035844916}\n","03/06/2019 02:38:33 - INFO - __main__ -   Loss on batch 0: 0.00035046786069869995\n","03/06/2019 02:39:01 - INFO - __main__ -   Training loss after epoch 0.0020923909709550615\n","03/06/2019 02:39:19 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 02:39:19 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 02:39:19 - INFO - __main__ -   Eval after epoch 9\n","03/06/2019 02:39:53 - INFO - __main__ -   {'loss': 1.6442464104918546, 'accuracy': 0.6532553035844916}\n","03/06/2019 02:39:54 - INFO - __main__ -   Loss on batch 0: 0.00062599778175354\n","03/06/2019 02:40:23 - INFO - __main__ -   Training loss after epoch 0.0018244556233904129\n","03/06/2019 02:40:40 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 02:40:40 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 02:40:40 - INFO - __main__ -   Eval after epoch 10\n","03/06/2019 02:41:14 - INFO - __main__ -   {'loss': 1.648131905600082, 'accuracy': 0.6532553035844916}\n","03/06/2019 02:41:14 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n","03/06/2019 02:41:15 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n","03/06/2019 02:41:15 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmp6qflpodu\n","03/06/2019 02:41:19 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"max_position_embeddings\": 512,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","03/06/2019 02:41:24 - INFO - pytorch_pretrained_bert.modeling -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","03/06/2019 02:41:24 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","03/06/2019 02:41:24 - INFO - __main__ -     Num examples = 1366\n","03/06/2019 02:41:24 - INFO - __main__ -     Batch size = 32\n","03/06/2019 02:41:24 - INFO - __main__ -     Num steps = 426\n","03/06/2019 02:41:24 - INFO - __main__ -   Loss on batch 0: 0.7093635201454163\n","03/06/2019 02:41:54 - INFO - __main__ -   Training loss after epoch 0.6903482592383097\n","03/06/2019 02:42:11 - INFO - __main__ -   Training accuracy after epoch 0.7474377745241582\n","03/06/2019 02:42:11 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 02:42:11 - INFO - __main__ -   Eval after epoch 1\n","03/06/2019 02:42:45 - INFO - __main__ -   {'loss': 0.6517686961695205, 'accuracy': 0.6645940014630578}\n","03/06/2019 02:42:45 - INFO - __main__ -   Loss on batch 0: 0.6071015000343323\n","03/06/2019 02:43:14 - INFO - __main__ -   Training loss after epoch 0.5507493393365727\n","03/06/2019 02:43:31 - INFO - __main__ -   Training accuracy after epoch 0.9377745241581259\n","03/06/2019 02:43:31 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 02:43:31 - INFO - __main__ -   Eval after epoch 2\n","03/06/2019 02:44:05 - INFO - __main__ -   {'loss': 0.6028010807065076, 'accuracy': 0.68983174835406}\n","03/06/2019 02:44:06 - INFO - __main__ -   Loss on batch 0: 0.2114398330450058\n","03/06/2019 02:44:34 - INFO - __main__ -   Training loss after epoch 0.19657595221732937\n","03/06/2019 02:44:52 - INFO - __main__ -   Training accuracy after epoch 0.9765739385065886\n","03/06/2019 02:44:52 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 02:44:52 - INFO - __main__ -   Eval after epoch 3\n","03/06/2019 02:45:26 - INFO - __main__ -   {'loss': 0.9902069464672444, 'accuracy': 0.6547183613752743}\n","03/06/2019 02:45:26 - INFO - __main__ -   Loss on batch 0: 0.14130045473575592\n","03/06/2019 02:45:55 - INFO - __main__ -   Training loss after epoch 0.040309696479938754\n","03/06/2019 02:46:12 - INFO - __main__ -   Training accuracy after epoch 0.9978038067349927\n","03/06/2019 02:46:12 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 02:46:12 - INFO - __main__ -   Eval after epoch 4\n","03/06/2019 02:46:46 - INFO - __main__ -   {'loss': 1.2394779296808465, 'accuracy': 0.6726408193123629}\n","03/06/2019 02:46:46 - INFO - __main__ -   Loss on batch 0: 0.00362589955329895\n","03/06/2019 02:47:15 - INFO - __main__ -   Training loss after epoch 0.008718594897884962\n","03/06/2019 02:47:32 - INFO - __main__ -   Training accuracy after epoch 0.9985358711566618\n","03/06/2019 02:47:32 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 02:47:32 - INFO - __main__ -   Eval after epoch 5\n","03/06/2019 02:48:07 - INFO - __main__ -   {'loss': 1.4083392807217532, 'accuracy': 0.6733723482077542}\n","03/06/2019 02:48:07 - INFO - __main__ -   Loss on batch 0: 0.01048368401825428\n","03/06/2019 02:48:35 - INFO - __main__ -   Training loss after epoch 0.005667682921210694\n","03/06/2019 02:48:53 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 02:48:53 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 02:48:53 - INFO - __main__ -   Eval after epoch 6\n","03/06/2019 02:49:27 - INFO - __main__ -   {'loss': 1.5046303535616674, 'accuracy': 0.667885881492319}\n","03/06/2019 02:49:27 - INFO - __main__ -   Loss on batch 0: 0.0014658495783805847\n","03/06/2019 02:49:56 - INFO - __main__ -   Training loss after epoch 0.0031651816395826117\n","03/06/2019 02:50:13 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 02:50:13 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 02:50:13 - INFO - __main__ -   Eval after epoch 7\n","03/06/2019 02:50:48 - INFO - __main__ -   {'loss': 1.5585487235424131, 'accuracy': 0.6719092904169714}\n","03/06/2019 02:50:48 - INFO - __main__ -   Loss on batch 0: 0.0008743107318878174\n","03/06/2019 02:51:17 - INFO - __main__ -   Training loss after epoch 0.0022593243250645005\n","03/06/2019 02:51:34 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 02:51:34 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 02:51:34 - INFO - __main__ -   Eval after epoch 8\n","03/06/2019 02:52:09 - INFO - __main__ -   {'loss': 1.5947151551412981, 'accuracy': 0.6737381126554499}\n","03/06/2019 02:52:09 - INFO - __main__ -   Loss on batch 0: 0.0008979961276054382\n","03/06/2019 02:52:38 - INFO - __main__ -   Training loss after epoch 0.0021082165320728753\n","03/06/2019 02:52:55 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 02:52:55 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 02:52:55 - INFO - __main__ -   Eval after epoch 9\n","03/06/2019 02:53:29 - INFO - __main__ -   {'loss': 1.6131567047085873, 'accuracy': 0.6741038771031456}\n","03/06/2019 02:53:30 - INFO - __main__ -   Loss on batch 0: 0.03239477425813675\n","03/06/2019 02:53:58 - INFO - __main__ -   Training loss after epoch 0.002057603184068792\n","03/06/2019 02:54:16 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 02:54:16 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 02:54:16 - INFO - __main__ -   Eval after epoch 10\n","03/06/2019 02:54:50 - INFO - __main__ -   {'loss': 1.6181635808113009, 'accuracy': 0.6741038771031456}\n","03/06/2019 02:54:50 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n","03/06/2019 02:54:50 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n","03/06/2019 02:54:50 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmplmhojj54\n","03/06/2019 02:54:55 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"max_position_embeddings\": 512,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","03/06/2019 02:55:00 - INFO - pytorch_pretrained_bert.modeling -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","03/06/2019 02:55:00 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","03/06/2019 02:55:00 - INFO - __main__ -     Num examples = 1366\n","03/06/2019 02:55:00 - INFO - __main__ -     Batch size = 32\n","03/06/2019 02:55:00 - INFO - __main__ -     Num steps = 426\n","03/06/2019 02:55:00 - INFO - __main__ -   Loss on batch 0: 0.744614839553833\n","03/06/2019 02:55:29 - INFO - __main__ -   Training loss after epoch 0.6811156834280768\n","03/06/2019 02:55:47 - INFO - __main__ -   Training accuracy after epoch 0.773792093704246\n","03/06/2019 02:55:47 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 02:55:47 - INFO - __main__ -   Eval after epoch 1\n","03/06/2019 02:56:21 - INFO - __main__ -   {'loss': 0.6437446267105812, 'accuracy': 0.6576444769568398}\n","03/06/2019 02:56:21 - INFO - __main__ -   Loss on batch 0: 0.46925750374794006\n","03/06/2019 02:56:50 - INFO - __main__ -   Training loss after epoch 0.49552438910617386\n","03/06/2019 02:57:07 - INFO - __main__ -   Training accuracy after epoch 0.9575402635431918\n","03/06/2019 02:57:07 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 02:57:07 - INFO - __main__ -   Eval after epoch 2\n","03/06/2019 02:57:42 - INFO - __main__ -   {'loss': 0.6262003692776658, 'accuracy': 0.6839795171909291}\n","03/06/2019 02:57:42 - INFO - __main__ -   Loss on batch 0: 0.23935848474502563\n","03/06/2019 02:58:10 - INFO - __main__ -   Training loss after epoch 0.12636716785125954\n","03/06/2019 02:58:28 - INFO - __main__ -   Training accuracy after epoch 0.9934114202049781\n","03/06/2019 02:58:28 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 02:58:28 - INFO - __main__ -   Eval after epoch 3\n","03/06/2019 02:59:02 - INFO - __main__ -   {'loss': 0.9127953208463137, 'accuracy': 0.6463057790782736}\n","03/06/2019 02:59:02 - INFO - __main__ -   Loss on batch 0: 0.02154085971415043\n","03/06/2019 02:59:31 - INFO - __main__ -   Training loss after epoch 0.02832477087111667\n","03/06/2019 02:59:48 - INFO - __main__ -   Training accuracy after epoch 0.9985358711566618\n","03/06/2019 02:59:48 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 02:59:48 - INFO - __main__ -   Eval after epoch 4\n","03/06/2019 03:00:22 - INFO - __main__ -   {'loss': 1.4378880934659826, 'accuracy': 0.653986832479883}\n","03/06/2019 03:00:22 - INFO - __main__ -   Loss on batch 0: 0.0036457106471061707\n","03/06/2019 03:00:51 - INFO - __main__ -   Training loss after epoch 0.01086553887918938\n","03/06/2019 03:01:08 - INFO - __main__ -   Training accuracy after epoch 0.9948755490483162\n","03/06/2019 03:01:08 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 03:01:08 - INFO - __main__ -   Eval after epoch 5\n","03/06/2019 03:01:43 - INFO - __main__ -   {'loss': 1.705001217681308, 'accuracy': 0.6353328456474031}\n","03/06/2019 03:01:43 - INFO - __main__ -   Loss on batch 0: 0.002418987452983856\n","03/06/2019 03:02:12 - INFO - __main__ -   Training loss after epoch 0.005956014731985538\n","03/06/2019 03:02:29 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 03:02:29 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 03:02:29 - INFO - __main__ -   Eval after epoch 6\n","03/06/2019 03:03:03 - INFO - __main__ -   {'loss': 1.5193095415137534, 'accuracy': 0.6613021214337966}\n","03/06/2019 03:03:03 - INFO - __main__ -   Loss on batch 0: 0.0018668249249458313\n","03/06/2019 03:03:32 - INFO - __main__ -   Training loss after epoch 0.004497162989600626\n","03/06/2019 03:03:49 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 03:03:49 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 03:03:49 - INFO - __main__ -   Eval after epoch 7\n","03/06/2019 03:04:23 - INFO - __main__ -   {'loss': 1.578214464492576, 'accuracy': 0.6645940014630578}\n","03/06/2019 03:04:24 - INFO - __main__ -   Loss on batch 0: 0.0012650564312934875\n","03/06/2019 03:04:52 - INFO - __main__ -   Training loss after epoch 0.003207021623005181\n","03/06/2019 03:05:10 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 03:05:10 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 03:05:10 - INFO - __main__ -   Eval after epoch 8\n","03/06/2019 03:05:44 - INFO - __main__ -   {'loss': 1.6141527205012565, 'accuracy': 0.6645940014630578}\n","03/06/2019 03:05:44 - INFO - __main__ -   Loss on batch 0: 0.0013873055577278137\n","03/06/2019 03:06:13 - INFO - __main__ -   Training loss after epoch 0.0026635786458893223\n","03/06/2019 03:06:30 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 03:06:30 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 03:06:30 - INFO - __main__ -   Eval after epoch 9\n","03/06/2019 03:07:05 - INFO - __main__ -   {'loss': 1.6329478344251944, 'accuracy': 0.6653255303584492}\n","03/06/2019 03:07:05 - INFO - __main__ -   Loss on batch 0: 0.03366132080554962\n","03/06/2019 03:07:34 - INFO - __main__ -   Training loss after epoch 0.0026081282277266647\n","03/06/2019 03:07:51 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 03:07:51 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 03:07:51 - INFO - __main__ -   Eval after epoch 10\n","03/06/2019 03:08:26 - INFO - __main__ -   {'loss': 1.6375757199387218, 'accuracy': 0.6653255303584492}\n","03/06/2019 03:08:26 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n","03/06/2019 03:08:26 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n","03/06/2019 03:08:26 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmp8vzpaamc\n","03/06/2019 03:08:31 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"max_position_embeddings\": 512,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","03/06/2019 03:08:35 - INFO - pytorch_pretrained_bert.modeling -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","03/06/2019 03:08:35 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","03/06/2019 03:08:35 - INFO - __main__ -     Num examples = 1366\n","03/06/2019 03:08:35 - INFO - __main__ -     Batch size = 16\n","03/06/2019 03:08:35 - INFO - __main__ -     Num steps = 853\n","03/06/2019 03:08:36 - INFO - __main__ -   Loss on batch 0: 0.6812304258346558\n","03/06/2019 03:08:58 - INFO - __main__ -   Loss on batch 50: 0.7093636393547058\n","03/06/2019 03:09:14 - INFO - __main__ -   Training loss after epoch 0.6948271213575851\n","03/06/2019 03:09:31 - INFO - __main__ -   Training accuracy after epoch 0.5373352855051244\n","03/06/2019 03:09:31 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 03:09:31 - INFO - __main__ -   Eval after epoch 1\n","03/06/2019 03:10:05 - INFO - __main__ -   {'loss': 0.691476795562478, 'accuracy': 0.5343818580833943}\n","03/06/2019 03:10:06 - INFO - __main__ -   Loss on batch 0: 0.6913767457008362\n","03/06/2019 03:10:28 - INFO - __main__ -   Loss on batch 50: 0.618413507938385\n","03/06/2019 03:10:43 - INFO - __main__ -   Training loss after epoch 0.6838960723821507\n","03/06/2019 03:11:00 - INFO - __main__ -   Training accuracy after epoch 0.5885797950219619\n","03/06/2019 03:11:00 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 03:11:00 - INFO - __main__ -   Eval after epoch 2\n","03/06/2019 03:11:35 - INFO - __main__ -   {'loss': 0.676169580498407, 'accuracy': 0.5464520848573519}\n","03/06/2019 03:11:35 - INFO - __main__ -   Loss on batch 0: 0.625961184501648\n","03/06/2019 03:11:57 - INFO - __main__ -   Loss on batch 50: 0.4039916396141052\n","03/06/2019 03:12:13 - INFO - __main__ -   Training loss after epoch 0.5685747005911761\n","03/06/2019 03:12:30 - INFO - __main__ -   Training accuracy after epoch 0.883601756954612\n","03/06/2019 03:12:30 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 03:12:30 - INFO - __main__ -   Eval after epoch 3\n","03/06/2019 03:13:04 - INFO - __main__ -   {'loss': 0.6580900802861812, 'accuracy': 0.6638624725676664}\n","03/06/2019 03:13:04 - INFO - __main__ -   Loss on batch 0: 0.37293165922164917\n","03/06/2019 03:13:26 - INFO - __main__ -   Loss on batch 50: 0.27057406306266785\n","03/06/2019 03:13:42 - INFO - __main__ -   Training loss after epoch 0.23881101543300373\n","03/06/2019 03:13:59 - INFO - __main__ -   Training accuracy after epoch 0.9787701317715959\n","03/06/2019 03:13:59 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 03:13:59 - INFO - __main__ -   Eval after epoch 4\n","03/06/2019 03:14:33 - INFO - __main__ -   {'loss': 0.7798279880784279, 'accuracy': 0.6766642282370153}\n","03/06/2019 03:14:34 - INFO - __main__ -   Loss on batch 0: 0.02595210075378418\n","03/06/2019 03:14:56 - INFO - __main__ -   Loss on batch 50: 0.12735718488693237\n","03/06/2019 03:15:11 - INFO - __main__ -   Training loss after epoch 0.05356599594098191\n","03/06/2019 03:15:28 - INFO - __main__ -   Training accuracy after epoch 0.9948755490483162\n","03/06/2019 03:15:28 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 03:15:28 - INFO - __main__ -   Eval after epoch 5\n","03/06/2019 03:16:03 - INFO - __main__ -   {'loss': 1.1373665253090304, 'accuracy': 0.6773957571324067}\n","03/06/2019 03:16:03 - INFO - __main__ -   Loss on batch 0: 0.008885137736797333\n","03/06/2019 03:16:25 - INFO - __main__ -   Loss on batch 50: 0.003007948398590088\n","03/06/2019 03:16:41 - INFO - __main__ -   Training loss after epoch 0.01581425596635009\n","03/06/2019 03:16:58 - INFO - __main__ -   Training accuracy after epoch 0.9970717423133236\n","03/06/2019 03:16:58 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 03:16:58 - INFO - __main__ -   Eval after epoch 6\n","03/06/2019 03:17:32 - INFO - __main__ -   {'loss': 1.272306646025458, 'accuracy': 0.6865398683247989}\n","03/06/2019 03:17:32 - INFO - __main__ -   Loss on batch 0: 0.0031479299068450928\n","03/06/2019 03:17:54 - INFO - __main__ -   Loss on batch 50: 0.0018385052680969238\n","03/06/2019 03:18:10 - INFO - __main__ -   Training loss after epoch 0.009959001613910808\n","03/06/2019 03:18:27 - INFO - __main__ -   Training accuracy after epoch 0.9970717423133236\n","03/06/2019 03:18:27 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 03:18:27 - INFO - __main__ -   Eval after epoch 7\n","03/06/2019 03:19:01 - INFO - __main__ -   {'loss': 1.3487478577813437, 'accuracy': 0.6839795171909291}\n","03/06/2019 03:19:01 - INFO - __main__ -   Loss on batch 0: 0.0019232183694839478\n","03/06/2019 03:19:23 - INFO - __main__ -   Loss on batch 50: 0.001327797770500183\n","03/06/2019 03:19:39 - INFO - __main__ -   Training loss after epoch 0.009055045570062776\n","03/06/2019 03:19:56 - INFO - __main__ -   Training accuracy after epoch 0.9970717423133236\n","03/06/2019 03:19:56 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 03:19:56 - INFO - __main__ -   Eval after epoch 8\n","03/06/2019 03:20:31 - INFO - __main__ -   {'loss': 1.3971061297627383, 'accuracy': 0.6836137527432333}\n","03/06/2019 03:20:31 - INFO - __main__ -   Loss on batch 0: 0.0012676715850830078\n","03/06/2019 03:20:53 - INFO - __main__ -   Loss on batch 50: 0.001253083348274231\n","03/06/2019 03:21:09 - INFO - __main__ -   Training loss after epoch 0.008074426098975764\n","03/06/2019 03:21:26 - INFO - __main__ -   Training accuracy after epoch 0.9978038067349927\n","03/06/2019 03:21:26 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 03:21:26 - INFO - __main__ -   Eval after epoch 9\n","03/06/2019 03:22:00 - INFO - __main__ -   {'loss': 1.3928666371245717, 'accuracy': 0.681784930504755}\n","03/06/2019 03:22:00 - INFO - __main__ -   Loss on batch 0: 0.0020049065351486206\n","03/06/2019 03:22:23 - INFO - __main__ -   Loss on batch 50: 0.0017392933368682861\n","03/06/2019 03:22:38 - INFO - __main__ -   Training loss after epoch 0.006802826715080978\n","03/06/2019 03:22:55 - INFO - __main__ -   Training accuracy after epoch 0.9978038067349927\n","03/06/2019 03:22:55 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 03:22:55 - INFO - __main__ -   Eval after epoch 10\n","03/06/2019 03:23:30 - INFO - __main__ -   {'loss': 1.395956157251846, 'accuracy': 0.6806876371616679}\n","03/06/2019 03:23:30 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n","03/06/2019 03:23:30 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n","03/06/2019 03:23:30 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpd9u_z9ek\n","03/06/2019 03:23:35 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"max_position_embeddings\": 512,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","03/06/2019 03:23:40 - INFO - pytorch_pretrained_bert.modeling -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","03/06/2019 03:23:40 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","03/06/2019 03:23:40 - INFO - __main__ -     Num examples = 1366\n","03/06/2019 03:23:40 - INFO - __main__ -     Batch size = 16\n","03/06/2019 03:23:40 - INFO - __main__ -     Num steps = 853\n","03/06/2019 03:23:40 - INFO - __main__ -   Loss on batch 0: 0.6790931820869446\n","03/06/2019 03:24:02 - INFO - __main__ -   Loss on batch 50: 0.6628369688987732\n","03/06/2019 03:24:18 - INFO - __main__ -   Training loss after epoch 0.693545340798622\n","03/06/2019 03:24:36 - INFO - __main__ -   Training accuracy after epoch 0.5021961932650073\n","03/06/2019 03:24:36 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 03:24:36 - INFO - __main__ -   Eval after epoch 1\n","03/06/2019 03:25:10 - INFO - __main__ -   {'loss': 0.6945564906264461, 'accuracy': 0.49195318215069495}\n","03/06/2019 03:25:10 - INFO - __main__ -   Loss on batch 0: 0.67130047082901\n","03/06/2019 03:25:33 - INFO - __main__ -   Loss on batch 50: 0.5169621706008911\n","03/06/2019 03:25:49 - INFO - __main__ -   Training loss after epoch 0.5785238510647486\n","03/06/2019 03:26:06 - INFO - __main__ -   Training accuracy after epoch 0.9011713030746705\n","03/06/2019 03:26:06 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 03:26:06 - INFO - __main__ -   Eval after epoch 2\n","03/06/2019 03:26:40 - INFO - __main__ -   {'loss': 0.6084642964740132, 'accuracy': 0.6810534016093636}\n","03/06/2019 03:26:41 - INFO - __main__ -   Loss on batch 0: 0.2982642650604248\n","03/06/2019 03:27:03 - INFO - __main__ -   Loss on batch 50: 0.2906835079193115\n","03/06/2019 03:27:18 - INFO - __main__ -   Training loss after epoch 0.280342532625032\n","03/06/2019 03:27:36 - INFO - __main__ -   Training accuracy after epoch 0.9795021961932651\n","03/06/2019 03:27:36 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 03:27:36 - INFO - __main__ -   Eval after epoch 3\n","03/06/2019 03:28:10 - INFO - __main__ -   {'loss': 0.7454606228789618, 'accuracy': 0.6715435259692758}\n","03/06/2019 03:28:10 - INFO - __main__ -   Loss on batch 0: 0.03826858848333359\n","03/06/2019 03:28:32 - INFO - __main__ -   Loss on batch 50: 0.05561362951993942\n","03/06/2019 03:28:48 - INFO - __main__ -   Training loss after epoch 0.07793111974633364\n","03/06/2019 03:29:05 - INFO - __main__ -   Training accuracy after epoch 0.9919472913616398\n","03/06/2019 03:29:05 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 03:29:05 - INFO - __main__ -   Eval after epoch 4\n","03/06/2019 03:29:40 - INFO - __main__ -   {'loss': 1.0070829141971678, 'accuracy': 0.674835405998537}\n","03/06/2019 03:29:40 - INFO - __main__ -   Loss on batch 0: 0.008051484823226929\n","03/06/2019 03:30:02 - INFO - __main__ -   Loss on batch 50: 0.008168019354343414\n","03/06/2019 03:30:17 - INFO - __main__ -   Training loss after epoch 0.03491945237159556\n","03/06/2019 03:30:35 - INFO - __main__ -   Training accuracy after epoch 0.9948755490483162\n","03/06/2019 03:30:35 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 03:30:35 - INFO - __main__ -   Eval after epoch 5\n","03/06/2019 03:31:09 - INFO - __main__ -   {'loss': 1.2661796565665755, 'accuracy': 0.675932699341624}\n","03/06/2019 03:31:09 - INFO - __main__ -   Loss on batch 0: 0.007676325738430023\n","03/06/2019 03:31:31 - INFO - __main__ -   Loss on batch 50: 0.004723601043224335\n","03/06/2019 03:31:47 - INFO - __main__ -   Training loss after epoch 0.02368700803192549\n","03/06/2019 03:32:04 - INFO - __main__ -   Training accuracy after epoch 0.9956076134699854\n","03/06/2019 03:32:04 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 03:32:04 - INFO - __main__ -   Eval after epoch 6\n","03/06/2019 03:32:38 - INFO - __main__ -   {'loss': 1.2693143473115078, 'accuracy': 0.6766642282370153}\n","03/06/2019 03:32:38 - INFO - __main__ -   Loss on batch 0: 0.0033824145793914795\n","03/06/2019 03:33:01 - INFO - __main__ -   Loss on batch 50: 0.005877181887626648\n","03/06/2019 03:33:16 - INFO - __main__ -   Training loss after epoch 0.02264360126194566\n","03/06/2019 03:33:33 - INFO - __main__ -   Training accuracy after epoch 0.9956076134699854\n","03/06/2019 03:33:33 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 03:33:33 - INFO - __main__ -   Eval after epoch 7\n","03/06/2019 03:34:08 - INFO - __main__ -   {'loss': 1.3084439247153525, 'accuracy': 0.6726408193123629}\n","03/06/2019 03:34:08 - INFO - __main__ -   Loss on batch 0: 0.003816559910774231\n","03/06/2019 03:34:30 - INFO - __main__ -   Loss on batch 50: 0.002556145191192627\n","03/06/2019 03:34:46 - INFO - __main__ -   Training loss after epoch 0.020164172766123745\n","03/06/2019 03:35:03 - INFO - __main__ -   Training accuracy after epoch 0.9956076134699854\n","03/06/2019 03:35:03 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 03:35:03 - INFO - __main__ -   Eval after epoch 8\n","03/06/2019 03:35:37 - INFO - __main__ -   {'loss': 1.3282189015732255, 'accuracy': 0.6737381126554499}\n","03/06/2019 03:35:37 - INFO - __main__ -   Loss on batch 0: 0.0034377723932266235\n","03/06/2019 03:36:00 - INFO - __main__ -   Loss on batch 50: 0.0027872174978256226\n","03/06/2019 03:36:15 - INFO - __main__ -   Training loss after epoch 0.01792730217756227\n","03/06/2019 03:36:32 - INFO - __main__ -   Training accuracy after epoch 0.9963396778916545\n","03/06/2019 03:36:32 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 03:36:32 - INFO - __main__ -   Eval after epoch 9\n","03/06/2019 03:37:07 - INFO - __main__ -   {'loss': 1.3421312341856402, 'accuracy': 0.6733723482077542}\n","03/06/2019 03:37:07 - INFO - __main__ -   Loss on batch 0: 0.002607971429824829\n","03/06/2019 03:37:29 - INFO - __main__ -   Loss on batch 50: 0.003540933132171631\n","03/06/2019 03:37:44 - INFO - __main__ -   Training loss after epoch 0.016728129857869516\n","03/06/2019 03:38:02 - INFO - __main__ -   Training accuracy after epoch 0.9963396778916545\n","03/06/2019 03:38:02 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 03:38:02 - INFO - __main__ -   Eval after epoch 10\n","03/06/2019 03:38:36 - INFO - __main__ -   {'loss': 1.3466584779495416, 'accuracy': 0.6737381126554499}\n","03/06/2019 03:38:36 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n","03/06/2019 03:38:37 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n","03/06/2019 03:38:37 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmptnfchn0a\n","03/06/2019 03:38:41 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"max_position_embeddings\": 512,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","03/06/2019 03:38:46 - INFO - pytorch_pretrained_bert.modeling -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","03/06/2019 03:38:46 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","03/06/2019 03:38:46 - INFO - __main__ -     Num examples = 1366\n","03/06/2019 03:38:46 - INFO - __main__ -     Batch size = 16\n","03/06/2019 03:38:46 - INFO - __main__ -     Num steps = 853\n","03/06/2019 03:38:46 - INFO - __main__ -   Loss on batch 0: 0.7481062412261963\n","03/06/2019 03:39:09 - INFO - __main__ -   Loss on batch 50: 0.6097149848937988\n","03/06/2019 03:39:24 - INFO - __main__ -   Training loss after epoch 0.694123047035794\n","03/06/2019 03:39:42 - INFO - __main__ -   Training accuracy after epoch 0.6976573938506588\n","03/06/2019 03:39:42 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 03:39:42 - INFO - __main__ -   Eval after epoch 1\n","03/06/2019 03:40:16 - INFO - __main__ -   {'loss': 0.6428180399329163, 'accuracy': 0.6177761521580103}\n","03/06/2019 03:40:16 - INFO - __main__ -   Loss on batch 0: 0.6290543079376221\n","03/06/2019 03:40:39 - INFO - __main__ -   Loss on batch 50: 1.0087776184082031\n","03/06/2019 03:40:54 - INFO - __main__ -   Training loss after epoch 0.5312794736304949\n","03/06/2019 03:41:11 - INFO - __main__ -   Training accuracy after epoch 0.9341142020497804\n","03/06/2019 03:41:11 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 03:41:11 - INFO - __main__ -   Eval after epoch 2\n","03/06/2019 03:41:46 - INFO - __main__ -   {'loss': 0.6108741694411566, 'accuracy': 0.6711777615215802}\n","03/06/2019 03:41:46 - INFO - __main__ -   Loss on batch 0: 0.27195021510124207\n","03/06/2019 03:42:08 - INFO - __main__ -   Loss on batch 50: 0.3770548105239868\n","03/06/2019 03:42:24 - INFO - __main__ -   Training loss after epoch 0.19226224192006644\n","03/06/2019 03:42:41 - INFO - __main__ -   Training accuracy after epoch 0.9882869692532943\n","03/06/2019 03:42:41 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 03:42:41 - INFO - __main__ -   Eval after epoch 3\n","03/06/2019 03:43:16 - INFO - __main__ -   {'loss': 0.7995734076167262, 'accuracy': 0.6770299926847111}\n","03/06/2019 03:43:16 - INFO - __main__ -   Loss on batch 0: 0.04013873264193535\n","03/06/2019 03:43:38 - INFO - __main__ -   Loss on batch 50: 0.014148026704788208\n","03/06/2019 03:43:53 - INFO - __main__ -   Training loss after epoch 0.045180368020610755\n","03/06/2019 03:44:11 - INFO - __main__ -   Training accuracy after epoch 0.9978038067349927\n","03/06/2019 03:44:11 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 03:44:11 - INFO - __main__ -   Eval after epoch 4\n","03/06/2019 03:44:45 - INFO - __main__ -   {'loss': 1.151350490575613, 'accuracy': 0.6781272860277981}\n","03/06/2019 03:44:45 - INFO - __main__ -   Loss on batch 0: 0.0038301944732666016\n","03/06/2019 03:45:07 - INFO - __main__ -   Loss on batch 50: 0.005998335778713226\n","03/06/2019 03:45:23 - INFO - __main__ -   Training loss after epoch 0.014673788072054036\n","03/06/2019 03:45:40 - INFO - __main__ -   Training accuracy after epoch 0.9985358711566618\n","03/06/2019 03:45:40 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 03:45:40 - INFO - __main__ -   Eval after epoch 5\n","03/06/2019 03:46:14 - INFO - __main__ -   {'loss': 1.2667850020319917, 'accuracy': 0.6825164594001463}\n","03/06/2019 03:46:14 - INFO - __main__ -   Loss on batch 0: 0.0029302388429641724\n","03/06/2019 03:46:36 - INFO - __main__ -   Loss on batch 50: 0.0021111220121383667\n","03/06/2019 03:46:52 - INFO - __main__ -   Training loss after epoch 0.006149700951091078\n","03/06/2019 03:47:09 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 03:47:09 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 03:47:09 - INFO - __main__ -   Eval after epoch 6\n","03/06/2019 03:47:44 - INFO - __main__ -   {'loss': 1.3856418645659159, 'accuracy': 0.6697147037307973}\n","03/06/2019 03:47:44 - INFO - __main__ -   Loss on batch 0: 0.002056986093521118\n","03/06/2019 03:48:06 - INFO - __main__ -   Loss on batch 50: 0.001256003975868225\n","03/06/2019 03:48:21 - INFO - __main__ -   Training loss after epoch 0.0033247635028389997\n","03/06/2019 03:48:39 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 03:48:39 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 03:48:39 - INFO - __main__ -   Eval after epoch 7\n","03/06/2019 03:49:13 - INFO - __main__ -   {'loss': 1.4244319796562195, 'accuracy': 0.6719092904169714}\n","03/06/2019 03:49:13 - INFO - __main__ -   Loss on batch 0: 0.0016185194253921509\n","03/06/2019 03:49:35 - INFO - __main__ -   Loss on batch 50: 0.0017803311347961426\n","03/06/2019 03:49:51 - INFO - __main__ -   Training loss after epoch 0.0026812143407242243\n","03/06/2019 03:50:08 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 03:50:08 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 03:50:08 - INFO - __main__ -   Eval after epoch 8\n","03/06/2019 03:50:43 - INFO - __main__ -   {'loss': 1.44691067240959, 'accuracy': 0.674835405998537}\n","03/06/2019 03:50:43 - INFO - __main__ -   Loss on batch 0: 0.0016629993915557861\n","03/06/2019 03:51:05 - INFO - __main__ -   Loss on batch 50: 0.0010106563568115234\n","03/06/2019 03:51:20 - INFO - __main__ -   Training loss after epoch 0.002488671087248381\n","03/06/2019 03:51:38 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 03:51:38 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 03:51:38 - INFO - __main__ -   Eval after epoch 9\n","03/06/2019 03:52:12 - INFO - __main__ -   {'loss': 1.4656084699686183, 'accuracy': 0.6752011704462326}\n","03/06/2019 03:52:12 - INFO - __main__ -   Loss on batch 0: 0.0016389936208724976\n","03/06/2019 03:52:34 - INFO - __main__ -   Loss on batch 50: 0.0010655969381332397\n","03/06/2019 03:52:50 - INFO - __main__ -   Training loss after epoch 0.002291787964654653\n","03/06/2019 03:53:07 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 03:53:07 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 03:53:07 - INFO - __main__ -   Eval after epoch 10\n","03/06/2019 03:53:42 - INFO - __main__ -   {'loss': 1.470183716263882, 'accuracy': 0.674835405998537}\n","03/06/2019 03:53:42 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n","03/06/2019 03:53:42 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n","03/06/2019 03:53:42 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpefq2k4dh\n","03/06/2019 03:53:47 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"max_position_embeddings\": 512,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","03/06/2019 03:53:51 - INFO - pytorch_pretrained_bert.modeling -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","03/06/2019 03:53:51 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","03/06/2019 03:53:51 - INFO - __main__ -     Num examples = 1366\n","03/06/2019 03:53:51 - INFO - __main__ -     Batch size = 16\n","03/06/2019 03:53:51 - INFO - __main__ -     Num steps = 853\n","03/06/2019 03:53:51 - INFO - __main__ -   Loss on batch 0: 0.7336305975914001\n","03/06/2019 03:54:14 - INFO - __main__ -   Loss on batch 50: 0.7788159847259521\n","03/06/2019 03:54:30 - INFO - __main__ -   Training loss after epoch 0.6851581335067749\n","03/06/2019 03:54:47 - INFO - __main__ -   Training accuracy after epoch 0.6705710102489019\n","03/06/2019 03:54:47 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 03:54:47 - INFO - __main__ -   Eval after epoch 1\n","03/06/2019 03:55:22 - INFO - __main__ -   {'loss': 0.6786654993545177, 'accuracy': 0.583394294074616}\n","03/06/2019 03:55:22 - INFO - __main__ -   Loss on batch 0: 0.7889773845672607\n","03/06/2019 03:55:44 - INFO - __main__ -   Loss on batch 50: 0.4257030487060547\n","03/06/2019 03:56:00 - INFO - __main__ -   Training loss after epoch 0.5068356017040652\n","03/06/2019 03:56:17 - INFO - __main__ -   Training accuracy after epoch 0.8257686676427526\n","03/06/2019 03:56:17 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 03:56:17 - INFO - __main__ -   Eval after epoch 2\n","03/06/2019 03:56:51 - INFO - __main__ -   {'loss': 0.8188525635835736, 'accuracy': 0.6254572055596196}\n","03/06/2019 03:56:51 - INFO - __main__ -   Loss on batch 0: 0.22433403134346008\n","03/06/2019 03:57:14 - INFO - __main__ -   Loss on batch 50: 0.03632093966007233\n","03/06/2019 03:57:29 - INFO - __main__ -   Training loss after epoch 0.2005244814682492\n","03/06/2019 03:57:46 - INFO - __main__ -   Training accuracy after epoch 0.9890190336749634\n","03/06/2019 03:57:46 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 03:57:46 - INFO - __main__ -   Eval after epoch 3\n","03/06/2019 03:58:21 - INFO - __main__ -   {'loss': 0.861722970771235, 'accuracy': 0.6682516459400146}\n","03/06/2019 03:58:21 - INFO - __main__ -   Loss on batch 0: 0.027473866939544678\n","03/06/2019 03:58:43 - INFO - __main__ -   Loss on batch 50: 0.00916239619255066\n","03/06/2019 03:58:59 - INFO - __main__ -   Training loss after epoch 0.04550871726796897\n","03/06/2019 03:59:16 - INFO - __main__ -   Training accuracy after epoch 0.9970717423133236\n","03/06/2019 03:59:16 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 03:59:16 - INFO - __main__ -   Eval after epoch 4\n","03/06/2019 03:59:50 - INFO - __main__ -   {'loss': 1.0693906552569812, 'accuracy': 0.6777615215801024}\n","03/06/2019 03:59:51 - INFO - __main__ -   Loss on batch 0: 0.009773008525371552\n","03/06/2019 04:00:13 - INFO - __main__ -   Loss on batch 50: 0.006084039807319641\n","03/06/2019 04:00:28 - INFO - __main__ -   Training loss after epoch 0.017352222026390737\n","03/06/2019 04:00:46 - INFO - __main__ -   Training accuracy after epoch 0.9978038067349927\n","03/06/2019 04:00:46 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 04:00:46 - INFO - __main__ -   Eval after epoch 5\n","03/06/2019 04:01:20 - INFO - __main__ -   {'loss': 1.2212166758470757, 'accuracy': 0.6667885881492319}\n","03/06/2019 04:01:20 - INFO - __main__ -   Loss on batch 0: 0.004018649458885193\n","03/06/2019 04:01:42 - INFO - __main__ -   Loss on batch 50: 0.0031935274600982666\n","03/06/2019 04:01:58 - INFO - __main__ -   Training loss after epoch 0.01300917828704642\n","03/06/2019 04:02:15 - INFO - __main__ -   Training accuracy after epoch 0.9978038067349927\n","03/06/2019 04:02:15 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 04:02:15 - INFO - __main__ -   Eval after epoch 6\n","03/06/2019 04:02:50 - INFO - __main__ -   {'loss': 1.2585330896599347, 'accuracy': 0.675932699341624}\n","03/06/2019 04:02:50 - INFO - __main__ -   Loss on batch 0: 0.0025413185358047485\n","03/06/2019 04:03:12 - INFO - __main__ -   Loss on batch 50: 0.0030781328678131104\n","03/06/2019 04:03:27 - INFO - __main__ -   Training loss after epoch 0.011755477017073263\n","03/06/2019 04:03:44 - INFO - __main__ -   Training accuracy after epoch 0.9978038067349927\n","03/06/2019 04:03:44 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 04:03:44 - INFO - __main__ -   Eval after epoch 7\n","03/06/2019 04:04:19 - INFO - __main__ -   {'loss': 1.2706978646821754, 'accuracy': 0.6777615215801024}\n","03/06/2019 04:04:19 - INFO - __main__ -   Loss on batch 0: 0.0020453929901123047\n","03/06/2019 04:04:41 - INFO - __main__ -   Loss on batch 50: 0.002006709575653076\n","03/06/2019 04:04:57 - INFO - __main__ -   Training loss after epoch 0.005628509113976602\n","03/06/2019 04:05:14 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 04:05:14 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 04:05:14 - INFO - __main__ -   Eval after epoch 8\n","03/06/2019 04:05:48 - INFO - __main__ -   {'loss': 1.3014289868432423, 'accuracy': 0.6722750548646672}\n","03/06/2019 04:05:48 - INFO - __main__ -   Loss on batch 0: 0.002124696969985962\n","03/06/2019 04:06:10 - INFO - __main__ -   Loss on batch 50: 0.0020746737718582153\n","03/06/2019 04:06:26 - INFO - __main__ -   Training loss after epoch 0.003250466927691081\n","03/06/2019 04:06:43 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 04:06:43 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 04:06:43 - INFO - __main__ -   Eval after epoch 9\n","03/06/2019 04:07:18 - INFO - __main__ -   {'loss': 1.3130525863447855, 'accuracy': 0.6741038771031456}\n","03/06/2019 04:07:18 - INFO - __main__ -   Loss on batch 0: 0.0018624663352966309\n","03/06/2019 04:07:40 - INFO - __main__ -   Loss on batch 50: 0.0019717812538146973\n","03/06/2019 04:07:56 - INFO - __main__ -   Training loss after epoch 0.0030856165428494297\n","03/06/2019 04:08:13 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 04:08:13 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 04:08:13 - INFO - __main__ -   Eval after epoch 10\n","03/06/2019 04:08:48 - INFO - __main__ -   {'loss': 1.315654631963996, 'accuracy': 0.6741038771031456}\n","03/06/2019 04:08:48 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n","03/06/2019 04:08:48 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n","03/06/2019 04:08:48 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmps5q2huge\n","03/06/2019 04:08:53 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"max_position_embeddings\": 512,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","03/06/2019 04:08:58 - INFO - pytorch_pretrained_bert.modeling -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","03/06/2019 04:08:58 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","03/06/2019 04:08:58 - INFO - __main__ -     Num examples = 1366\n","03/06/2019 04:08:58 - INFO - __main__ -     Batch size = 16\n","03/06/2019 04:08:58 - INFO - __main__ -     Num steps = 853\n","03/06/2019 04:08:58 - INFO - __main__ -   Loss on batch 0: 0.686045229434967\n","03/06/2019 04:09:20 - INFO - __main__ -   Loss on batch 50: 0.650130033493042\n","03/06/2019 04:09:36 - INFO - __main__ -   Training loss after epoch 0.683516227228697\n","03/06/2019 04:09:54 - INFO - __main__ -   Training accuracy after epoch 0.7174231332357247\n","03/06/2019 04:09:54 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 04:09:54 - INFO - __main__ -   Eval after epoch 1\n","03/06/2019 04:10:28 - INFO - __main__ -   {'loss': 0.6395527013512545, 'accuracy': 0.6104608632040965}\n","03/06/2019 04:10:28 - INFO - __main__ -   Loss on batch 0: 0.5442987680435181\n","03/06/2019 04:10:51 - INFO - __main__ -   Loss on batch 50: 0.48432567715644836\n","03/06/2019 04:11:06 - INFO - __main__ -   Training loss after epoch 0.5152830938960231\n","03/06/2019 04:11:24 - INFO - __main__ -   Training accuracy after epoch 0.9509516837481699\n","03/06/2019 04:11:24 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 04:11:24 - INFO - __main__ -   Eval after epoch 2\n","03/06/2019 04:11:58 - INFO - __main__ -   {'loss': 0.6181726375984591, 'accuracy': 0.681784930504755}\n","03/06/2019 04:11:58 - INFO - __main__ -   Loss on batch 0: 0.23006734251976013\n","03/06/2019 04:12:20 - INFO - __main__ -   Loss on batch 50: 0.1795736700296402\n","03/06/2019 04:12:36 - INFO - __main__ -   Training loss after epoch 0.17655778667607971\n","03/06/2019 04:12:53 - INFO - __main__ -   Training accuracy after epoch 0.9926793557833089\n","03/06/2019 04:12:53 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 04:12:53 - INFO - __main__ -   Eval after epoch 3\n","03/06/2019 04:13:28 - INFO - __main__ -   {'loss': 0.8898320159939832, 'accuracy': 0.6700804681784931}\n","03/06/2019 04:13:28 - INFO - __main__ -   Loss on batch 0: 0.04555311053991318\n","03/06/2019 04:13:50 - INFO - __main__ -   Loss on batch 50: 0.00787103921175003\n","03/06/2019 04:14:06 - INFO - __main__ -   Training loss after epoch 0.041827222440651686\n","03/06/2019 04:14:23 - INFO - __main__ -   Training accuracy after epoch 0.9963396778916545\n","03/06/2019 04:14:23 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 04:14:23 - INFO - __main__ -   Eval after epoch 4\n","03/06/2019 04:14:57 - INFO - __main__ -   {'loss': 1.0832446227933086, 'accuracy': 0.6770299926847111}\n","03/06/2019 04:14:57 - INFO - __main__ -   Loss on batch 0: 0.005284801125526428\n","03/06/2019 04:15:19 - INFO - __main__ -   Loss on batch 50: 0.003115549683570862\n","03/06/2019 04:15:35 - INFO - __main__ -   Training loss after epoch 0.014665053878520984\n","03/06/2019 04:15:52 - INFO - __main__ -   Training accuracy after epoch 0.9985358711566618\n","03/06/2019 04:15:52 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 04:15:52 - INFO - __main__ -   Eval after epoch 5\n","03/06/2019 04:16:27 - INFO - __main__ -   {'loss': 1.2160000884255697, 'accuracy': 0.6762984637893197}\n","03/06/2019 04:16:27 - INFO - __main__ -   Loss on batch 0: 0.0027061104774475098\n","03/06/2019 04:16:49 - INFO - __main__ -   Loss on batch 50: 0.002248421311378479\n","03/06/2019 04:17:04 - INFO - __main__ -   Training loss after epoch 0.008856331983711137\n","03/06/2019 04:17:22 - INFO - __main__ -   Training accuracy after epoch 0.9985358711566618\n","03/06/2019 04:17:22 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 04:17:22 - INFO - __main__ -   Eval after epoch 6\n","03/06/2019 04:17:56 - INFO - __main__ -   {'loss': 1.2943312705949295, 'accuracy': 0.6806876371616679}\n","03/06/2019 04:17:56 - INFO - __main__ -   Loss on batch 0: 0.002437181770801544\n","03/06/2019 04:18:18 - INFO - __main__ -   Loss on batch 50: 0.001825869083404541\n","03/06/2019 04:18:34 - INFO - __main__ -   Training loss after epoch 0.007210819693661274\n","03/06/2019 04:18:51 - INFO - __main__ -   Training accuracy after epoch 0.9985358711566618\n","03/06/2019 04:18:51 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 04:18:51 - INFO - __main__ -   Eval after epoch 7\n","03/06/2019 04:19:25 - INFO - __main__ -   {'loss': 1.3412136463231819, 'accuracy': 0.6825164594001463}\n","03/06/2019 04:19:26 - INFO - __main__ -   Loss on batch 0: 0.002409234642982483\n","03/06/2019 04:19:48 - INFO - __main__ -   Loss on batch 50: 0.0023643970489501953\n","03/06/2019 04:20:03 - INFO - __main__ -   Training loss after epoch 0.005930514897891256\n","03/06/2019 04:20:20 - INFO - __main__ -   Training accuracy after epoch 0.9985358711566618\n","03/06/2019 04:20:20 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 04:20:20 - INFO - __main__ -   Eval after epoch 8\n","03/06/2019 04:20:55 - INFO - __main__ -   {'loss': 1.3528638703878535, 'accuracy': 0.6832479882955377}\n","03/06/2019 04:20:55 - INFO - __main__ -   Loss on batch 0: 0.002383604645729065\n","03/06/2019 04:21:17 - INFO - __main__ -   Loss on batch 50: 0.0015768855810165405\n","03/06/2019 04:21:33 - INFO - __main__ -   Training loss after epoch 0.004843434297241444\n","03/06/2019 04:21:50 - INFO - __main__ -   Training accuracy after epoch 0.9985358711566618\n","03/06/2019 04:21:50 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 04:21:50 - INFO - __main__ -   Eval after epoch 9\n","03/06/2019 04:22:25 - INFO - __main__ -   {'loss': 1.3784192752006441, 'accuracy': 0.6814191660570592}\n","03/06/2019 04:22:25 - INFO - __main__ -   Loss on batch 0: 0.0015703141689300537\n","03/06/2019 04:22:47 - INFO - __main__ -   Loss on batch 50: 0.001484706997871399\n","03/06/2019 04:23:03 - INFO - __main__ -   Training loss after epoch 0.004271749313650003\n","03/06/2019 04:23:20 - INFO - __main__ -   Training accuracy after epoch 0.9985358711566618\n","03/06/2019 04:23:20 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 04:23:20 - INFO - __main__ -   Eval after epoch 10\n","03/06/2019 04:23:55 - INFO - __main__ -   {'loss': 1.383176067540812, 'accuracy': 0.6832479882955377}\n","03/06/2019 04:23:55 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n","03/06/2019 04:23:55 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n","03/06/2019 04:23:55 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpxmi_ndkz\n","03/06/2019 04:24:00 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"max_position_embeddings\": 512,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","03/06/2019 04:24:04 - INFO - pytorch_pretrained_bert.modeling -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","03/06/2019 04:24:04 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","03/06/2019 04:24:04 - INFO - __main__ -     Num examples = 1366\n","03/06/2019 04:24:04 - INFO - __main__ -     Batch size = 32\n","03/06/2019 04:24:04 - INFO - __main__ -     Num steps = 426\n","03/06/2019 04:24:05 - INFO - __main__ -   Loss on batch 0: 0.7214308977127075\n","03/06/2019 04:24:34 - INFO - __main__ -   Training loss after epoch 0.6800499967364377\n","03/06/2019 04:24:51 - INFO - __main__ -   Training accuracy after epoch 0.6654465592972182\n","03/06/2019 04:24:51 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 04:24:51 - INFO - __main__ -   Eval after epoch 1\n","03/06/2019 04:25:26 - INFO - __main__ -   {'loss': 0.6481475566708764, 'accuracy': 0.6170446232626189}\n","03/06/2019 04:25:26 - INFO - __main__ -   Loss on batch 0: 0.5274595618247986\n","03/06/2019 04:25:55 - INFO - __main__ -   Training loss after epoch 0.550072769092959\n","03/06/2019 04:26:12 - INFO - __main__ -   Training accuracy after epoch 0.9363103953147877\n","03/06/2019 04:26:12 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 04:26:12 - INFO - __main__ -   Eval after epoch 2\n","03/06/2019 04:26:47 - INFO - __main__ -   {'loss': 0.6935788580151492, 'accuracy': 0.6576444769568398}\n","03/06/2019 04:26:47 - INFO - __main__ -   Loss on batch 0: 0.21628041565418243\n","03/06/2019 04:27:16 - INFO - __main__ -   Training loss after epoch 0.20206554649874223\n","03/06/2019 04:27:33 - INFO - __main__ -   Training accuracy after epoch 0.9897510980966325\n","03/06/2019 04:27:33 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 04:27:33 - INFO - __main__ -   Eval after epoch 3\n","03/06/2019 04:28:08 - INFO - __main__ -   {'loss': 0.8019954451294833, 'accuracy': 0.6638624725676664}\n","03/06/2019 04:28:08 - INFO - __main__ -   Loss on batch 0: 0.04433547332882881\n","03/06/2019 04:28:37 - INFO - __main__ -   Training loss after epoch 0.046820309511277566\n","03/06/2019 04:28:54 - INFO - __main__ -   Training accuracy after epoch 0.9948755490483162\n","03/06/2019 04:28:54 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 04:28:54 - INFO - __main__ -   Eval after epoch 4\n","03/06/2019 04:29:28 - INFO - __main__ -   {'loss': 1.359759852636692, 'accuracy': 0.65508412582297}\n","03/06/2019 04:29:28 - INFO - __main__ -   Loss on batch 0: 0.005708899348974228\n","03/06/2019 04:29:57 - INFO - __main__ -   Training loss after epoch 0.01640324599954278\n","03/06/2019 04:30:14 - INFO - __main__ -   Training accuracy after epoch 0.9985358711566618\n","03/06/2019 04:30:14 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 04:30:14 - INFO - __main__ -   Eval after epoch 5\n","03/06/2019 04:30:49 - INFO - __main__ -   {'loss': 1.3468309883461442, 'accuracy': 0.6605705925384052}\n","03/06/2019 04:30:49 - INFO - __main__ -   Loss on batch 0: 0.00274658203125\n","03/06/2019 04:31:18 - INFO - __main__ -   Training loss after epoch 0.004677497944253129\n","03/06/2019 04:31:35 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 04:31:35 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 04:31:35 - INFO - __main__ -   Eval after epoch 6\n","03/06/2019 04:32:10 - INFO - __main__ -   {'loss': 1.5068423498508543, 'accuracy': 0.6634967081199707}\n","03/06/2019 04:32:10 - INFO - __main__ -   Loss on batch 0: 0.00248032808303833\n","03/06/2019 04:32:39 - INFO - __main__ -   Training loss after epoch 0.0031057338522703843\n","03/06/2019 04:32:56 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 04:32:56 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 04:32:56 - INFO - __main__ -   Eval after epoch 7\n","03/06/2019 04:33:31 - INFO - __main__ -   {'loss': 1.5666304681190224, 'accuracy': 0.6638624725676664}\n","03/06/2019 04:33:31 - INFO - __main__ -   Loss on batch 0: 0.0018095150589942932\n","03/06/2019 04:34:00 - INFO - __main__ -   Training loss after epoch 0.00282441746703414\n","03/06/2019 04:34:17 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 04:34:17 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 04:34:17 - INFO - __main__ -   Eval after epoch 8\n","03/06/2019 04:34:51 - INFO - __main__ -   {'loss': 1.5992008530816366, 'accuracy': 0.6675201170446232}\n","03/06/2019 04:34:51 - INFO - __main__ -   Loss on batch 0: 0.001195654273033142\n","03/06/2019 04:35:20 - INFO - __main__ -   Training loss after epoch 0.0025026484008142075\n","03/06/2019 04:35:37 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 04:35:37 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 04:35:37 - INFO - __main__ -   Eval after epoch 9\n","03/06/2019 04:36:11 - INFO - __main__ -   {'loss': 1.6187503025975338, 'accuracy': 0.6675201170446232}\n","03/06/2019 04:36:12 - INFO - __main__ -   Loss on batch 0: 0.0011204853653907776\n","03/06/2019 04:36:40 - INFO - __main__ -   Training loss after epoch 0.0023903687766125034\n","03/06/2019 04:36:58 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 04:36:58 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 04:36:58 - INFO - __main__ -   Eval after epoch 10\n","03/06/2019 04:37:32 - INFO - __main__ -   {'loss': 1.6202570844528288, 'accuracy': 0.6671543525969276}\n","03/06/2019 04:37:32 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n","03/06/2019 04:37:33 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n","03/06/2019 04:37:33 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpl_ii05_3\n","03/06/2019 04:37:37 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"max_position_embeddings\": 512,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","03/06/2019 04:37:42 - INFO - pytorch_pretrained_bert.modeling -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","03/06/2019 04:37:42 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","03/06/2019 04:37:42 - INFO - __main__ -     Num examples = 1366\n","03/06/2019 04:37:42 - INFO - __main__ -     Batch size = 32\n","03/06/2019 04:37:42 - INFO - __main__ -     Num steps = 426\n","03/06/2019 04:37:42 - INFO - __main__ -   Loss on batch 0: 0.8143405914306641\n","03/06/2019 04:38:11 - INFO - __main__ -   Training loss after epoch 0.7048596615015075\n","03/06/2019 04:38:29 - INFO - __main__ -   Training accuracy after epoch 0.6017569546120058\n","03/06/2019 04:38:29 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 04:38:29 - INFO - __main__ -   Eval after epoch 1\n","03/06/2019 04:39:03 - INFO - __main__ -   {'loss': 0.6705627476060113, 'accuracy': 0.5709583028529627}\n","03/06/2019 04:39:03 - INFO - __main__ -   Loss on batch 0: 0.6565209031105042\n","03/06/2019 04:39:32 - INFO - __main__ -   Training loss after epoch 0.5905724784662557\n","03/06/2019 04:39:50 - INFO - __main__ -   Training accuracy after epoch 0.8967789165446559\n","03/06/2019 04:39:50 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 04:39:50 - INFO - __main__ -   Eval after epoch 2\n","03/06/2019 04:40:24 - INFO - __main__ -   {'loss': 0.6227643479441487, 'accuracy': 0.662033650329188}\n","03/06/2019 04:40:24 - INFO - __main__ -   Loss on batch 0: 0.4798078238964081\n","03/06/2019 04:40:53 - INFO - __main__ -   Training loss after epoch 0.2282210363205089\n","03/06/2019 04:41:11 - INFO - __main__ -   Training accuracy after epoch 0.986822840409956\n","03/06/2019 04:41:11 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 04:41:11 - INFO - __main__ -   Eval after epoch 3\n","03/06/2019 04:41:45 - INFO - __main__ -   {'loss': 0.8039311506720477, 'accuracy': 0.6766642282370153}\n","03/06/2019 04:41:45 - INFO - __main__ -   Loss on batch 0: 0.2369534969329834\n","03/06/2019 04:42:14 - INFO - __main__ -   Training loss after epoch 0.05268456297385138\n","03/06/2019 04:42:32 - INFO - __main__ -   Training accuracy after epoch 0.9956076134699854\n","03/06/2019 04:42:32 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 04:42:32 - INFO - __main__ -   Eval after epoch 4\n","03/06/2019 04:43:06 - INFO - __main__ -   {'loss': 1.1760896849770879, 'accuracy': 0.6675201170446232}\n","03/06/2019 04:43:06 - INFO - __main__ -   Loss on batch 0: 0.16757449507713318\n","03/06/2019 04:43:35 - INFO - __main__ -   Training loss after epoch 0.021262768601868733\n","03/06/2019 04:43:52 - INFO - __main__ -   Training accuracy after epoch 0.9978038067349927\n","03/06/2019 04:43:52 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 04:43:52 - INFO - __main__ -   Eval after epoch 5\n","03/06/2019 04:44:27 - INFO - __main__ -   {'loss': 1.369666793318682, 'accuracy': 0.6667885881492319}\n","03/06/2019 04:44:27 - INFO - __main__ -   Loss on batch 0: 0.00554773211479187\n","03/06/2019 04:44:56 - INFO - __main__ -   Training loss after epoch 0.012506421482147173\n","03/06/2019 04:45:13 - INFO - __main__ -   Training accuracy after epoch 0.9978038067349927\n","03/06/2019 04:45:13 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 04:45:13 - INFO - __main__ -   Eval after epoch 6\n","03/06/2019 04:45:47 - INFO - __main__ -   {'loss': 1.3025839401538981, 'accuracy': 0.6792245793708851}\n","03/06/2019 04:45:47 - INFO - __main__ -   Loss on batch 0: 0.003217726945877075\n","03/06/2019 04:46:16 - INFO - __main__ -   Training loss after epoch 0.011263603295827674\n","03/06/2019 04:46:33 - INFO - __main__ -   Training accuracy after epoch 0.9978038067349927\n","03/06/2019 04:46:33 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 04:46:33 - INFO - __main__ -   Eval after epoch 7\n","03/06/2019 04:47:08 - INFO - __main__ -   {'loss': 1.3331674465606378, 'accuracy': 0.6799561082662765}\n","03/06/2019 04:47:08 - INFO - __main__ -   Loss on batch 0: 0.002628736197948456\n","03/06/2019 04:47:37 - INFO - __main__ -   Training loss after epoch 0.00988974133073244\n","03/06/2019 04:47:54 - INFO - __main__ -   Training accuracy after epoch 0.9978038067349927\n","03/06/2019 04:47:54 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 04:47:54 - INFO - __main__ -   Eval after epoch 8\n","03/06/2019 04:48:28 - INFO - __main__ -   {'loss': 1.3583814584931662, 'accuracy': 0.6795903438185809}\n","03/06/2019 04:48:28 - INFO - __main__ -   Loss on batch 0: 0.14942988753318787\n","03/06/2019 04:48:57 - INFO - __main__ -   Training loss after epoch 0.0076119767415315604\n","03/06/2019 04:49:14 - INFO - __main__ -   Training accuracy after epoch 0.9985358711566618\n","03/06/2019 04:49:14 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 04:49:14 - INFO - __main__ -   Eval after epoch 9\n","03/06/2019 04:49:49 - INFO - __main__ -   {'loss': 1.3700677655463995, 'accuracy': 0.6810534016093636}\n","03/06/2019 04:49:49 - INFO - __main__ -   Loss on batch 0: 0.002270035445690155\n","03/06/2019 04:50:18 - INFO - __main__ -   Training loss after epoch 0.007177485272201688\n","03/06/2019 04:50:35 - INFO - __main__ -   Training accuracy after epoch 0.9985358711566618\n","03/06/2019 04:50:35 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 04:50:35 - INFO - __main__ -   Eval after epoch 10\n","03/06/2019 04:51:09 - INFO - __main__ -   {'loss': 1.3748001300318295, 'accuracy': 0.6803218727139722}\n","03/06/2019 04:51:09 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n","03/06/2019 04:51:10 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n","03/06/2019 04:51:10 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpwu7acsg_\n","03/06/2019 04:51:14 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"max_position_embeddings\": 512,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","03/06/2019 04:51:19 - INFO - pytorch_pretrained_bert.modeling -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","03/06/2019 04:51:19 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","03/06/2019 04:51:19 - INFO - __main__ -     Num examples = 1366\n","03/06/2019 04:51:19 - INFO - __main__ -     Batch size = 32\n","03/06/2019 04:51:19 - INFO - __main__ -     Num steps = 426\n","03/06/2019 04:51:19 - INFO - __main__ -   Loss on batch 0: 0.7045347094535828\n","03/06/2019 04:51:48 - INFO - __main__ -   Training loss after epoch 0.6937217379725257\n","03/06/2019 04:52:06 - INFO - __main__ -   Training accuracy after epoch 0.7437774524158126\n","03/06/2019 04:52:06 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 04:52:06 - INFO - __main__ -   Eval after epoch 1\n","03/06/2019 04:52:40 - INFO - __main__ -   {'loss': 0.6368477704913117, 'accuracy': 0.6302121433796635}\n","03/06/2019 04:52:40 - INFO - __main__ -   Loss on batch 0: 0.5856986045837402\n","03/06/2019 04:53:09 - INFO - __main__ -   Training loss after epoch 0.5200873675734498\n","03/06/2019 04:53:26 - INFO - __main__ -   Training accuracy after epoch 0.9538799414348462\n","03/06/2019 04:53:26 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 04:53:26 - INFO - __main__ -   Eval after epoch 2\n","03/06/2019 04:54:01 - INFO - __main__ -   {'loss': 0.6464080179846564, 'accuracy': 0.667885881492319}\n","03/06/2019 04:54:01 - INFO - __main__ -   Loss on batch 0: 0.23588399589061737\n","03/06/2019 04:54:30 - INFO - __main__ -   Training loss after epoch 0.17119061881892902\n","03/06/2019 04:54:47 - INFO - __main__ -   Training accuracy after epoch 0.9897510980966325\n","03/06/2019 04:54:47 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 04:54:47 - INFO - __main__ -   Eval after epoch 3\n","03/06/2019 04:55:21 - INFO - __main__ -   {'loss': 0.8830396560735481, 'accuracy': 0.6525237746891002}\n","03/06/2019 04:55:22 - INFO - __main__ -   Loss on batch 0: 0.029286570847034454\n","03/06/2019 04:55:50 - INFO - __main__ -   Training loss after epoch 0.035164606053555425\n","03/06/2019 04:56:08 - INFO - __main__ -   Training accuracy after epoch 0.9985358711566618\n","03/06/2019 04:56:08 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 04:56:08 - INFO - __main__ -   Eval after epoch 4\n","03/06/2019 04:56:42 - INFO - __main__ -   {'loss': 1.155134489369947, 'accuracy': 0.662033650329188}\n","03/06/2019 04:56:42 - INFO - __main__ -   Loss on batch 0: 0.005768977105617523\n","03/06/2019 04:57:11 - INFO - __main__ -   Training loss after epoch 0.011735879361282947\n","03/06/2019 04:57:28 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 04:57:28 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 04:57:28 - INFO - __main__ -   Eval after epoch 5\n","03/06/2019 04:58:03 - INFO - __main__ -   {'loss': 1.2917660599531129, 'accuracy': 0.6682516459400146}\n","03/06/2019 04:58:03 - INFO - __main__ -   Loss on batch 0: 0.002503722906112671\n","03/06/2019 04:58:32 - INFO - __main__ -   Training loss after epoch 0.003950014128349721\n","03/06/2019 04:58:49 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 04:58:49 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 04:58:49 - INFO - __main__ -   Eval after epoch 6\n","03/06/2019 04:59:23 - INFO - __main__ -   {'loss': 1.3807644109393276, 'accuracy': 0.6697147037307973}\n","03/06/2019 04:59:24 - INFO - __main__ -   Loss on batch 0: 0.0015895813703536987\n","03/06/2019 04:59:52 - INFO - __main__ -   Training loss after epoch 0.00309327568014174\n","03/06/2019 05:00:09 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 05:00:09 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 05:00:10 - INFO - __main__ -   Eval after epoch 7\n","03/06/2019 05:00:44 - INFO - __main__ -   {'loss': 1.4303519504014837, 'accuracy': 0.6697147037307973}\n","03/06/2019 05:00:44 - INFO - __main__ -   Loss on batch 0: 0.0024417974054813385\n","03/06/2019 05:01:13 - INFO - __main__ -   Training loss after epoch 0.002659833719304135\n","03/06/2019 05:01:30 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 05:01:30 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 05:01:30 - INFO - __main__ -   Eval after epoch 8\n","03/06/2019 05:02:04 - INFO - __main__ -   {'loss': 1.4618330244408098, 'accuracy': 0.667885881492319}\n","03/06/2019 05:02:05 - INFO - __main__ -   Loss on batch 0: 0.0011787787079811096\n","03/06/2019 05:02:33 - INFO - __main__ -   Training loss after epoch 0.0023443011355824593\n","03/06/2019 05:02:51 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 05:02:51 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 05:02:51 - INFO - __main__ -   Eval after epoch 9\n","03/06/2019 05:03:25 - INFO - __main__ -   {'loss': 1.4777815473634144, 'accuracy': 0.6664228237015362}\n","03/06/2019 05:03:25 - INFO - __main__ -   Loss on batch 0: 0.0009718835353851318\n","03/06/2019 05:03:54 - INFO - __main__ -   Training loss after epoch 0.0022375602911356403\n","03/06/2019 05:04:11 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 05:04:11 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 05:04:11 - INFO - __main__ -   Eval after epoch 10\n","03/06/2019 05:04:45 - INFO - __main__ -   {'loss': 1.4814209591510683, 'accuracy': 0.6660570592538405}\n","03/06/2019 05:04:45 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n","03/06/2019 05:04:46 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n","03/06/2019 05:04:46 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmps5pxqtrh\n","03/06/2019 05:04:50 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"max_position_embeddings\": 512,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","03/06/2019 05:04:55 - INFO - pytorch_pretrained_bert.modeling -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","03/06/2019 05:04:55 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","03/06/2019 05:04:55 - INFO - __main__ -     Num examples = 1366\n","03/06/2019 05:04:55 - INFO - __main__ -     Batch size = 32\n","03/06/2019 05:04:55 - INFO - __main__ -     Num steps = 426\n","03/06/2019 05:04:55 - INFO - __main__ -   Loss on batch 0: 0.763346254825592\n","03/06/2019 05:05:24 - INFO - __main__ -   Training loss after epoch 0.684653875439666\n","03/06/2019 05:05:42 - INFO - __main__ -   Training accuracy after epoch 0.7027818448023426\n","03/06/2019 05:05:42 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 05:05:42 - INFO - __main__ -   Eval after epoch 1\n","03/06/2019 05:06:16 - INFO - __main__ -   {'loss': 0.645559752056765, 'accuracy': 0.6294806144842722}\n","03/06/2019 05:06:16 - INFO - __main__ -   Loss on batch 0: 0.48341837525367737\n","03/06/2019 05:06:45 - INFO - __main__ -   Training loss after epoch 0.5519906996294509\n","03/06/2019 05:07:02 - INFO - __main__ -   Training accuracy after epoch 0.945095168374817\n","03/06/2019 05:07:02 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 05:07:02 - INFO - __main__ -   Eval after epoch 2\n","03/06/2019 05:07:36 - INFO - __main__ -   {'loss': 0.6083966601033544, 'accuracy': 0.6795903438185809}\n","03/06/2019 05:07:37 - INFO - __main__ -   Loss on batch 0: 0.263071745634079\n","03/06/2019 05:08:05 - INFO - __main__ -   Training loss after epoch 0.16934504923085833\n","03/06/2019 05:08:23 - INFO - __main__ -   Training accuracy after epoch 0.9912152269399708\n","03/06/2019 05:08:23 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 05:08:23 - INFO - __main__ -   Eval after epoch 3\n","03/06/2019 05:08:57 - INFO - __main__ -   {'loss': 0.8578687528538149, 'accuracy': 0.6825164594001463}\n","03/06/2019 05:08:57 - INFO - __main__ -   Loss on batch 0: 0.0295364111661911\n","03/06/2019 05:09:26 - INFO - __main__ -   Training loss after epoch 0.03558144952322161\n","03/06/2019 05:09:44 - INFO - __main__ -   Training accuracy after epoch 0.9978038067349927\n","03/06/2019 05:09:44 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 05:09:44 - INFO - __main__ -   Eval after epoch 4\n","03/06/2019 05:10:18 - INFO - __main__ -   {'loss': 1.156969187564628, 'accuracy': 0.6880029261155816}\n","03/06/2019 05:10:18 - INFO - __main__ -   Loss on batch 0: 0.0048894211649894714\n","03/06/2019 05:10:47 - INFO - __main__ -   Training loss after epoch 0.013989112729769807\n","03/06/2019 05:11:04 - INFO - __main__ -   Training accuracy after epoch 0.9985358711566618\n","03/06/2019 05:11:04 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 05:11:04 - INFO - __main__ -   Eval after epoch 5\n","03/06/2019 05:11:39 - INFO - __main__ -   {'loss': 1.2959488768910252, 'accuracy': 0.6843452816386247}\n","03/06/2019 05:11:39 - INFO - __main__ -   Loss on batch 0: 0.0027752742171287537\n","03/06/2019 05:12:08 - INFO - __main__ -   Training loss after epoch 0.010193782874794548\n","03/06/2019 05:12:25 - INFO - __main__ -   Training accuracy after epoch 0.9985358711566618\n","03/06/2019 05:12:25 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 05:12:25 - INFO - __main__ -   Eval after epoch 6\n","03/06/2019 05:12:59 - INFO - __main__ -   {'loss': 1.333806564988092, 'accuracy': 0.6825164594001463}\n","03/06/2019 05:13:00 - INFO - __main__ -   Loss on batch 0: 0.002415381371974945\n","03/06/2019 05:13:28 - INFO - __main__ -   Training loss after epoch 0.007599714775244857\n","03/06/2019 05:13:45 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 05:13:46 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 05:13:46 - INFO - __main__ -   Eval after epoch 7\n","03/06/2019 05:14:20 - INFO - __main__ -   {'loss': 1.3584320666485055, 'accuracy': 0.6891002194586686}\n","03/06/2019 05:14:20 - INFO - __main__ -   Loss on batch 0: 0.0032942816615104675\n","03/06/2019 05:14:49 - INFO - __main__ -   Training loss after epoch 0.004069620283147277\n","03/06/2019 05:15:06 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 05:15:06 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 05:15:06 - INFO - __main__ -   Eval after epoch 8\n","03/06/2019 05:15:40 - INFO - __main__ -   {'loss': 1.3895839258681897, 'accuracy': 0.6854425749817118}\n","03/06/2019 05:15:40 - INFO - __main__ -   Loss on batch 0: 0.0016908645629882812\n","03/06/2019 05:16:09 - INFO - __main__ -   Training loss after epoch 0.0032339920398107794\n","03/06/2019 05:16:26 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 05:16:26 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 05:16:26 - INFO - __main__ -   Eval after epoch 9\n","03/06/2019 05:17:01 - INFO - __main__ -   {'loss': 1.404730633594269, 'accuracy': 0.6839795171909291}\n","03/06/2019 05:17:01 - INFO - __main__ -   Loss on batch 0: 0.0016144216060638428\n","03/06/2019 05:17:30 - INFO - __main__ -   Training loss after epoch 0.0028188722018628967\n","03/06/2019 05:17:47 - INFO - __main__ -   Training accuracy after epoch 0.9992679355783309\n","03/06/2019 05:17:47 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 05:17:47 - INFO - __main__ -   Eval after epoch 10\n","03/06/2019 05:18:21 - INFO - __main__ -   {'loss': 1.4095897386933482, 'accuracy': 0.6839795171909291}\n","03/06/2019 05:18:21 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n","03/06/2019 05:18:22 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n","03/06/2019 05:18:22 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpx3c0ak3t\n","03/06/2019 05:18:26 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"max_position_embeddings\": 512,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","03/06/2019 05:18:31 - INFO - pytorch_pretrained_bert.modeling -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","03/06/2019 05:18:31 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","03/06/2019 05:18:31 - INFO - __main__ -     Num examples = 1366\n","03/06/2019 05:18:31 - INFO - __main__ -     Batch size = 32\n","03/06/2019 05:18:31 - INFO - __main__ -     Num steps = 426\n","03/06/2019 05:18:31 - INFO - __main__ -   Loss on batch 0: 0.8015965223312378\n","03/06/2019 05:19:00 - INFO - __main__ -   Training loss after epoch 0.6983873705531276\n","03/06/2019 05:19:17 - INFO - __main__ -   Training accuracy after epoch 0.7210834553440703\n","03/06/2019 05:19:17 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 05:19:18 - INFO - __main__ -   Eval after epoch 1\n","03/06/2019 05:19:52 - INFO - __main__ -   {'loss': 0.645954430103302, 'accuracy': 0.626188734455011}\n","03/06/2019 05:19:52 - INFO - __main__ -   Loss on batch 0: 0.5727028250694275\n","03/06/2019 05:20:21 - INFO - __main__ -   Training loss after epoch 0.5484264340511588\n","03/06/2019 05:20:38 - INFO - __main__ -   Training accuracy after epoch 0.9414348462664714\n","03/06/2019 05:20:38 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 05:20:38 - INFO - __main__ -   Eval after epoch 2\n","03/06/2019 05:21:12 - INFO - __main__ -   {'loss': 0.6118550723375276, 'accuracy': 0.6660570592538405}\n","03/06/2019 05:21:13 - INFO - __main__ -   Loss on batch 0: 0.21952493488788605\n","03/06/2019 05:21:41 - INFO - __main__ -   Training loss after epoch 0.17187428708339847\n","03/06/2019 05:21:59 - INFO - __main__ -   Training accuracy after epoch 0.9758418740849195\n","03/06/2019 05:21:59 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 05:21:59 - INFO - __main__ -   Eval after epoch 3\n","03/06/2019 05:22:33 - INFO - __main__ -   {'loss': 0.9978692081085471, 'accuracy': 0.6675201170446232}\n","03/06/2019 05:22:33 - INFO - __main__ -   Loss on batch 0: 0.02190035954117775\n","03/06/2019 05:23:02 - INFO - __main__ -   Training loss after epoch 0.06773436431188223\n","03/06/2019 05:23:19 - INFO - __main__ -   Training accuracy after epoch 0.9926793557833089\n","03/06/2019 05:23:19 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 05:23:19 - INFO - __main__ -   Eval after epoch 4\n","03/06/2019 05:23:53 - INFO - __main__ -   {'loss': 1.2068340764489285, 'accuracy': 0.6708119970738844}\n","03/06/2019 05:23:54 - INFO - __main__ -   Loss on batch 0: 0.007902737706899643\n","03/06/2019 05:24:22 - INFO - __main__ -   Training loss after epoch 0.031086265391042065\n","03/06/2019 05:24:40 - INFO - __main__ -   Training accuracy after epoch 0.9963396778916545\n","03/06/2019 05:24:40 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 05:24:40 - INFO - __main__ -   Eval after epoch 5\n","03/06/2019 05:25:14 - INFO - __main__ -   {'loss': 1.270910871583362, 'accuracy': 0.6810534016093636}\n","03/06/2019 05:25:14 - INFO - __main__ -   Loss on batch 0: 0.005092024803161621\n","03/06/2019 05:25:43 - INFO - __main__ -   Training loss after epoch 0.02018884810900619\n","03/06/2019 05:26:00 - INFO - __main__ -   Training accuracy after epoch 0.9978038067349927\n","03/06/2019 05:26:00 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 05:26:00 - INFO - __main__ -   Eval after epoch 6\n","03/06/2019 05:26:34 - INFO - __main__ -   {'loss': 1.2934837888839632, 'accuracy': 0.6854425749817118}\n","03/06/2019 05:26:35 - INFO - __main__ -   Loss on batch 0: 0.003871053457260132\n","03/06/2019 05:27:03 - INFO - __main__ -   Training loss after epoch 0.012329098015893684\n","03/06/2019 05:27:20 - INFO - __main__ -   Training accuracy after epoch 0.9978038067349927\n","03/06/2019 05:27:20 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 05:27:20 - INFO - __main__ -   Eval after epoch 7\n","03/06/2019 05:27:55 - INFO - __main__ -   {'loss': 1.3482799821121747, 'accuracy': 0.6839795171909291}\n","03/06/2019 05:27:55 - INFO - __main__ -   Loss on batch 0: 0.0031188204884529114\n","03/06/2019 05:28:24 - INFO - __main__ -   Training loss after epoch 0.010812407624799498\n","03/06/2019 05:28:41 - INFO - __main__ -   Training accuracy after epoch 0.9978038067349927\n","03/06/2019 05:28:41 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 05:28:41 - INFO - __main__ -   Eval after epoch 8\n","03/06/2019 05:29:15 - INFO - __main__ -   {'loss': 1.3779197196627773, 'accuracy': 0.6847110460863204}\n","03/06/2019 05:29:15 - INFO - __main__ -   Loss on batch 0: 0.003065928816795349\n","03/06/2019 05:29:44 - INFO - __main__ -   Training loss after epoch 0.00845081333157628\n","03/06/2019 05:30:01 - INFO - __main__ -   Training accuracy after epoch 0.9985358711566618\n","03/06/2019 05:30:01 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 05:30:01 - INFO - __main__ -   Eval after epoch 9\n","03/06/2019 05:30:36 - INFO - __main__ -   {'loss': 1.3954021729702173, 'accuracy': 0.6814191660570592}\n","03/06/2019 05:30:36 - INFO - __main__ -   Loss on batch 0: 0.002537161111831665\n","03/06/2019 05:31:05 - INFO - __main__ -   Training loss after epoch 0.00725511463120753\n","03/06/2019 05:31:22 - INFO - __main__ -   Training accuracy after epoch 0.9985358711566618\n","03/06/2019 05:31:22 - INFO - __main__ -   ***** Running evaluation *****\n","03/06/2019 05:31:22 - INFO - __main__ -   Eval after epoch 10\n","03/06/2019 05:31:56 - INFO - __main__ -   {'loss': 1.3997312860433446, 'accuracy': 0.681784930504755}\n"],"name":"stderr"}]}]}