{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Sentence Embeddings - GloVE.ipynb","version":"0.3.2","provenance":[{"file_id":"1uKUp1OeC7BxVSWbdmRU-gXmvA7dHXjo5","timestamp":1552301799332},{"file_id":"1VNv0lh0SqiUNgxOGrEDNcc3EvzY0G_Ju","timestamp":1551615990477}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"EVTPLS2PlNTV","colab_type":"text"},"cell_type":"markdown","source":["## The majority of the code in this notebook is work produced by Khodak et al. (2017) and can be found at the following links: https://github.com/NLPrinceton/SARC and https://github.com/NLPrinceton/text_embedding\n","\n","## Code from these repositories has been referenced below."]},{"metadata":{"id":"PB2veJx4ZfVZ","colab_type":"text"},"cell_type":"markdown","source":["## Import libraries and data"]},{"metadata":{"id":"g8o0dxPrZfVd","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import csv\n","import json\n","from sklearn.model_selection import train_test_split\n","import pickle\n","\n","import argparse\n","import nltk\n","from sklearn.linear_model import LogisticRegressionCV as LogitCV\n","from sklearn.preprocessing import normalize\n","from sklearn.metrics import f1_score\n","\n","from collections import Counter\n","from itertools import chain\n","from itertools import groupby\n","from operator import itemgetter\n","#from string import punctuation\n","from unicodedata import category\n","import nltk\n","import numpy as np\n","from scipy import sparse as sp"],"execution_count":0,"outputs":[]},{"metadata":{"id":"gArFUBK2g8sh","colab_type":"code","outputId":"960e246d-4779-4aba-e77e-415cc33846d2","executionInfo":{"status":"ok","timestamp":1552383661950,"user_tz":0,"elapsed":25151,"user":{"displayName":"Joe Farrington","photoUrl":"https://lh5.googleusercontent.com/-bNEtdlkbGn8/AAAAAAAAAAI/AAAAAAAAAF4/7VpSGeR6wrY/s64/photo.jpg","userId":"09132137217736073231"}},"colab":{"base_uri":"https://localhost:8080/","height":189}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","### SARC Directory Paths ###\n","SARC_POL = '/content/gdrive/My Drive/SARC pol/project_data/'"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"metadata":{"id":"hfz04lufb2tD","colab_type":"code","outputId":"6cb3b308-ddc2-4eed-a6ba-147a9d734b49","executionInfo":{"status":"ok","timestamp":1552337736202,"user_tz":0,"elapsed":103455,"user":{"displayName":"Joe Farrington","photoUrl":"https://lh5.googleusercontent.com/-bNEtdlkbGn8/AAAAAAAAAAI/AAAAAAAAAF4/7VpSGeR6wrY/s64/photo.jpg","userId":"09132137217736073231"}},"colab":{"base_uri":"https://localhost:8080/","height":233}},"cell_type":"code","source":["!wget -P '/content/gdrive/My Drive/SARC pol/embeddings/glove.txt' 'http://nlp.cs.princeton.edu/DisC/amazon_glove1600.txt.bz2'"],"execution_count":0,"outputs":[{"output_type":"stream","text":["--2019-03-11 20:54:35--  http://nlp.cs.princeton.edu/DisC/amazon_glove1600.txt.bz2\n","Resolving nlp.cs.princeton.edu (nlp.cs.princeton.edu)... 128.112.136.51\n","Connecting to nlp.cs.princeton.edu (nlp.cs.princeton.edu)|128.112.136.51|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2593194143 (2.4G) [application/x-bzip2]\n","Saving to: ‘/content/gdrive/My Drive/SARC pol/embeddings/glove.txt/amazon_glove1600.txt.bz2’\n","\n","amazon_glove1600.tx 100%[===================>]   2.42G  55.4MB/s    in 57s     \n","\n","2019-03-11 20:55:32 (43.6 MB/s) - ‘/content/gdrive/My Drive/SARC pol/embeddings/glove.txt/amazon_glove1600.txt.bz2’ saved [2593194143/2593194143]\n","\n"],"name":"stdout"}]},{"metadata":{"id":"2-EbBPz4eSAK","colab_type":"code","outputId":"cccdf2ce-1041-4100-b710-a853701d45e1","executionInfo":{"status":"ok","timestamp":1552337740734,"user_tz":0,"elapsed":107980,"user":{"displayName":"Joe Farrington","photoUrl":"https://lh5.googleusercontent.com/-bNEtdlkbGn8/AAAAAAAAAAI/AAAAAAAAAF4/7VpSGeR6wrY/s64/photo.jpg","userId":"09132137217736073231"}},"colab":{"base_uri":"https://localhost:8080/","height":63}},"cell_type":"code","source":["!bunzip2 \"/content/gdrive/My Drive/SARC pol/embeddings/glove/amazon_glove1600.txt.bz2\""],"execution_count":0,"outputs":[{"output_type":"stream","text":["bunzip2: Can't open input file /content/gdrive/My Drive/SARC pol/embeddings/glove/amazon_glove1600.txt.bz2: No such file or directory.\n"],"name":"stdout"}]},{"metadata":{"id":"0xOj9eUNZfVk","colab_type":"code","colab":{}},"cell_type":"code","source":["############################################ Khodak et al. 2017\n","\n","def tokenize(documents):\n","  '''tokenizes documents\n","  Args:\n","    documents: iterable of strings\n","  Returns:\n","    list of list of strings\n","  '''\n","\n","  return [list(split_on_punctuation(doc)) for doc in documents]\n","\n","###############################################################"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JRyd0lwMZfVo","colab_type":"code","colab":{}},"cell_type":"code","source":["############################################ Khodak et al. 2017\n","\n","#PUNCTUATION = set(punctuation)\n","PUNCTUATION = {'M', 'P', 'S'}\n","UINT = np.uint16\n","from unicodedata import category\n","\n","def split_on_punctuation(document):\n","  '''tokenizes string by splitting on spaces and punctuation\n","  Args:\n","    document: string\n","  Returns:\n","    str generator\n","  '''\n","\n","  for token in document.split():\n","    if len(token) == 1:\n","      yield token\n","    else:\n","      chunk = token[0]\n","      for char0, char1 in zip(token[:-1], token[1:]):\n","        #if (char0 in PUNCTUATION) == (char1 in PUNCTUATION):\n","        if (category(char0)[0] in PUNCTUATION) == (category(char1)[0] in PUNCTUATION):\n","          chunk += char1\n","        else:\n","          yield chunk\n","          chunk = char1\n","      if chunk:\n","        yield chunk\n","\n","###############################################################"],"execution_count":0,"outputs":[]},{"metadata":{"id":"6yTdpsvUZfVr","colab_type":"code","colab":{}},"cell_type":"code","source":["############################################ Khodak et al. 2017\n","\n","def feature_counts(documents):\n","  '''computes feature counts from featurized documents\n","  Args:\n","    documents: iterable of lists of hashable features\n","  Returns:\n","    dict mapping features to counts\n","  '''\n","\n","  return Counter(feat for doc in documents for feat in doc)\n","\n","\n","def feature_vocab(documents, min_count=1, sorted_features=sorted):\n","  '''gets feature vocabulary from featurized documents\n","  Args:\n","    documents: iterable of lists of hashable features\n","    min_count: minimum number of times feature must appear to be included in the vocabulary\n","    sorted_features: function that sorts the features\n","  Returns:\n","    {feature: index} dict\n","  '''\n","  \n","  return {feat: i for i, feat in enumerate(sorted_features(feat for feat, count in feature_counts(documents).items() if count >= min_count))}\n","\n","\n","def docs2bofs(documents, vocabulary=None, weights=None, default=1.0, format='csr', **kwargs):\n","  '''constructs sparse BoF representations from featurized documents\n","  Args:\n","    documents: iterable of lists of hashable features\n","    vocabulary: dict mapping features to indices (nonnegative ints) or a list of features; if None will compute automatically from documents\n","    weights: dict mapping features to weights (floats) or a list/np.ndarray of weights; if None will compute unweighted BoFs\n","    default: default feature weight if not feature in weights; ignored if weights is None\n","    format: sparse matrix format\n","    kwargs: passed to feature_vocab; ignored if not vocabulary is None\n","  Returns:\n","    sparse BoF matrix in CSR format of size (len(documents), len(vocabulary))\n","  '''\n","\n","  if vocabulary is None:\n","    vocabulary = feature_vocab(documents, **kwargs)\n","  elif type(vocabulary) == list:\n","    vocabulary = {feat: i for i, feat in enumerate(vocabulary)}\n","\n","  rows, cols, values = zip(*((row, col, count) for (row, col), count in Counter((i, vocabulary.get(feat, -1)) for i, doc in enumerate(documents) for feat in doc).items() if not col==-1))\n","  m = len(documents)\n","  V = len(vocabulary)\n","  if weights is None:\n","    return sp.coo_matrix((values, (rows, cols)), shape=(m, V), dtype=UINT).asformat(format)\n","  bofs = sp.coo_matrix((values, (rows, cols)), shape=(m, V)).tocsr()\n","\n","  if type(weights) == dict:\n","    diag = np.empty(V)\n","    for feat, i in vocabulary.items():\n","      diag[i] = weights.gets(feat, default)\n","  else:\n","    assert len(weights) == V, \"if weights passed as a list/np.ndarray, length must be same as vocabulary size\"\n","    if type(weights) == list:\n","      diag = np.array(weights)\n","    else:\n","      diag = weights\n","  return bofs.dot(sp.diags(diag, 0)).asformat(format)\n","\n","###############################################################"],"execution_count":0,"outputs":[]},{"metadata":{"id":"A8n47210ayue","colab_type":"code","colab":{}},"cell_type":"code","source":["############################################ Khodak et al. 2017\n","import numpy as np\n","from numpy.linalg import norm\n","from scipy.linalg import svd\n","from sklearn.linear_model import LinearRegression\n","from sklearn.preprocessing import normalize\n","\n","\n","FLOAT = np.float32\n","# NOTE: filepath for Common Crawl GloVe embeddings goes here\n","CCGLOVE = \"/content/gdrive/My Drive/SARC pol/embeddings/glove/amazon_glove1600.txt\"\n","\n","\n","# NOTE: Some files have 2d or 2d+2 numbers on each line, with the last d of them being meaningless; avoid loading them by setting dimension=d\n","def load(vectorfile, vocabulary=None, dimension=None):\n","  '''generates word embeddings from file\n","  Args:\n","    vectorfile: word embedding text file or HDF5 file with keys 'words' and 'vectors'\n","    vocabulary: dict/set of strings, or int specifying number of words to load; if None loads all words from file\n","    dimension: number of dimensions to load\n","  Returns:\n","    (word, vector) generator\n","  '''\n","\n","  try:\n","    f = h5py.File(vectorfile, 'r')\n","    words, vectors = np.array(f['words']), np.array(f['vectors'])\n","    for word, vector in zip(words, vectors):\n","      if vocabulary is None or word in vocabulary:\n","        yield word, vector\n","    f.close()\n","\n","  except OSError:\n","    if vocabulary is None:\n","      V = float('inf')\n","    elif type(vocabulary) == int:\n","      V = vocabulary\n","      vocabulary = None\n","    else:\n","      V = len(vocabulary)\n","    dimension = -1 if dimension is None else dimension\n","\n","    with open(vectorfile, 'r') as f:\n","      n = 0\n","      for line in f:\n","        index = line.index(' ')\n","        word = line[:index]\n","        if vocabulary is None or word in vocabulary:\n","          yield word, np.fromstring(line[index+1:], dtype=FLOAT, count=dimension, sep=' ')\n","          n += 1\n","        if n == V:\n","          break\n","\n","\n","def text2hdf5(textfile, hdf5file, **kwargs):\n","  '''converts word embeddings file from text to HDF5 format\n","  Args:\n","      textfile: word embeddings file in format \"word float ... float\\n\"\n","      hdf5file: output file ; will have keys 'words' and 'vectors'\n","      kwargs: passed to load\n","  Returns:\n","      None\n","  '''\n","\n","  words, vectors = zip(*load(textfile, **kwargs))\n","  f = h5py.File(hdf5file)\n","  f.create_dataset('words', (len(words),), dtype=h5py.special_dtype(vlen=str))\n","  for i, word in enumerate(words):\n","      f['words'][i] = word\n","  f.create_dataset('vectors', data=np.vstack(vectors))\n","  f.close()\n","\n","\n","def vocab2mat(vocabulary=None, random=None, vectorfile=CCGLOVE, dimension=None, unit=True):\n","  '''constructs matrix of word vectors\n","  Args:\n","    vocabulary: dict mapping strings to indices, or iterable of strings, or int specifying vocab size; if None loads all words in vectorfile\n","    random: type ('Gaussian' or 'Rademacher') of random vectors to use; if None uses pretrained vectors; if tuple (low, high) uses uniform distribution over [low, high)\n","    vectorfile: word embedding text file; ignored if not random is None\n","    dimension: embedding dimension\n","    unit: normalize embeddings\n","  Returns:\n","    numpy matrix of size (len(vocabulary), dimension)\n","  '''\n","\n","  assert random is None or not vocabulary is None, \"needs vocabulary size information for random vectors\"\n","  assert random is None or not dimension is None, \"needs dimension information for random vectors\"\n","\n","  if random is None:\n","\n","    if type(vocabulary) == set:\n","      vocabulary = sorted(vocabulary)\n","    if type(vocabulary) == list:\n","      vocabulary = {word: i for i, word in enumerate(vocabulary)}\n","    if type(vocabulary) == dict:\n","      matrix = np.zeros((len(vocabulary), dimension), dtype=FLOAT)\n","      for word, vector in load(vectorfile, vocabulary, dimension):\n","        matrix[vocabulary[word]] = vector\n","    else:\n","      matrix = np.vstack(vector for _, vector in load(vectorfile, vocabulary, dimension))\n","  \n","  else:\n","\n","    if not type(vocabulary) == int:\n","      vocabulary = len(vocabulary)\n","    if type(random) == tuple:\n","      return np.random.uniform(*random, size=(vocabulary, dimension)).astype(FLOAT)\n","    elif random.lower() == 'gaussian':\n","      matrix = np.random.normal(scale=1.0/np.sqrt(dimension), size=(vocabulary, dimension)).astype(FLOAT)\n","    elif random.lower() == 'rademacher':\n","      return (2.0*np.random.randint(2, size=(vocabulary, dimension)).astype(FLOAT)-1.0)/np.sqrt(dimension)\n","    else:\n","      raise(NotImplementedError)\n","\n","  if unit:\n","    return normalize(matrix)\n","  return matrix\n","\n","\n","def vocab2vecs(vocabulary=None, random=None, vectorfile=CCGLOVE, dimension=None, unit=True):\n","  '''constructs dict mapping words to vectors\n","  Args:\n","    vocabulary: iterable of strings, or int specifying vocab size; if None loads all words in vectorfile\n","    random: type ('Gaussian' or 'Rademacher') of random vectors to use; if None uses pretrained vectors\n","    vectorfile: word embedding text file; ignored if not random is None\n","    dimension: embedding dimension\n","    unit: normalize embeddings\n","  Returns:\n","    {word: vector} dict; words not in vectorfile are not included\n","  '''\n","\n","  assert random is None or not (vocabulary is None or type(vocabulary) == int), \"needs word information for random vectors\"\n","\n","  if random is None:\n","    if unit:\n","      return {word: vector/norm(vector) for word, vector in load(vectorfile, vocabulary, dimension)}\n","    return dict(load(vectorfile, vocabulary, dimension))\n","  return dict(zip(vocabulary, vocab2mat(vocabulary, random=random, dimension=dimension, unit=unit)))\n","\n","\n","def docs2vecs(documents, f2v=None, weights=None, default=1.0, avg=False, **kwargs):\n","  '''computes document embeddings from documents\n","  Args:\n","    documents: iterable of lists of hashable features\n","    f2v: dict mapping features to vectors; if None will compute this using vocab2vecs\n","    weights: dict mapping features to weights; unweighted if None\n","    default: default weight to assign if feature not in weights; ignored if weights is None\n","    avg: divide embeddings by the document length\n","    kwargs: passed to vocab2vecs; ignored if not f2v is None\n","  Returns:\n","    matrix of size (len(documents), dimension)\n","  '''\n","\n","  if f2v is None:\n","    f2v = vocab2vecs({word for document in documents for word in documents}, **kwargs)\n","    dimension = kwargs.get('dimension', 300)\n","  else:\n","    dimensions = {v.shape for v in f2v.values()}\n","    assert len(dimensions) == 1, \"all feature vectors must have same dimension\"\n","    dimension = dimensions.pop()\n","  if not weights is None:\n","    f2v = {feat: weights.get(feat, default)*vec for feat, vec in f2v.items()}\n","    \n","  z = np.zeros(dimension, dtype=FLOAT)\n","  if avg:\n","    return np.vstack(sum((f2v.get(feat, z) for feat in document), z) / max(1.0, len(document)) for document in documents)\n","  return np.vstack(sum((f2v.get(feat, z) for feat in document), z) for document in documents)\n","\n","\n","class OrthogonalProcrustes:\n","  '''sklearn-style class for solving the Orthogonal Procrustes problem\n","  '''\n","\n","  def __init__(self, fit_intercept=False):\n","    '''initializes object\n","    Args:\n","      fit_intercept: whether to find best transformation after translation\n","    Returns:\n","      None\n","    '''\n","\n","    self.fit_intercept = fit_intercept\n","\n","  def fit(self, X, Y):\n","    '''finds orthogonal matrix M minimizing |XM^T-Y|\n","    Args:\n","      X: numpy array of shape (n, d)\n","      Y: numpy array of shape (n, d)\n","    Returns:\n","      self (with attribute coef_, a numpy array of shape (d, d)\n","    '''\n","\n","    if self.fit_intercept:\n","      Xbar, Ybar = np.mean(X, axis=0), np.mean(Y, axis=0)\n","      X, Y = X-Xbar, Y-Ybar\n","    U, _, VT = svd(Y.T.dot(X))\n","    self.coef_ = U.dot(VT)\n","    if self.fit_intercept:\n","      self.intercept_ = Ybar - self.coef_.dot(Xbar)\n","    else:\n","      self.intercept_ = np.zeros(self.coef_.shape[0], dtype=self.coef_.dtype)\n","    return self\n","\n","\n","def align_vocab(func):\n","  '''wrapper to align vocab to allow word-to-vector dict inputs to functions taking two word-vector matrices as inputs\n","  '''\n","\n","  def wrapper(X, Y, **kwargs):\n","    assert type(X) == type(Y), \"first two arguments must be the same type\"\n","    if type(X) == dict:\n","      vocab = sorted(set(X.keys()).intersection(Y.keys()))\n","      X = np.vstack(X[w] for w in vocab)\n","      Y = np.vstack(Y[w] for w in vocab)\n","    else:\n","      assert type(X) == np.ndarray, \"first two arguments must be 'dict' or 'numpy.ndarray'\"\n","    return func(X, Y, **kwargs)\n","\n","  return wrapper\n","\n","\n","@align_vocab\n","def best_transform(source, target, orthogonal=True, fit_intercept=False):\n","  '''computes best matrix between two sets of word embeddings in terms of least-squares error\n","  Args:\n","    source: numpy array of size (len(vocabulary), dimension) or dict mapping words to vectors; must be same type as target\n","    target: numpy array of size (len(vocabulary), dimension) or dict mapping words to vectors; must be same type as source\n","    orthogonal: if True constrains best transform to be orthogonal\n","    fit_intercept: whether to find best transformation after translation\n","  Returns:\n","    numpy array of size (dimension, dimension)\n","  '''\n","\n","  if orthogonal:\n","    transform = OrthogonalProcrustes(fit_intercept=fit_intercept).fit(source, target)\n","  else:\n","    transform = LinearRegression(fit_intercept=fit_intercept).fit(source, target)\n","    if not fit_intercept:\n","      transform.intercept_ = np.zeros(target.shape[1])\n","  return transform.coef_.astype(target.dtype), transform.intercept_.astype(target.dtype)\n","\n","\n","@align_vocab\n","def average_cosine_similarity(X, Y):\n","  '''computes the average cosine similarity between two sets of word embeddings\n","  Args:\n","    X: numpy array of size (len(vocabulary), dimension) or dict mapping words to vectors; must be same type as target\n","    Y: numpy array of size (len(vocabulary), dimension) or dict mapping words to vectors; must be same type as source\n","  Returns:\n","    average cosine similarity as a float\n","  '''\n","\n","  return np.mean((normalize(X) * normalize(Y)).sum(1))\n","\n","###############################################################"],"execution_count":0,"outputs":[]},{"metadata":{"id":"2BSGM1-YpdDa","colab_type":"text"},"cell_type":"markdown","source":["## Let's go"]},{"metadata":{"id":"4wo64YWepYs6","colab_type":"text"},"cell_type":"markdown","source":["### 100% project training set"]},{"metadata":{"id":"nGHO_YZbpKP1","colab_type":"code","outputId":"990d5878-b5d8-4e22-abcb-0bb2e809b959","executionInfo":{"status":"ok","timestamp":1552338535918,"user_tz":0,"elapsed":901746,"user":{"displayName":"Joe Farrington","photoUrl":"https://lh5.googleusercontent.com/-bNEtdlkbGn8/AAAAAAAAAAI/AAAAAAAAAF4/7VpSGeR6wrY/s64/photo.jpg","userId":"09132137217736073231"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"cell_type":"code","source":["filename =  ['project_training_100.csv']\n","\n","record_100 = pd.DataFrame()\n","\n","#Load in the test set\n","validdf = pd.read_csv(SARC_POL+'balanced_test.csv', index_col = 0)\n","\n","for fname in filename:\n","  \n","  #Load in the training set\n","  traindf = pd.read_csv(SARC_POL+fname, index_col = 0)\n","  \n","  # Only use responses for this method. Ignore ancestors.\n","  train_resp = traindf['response'].values.tolist()\n","  test_resp = validdf['response'].values.tolist()\n","  train_labels = traindf['label'].values.tolist()\n","  test_labels = validdf['label'].values.tolist()\n","\n","  # Train resp\n","  first_resp = []\n","  second_resp = []\n","  for idx, resp in enumerate(train_resp):\n","\n","    if idx % 2 == 0:\n","      first_resp.append(resp)\n","    else:\n","      second_resp.append(resp)\n","\n","  train_docs = {0: first_resp, 1: second_resp}\n","\n","\n","  # Test resp\n","  first_resp = []\n","  second_resp = []\n","  for idx, resp in enumerate(test_resp):\n","\n","    if idx % 2 == 0:\n","      first_resp.append(resp)\n","    else:\n","      second_resp.append(resp)\n","\n","  test_docs = {0: first_resp, 1: second_resp}\n","\n","\n","  # Train labels\n","  first_label = []\n","  second_label = []\n","  for idx, label in enumerate(train_labels):\n","\n","    if idx % 2 == 0:\n","      first_label.append(label)\n","    else:\n","      second_label.append(label)\n","\n","  train_labels = {0: first_label, 1: second_label}\n","\n","\n","  # Test labels\n","  first_label = []\n","  second_label = []\n","  for idx, label in enumerate(test_labels):\n","\n","    if idx % 2 == 0:\n","      first_label.append(label)\n","    else:\n","      second_label.append(label)\n","\n","  test_labels = {0: first_label, 1: second_label}\n","\n","  ############################################ Khodak et al. 2017\n","  \n","  # Train a classifier on all responses in training data. We will later use this\n","  # classifier to determine for every sequence which of the 2 responses is more sarcastic.\n","  train_all_docs_tok = tokenize(train_docs[0] + train_docs[1])\n","  test_all_docs_tok = tokenize(test_docs[0] + test_docs[1])\n","  train_all_labels = np.array(train_labels[0] + train_labels[1])\n","  test_all_labels = np.array(test_labels[0] + test_labels[1])\n","\n","  weights = None\n","\n","  w2v = vocab2vecs({word for doc in train_all_docs_tok+test_all_docs_tok for word in doc}, vectorfile=CCGLOVE)\n","  train_all_vecs = docs2vecs(train_all_docs_tok, f2v=w2v, weights=weights)\n","  test_all_vecs = docs2vecs(test_all_docs_tok, f2v=w2v, weights=weights)\n","  \n","  print(fname, \"\\n----------------------------------\")\n","    \n","  for seed in [0, 24, 729, 857, 403]:\n","\n","    # Evaluate this classifier on all responses.\n","#     print('Evaluate the classifier on all responses')\n","    clf = LogitCV(Cs=[10**i for i in range(-2, 3)], fit_intercept=False, cv=2, dual=np.less(*train_all_vecs.shape), solver='liblinear', n_jobs=-1, random_state=seed) \n","    clf.fit(train_all_vecs, train_all_labels)\n","    #print('Train acc: ', clf.score(train_all_vecs, train_all_labels))\n","    test_acc = clf.score(test_all_vecs, test_all_labels)\n","    #print('Test acc: ', test_acc )\n","    \n","    ############################################ \n","        \n","    # Balanced Test Score Calculation\n","    nAncestors = len(test_labels[0])\n","    countCorrect = 0\n","    for i in range(nAncestors):\n","      \n","      scoreResponse0 = clf.predict_proba(test_all_vecs[i].reshape(1,-1))[0,1]\n","      scoreResponse1 = clf.predict_proba(test_all_vecs[i+nAncestors].reshape(1,-1))[0,1]\n","     \n","      if scoreResponse0 > scoreResponse1 and test_labels[0][i] == 1:\n","        countCorrect += 1\n","        \n","      elif scoreResponse1 > scoreResponse0 and test_labels[1][i] == 1:\n","        countCorrect += 1\n","       \n","    bal_test_score =  countCorrect/nAncestors\n","    #print(\"Balanced Test Score:\", bal_test_score )\n","    \n","    # F1 Prediction\n","    \n","    y_pred = []\n","    y_true = []\n","    \n","    for i in range(len(test_labels[0])+len(test_labels[1])):\n","      \n","      scoreResponse = clf.predict_proba(test_all_vecs[i].reshape(1,-1))[0][1]\n","      \n","      if i < nAncestors:\n","        \n","        y_true.append(test_labels[0][i])\n","        \n","      else:\n","        \n","        y_true.append(test_labels[1][i-nAncestors])\n","      \n","      if scoreResponse > 0.5:\n","        y_pred.append(1)\n","        \n","      else:\n","        y_pred.append(0)\n","       \n","    f1Score = f1_score(y_true, y_pred, pos_label=1, average='binary', sample_weight=None)\n","    #print(\"F1 Score:\", f1Score)\n","    \n","    #Store the results\n","    record_100 = record_100.append({'Acc (bal, bal)': bal_test_score, 'Acc (bal, reg)':test_acc , 'F1 (bal, reg)': f1Score}, ignore_index=True)\n","    \n","print(record_100)\n","\n","with open(\"/content/gdrive/My Drive/SARC pol/test_set_results_glove/test100.pickle\", 'wb') as handle:\n","  pickle.dump(record_100, handle)\n","  "],"execution_count":0,"outputs":[{"output_type":"stream","text":["project_training_100.csv \n","----------------------------------\n","   Acc (bal, bal)  Acc (bal, reg)  F1 (bal, reg)\n","0        0.744568         0.67616       0.669662\n","1        0.744568         0.67616       0.669662\n","2        0.744568         0.67616       0.669662\n","3        0.744568         0.67616       0.669662\n","4        0.744568         0.67616       0.669662\n"],"name":"stdout"}]},{"metadata":{"id":"M4cGRwPGpWI8","colab_type":"text"},"cell_type":"markdown","source":["### 50% project training set"]},{"metadata":{"id":"nrsB5w1lpKNt","colab_type":"code","outputId":"3c5d7777-e65f-46d7-edec-5c9e6d3f8630","executionInfo":{"status":"ok","timestamp":1552327601261,"user_tz":0,"elapsed":20,"user":{"displayName":"Joe Farrington","photoUrl":"https://lh5.googleusercontent.com/-bNEtdlkbGn8/AAAAAAAAAAI/AAAAAAAAAF4/7VpSGeR6wrY/s64/photo.jpg","userId":"09132137217736073231"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"cell_type":"code","source":["filename =  ['project_training_50.csv']\n","\n","record_50 = pd.DataFrame()\n","\n","#Load in the test set\n","validdf = pd.read_csv(SARC_POL+'balanced_test.csv', index_col = 0)\n","\n","for fname in filename:\n","  \n","  #Load in the training set\n","  traindf = pd.read_csv(SARC_POL+fname, index_col = 0)\n","  \n","  # Only use responses for this method. Ignore ancestors.\n","  train_resp = traindf['response'].values.tolist()\n","  test_resp = validdf['response'].values.tolist()\n","  train_labels = traindf['label'].values.tolist()\n","  test_labels = validdf['label'].values.tolist()\n","\n","  # Train resp\n","  first_resp = []\n","  second_resp = []\n","  for idx, resp in enumerate(train_resp):\n","\n","    if idx % 2 == 0:\n","      first_resp.append(resp)\n","    else:\n","      second_resp.append(resp)\n","\n","  train_docs = {0: first_resp, 1: second_resp}\n","\n","\n","  # Test resp\n","  first_resp = []\n","  second_resp = []\n","  for idx, resp in enumerate(test_resp):\n","\n","    if idx % 2 == 0:\n","      first_resp.append(resp)\n","    else:\n","      second_resp.append(resp)\n","\n","  test_docs = {0: first_resp, 1: second_resp}\n","\n","\n","  # Train labels\n","  first_label = []\n","  second_label = []\n","  for idx, label in enumerate(train_labels):\n","\n","    if idx % 2 == 0:\n","      first_label.append(label)\n","    else:\n","      second_label.append(label)\n","\n","  train_labels = {0: first_label, 1: second_label}\n","\n","\n","  # Test labels\n","  first_label = []\n","  second_label = []\n","  for idx, label in enumerate(test_labels):\n","\n","    if idx % 2 == 0:\n","      first_label.append(label)\n","    else:\n","      second_label.append(label)\n","\n","  test_labels = {0: first_label, 1: second_label}\n","\n","  ############################################ Khodak et al. 2017\n","  \n","  # Train a classifier on all responses in training data. We will later use this\n","  # classifier to determine for every sequence which of the 2 responses is more sarcastic.\n","  train_all_docs_tok = tokenize(train_docs[0] + train_docs[1])\n","  test_all_docs_tok = tokenize(test_docs[0] + test_docs[1])\n","  train_all_labels = np.array(train_labels[0] + train_labels[1])\n","  test_all_labels = np.array(test_labels[0] + test_labels[1])\n","\n","  weights = None\n","\n","  w2v = vocab2vecs({word for doc in train_all_docs_tok+test_all_docs_tok for word in doc}, vectorfile=CCGLOVE)\n","  train_all_vecs = docs2vecs(train_all_docs_tok, f2v=w2v, weights=weights)\n","  test_all_vecs = docs2vecs(test_all_docs_tok, f2v=w2v, weights=weights)\n","  \n","  print(fname, \"\\n----------------------------------\")\n","    \n","  for seed in [0, 24, 729, 857, 403]:\n","\n","    # Evaluate this classifier on all responses.\n","#     print('Evaluate the classifier on all responses')\n","    clf = LogitCV(Cs=[10**i for i in range(-2, 3)], fit_intercept=False, cv=2, dual=np.less(*train_all_vecs.shape), solver='liblinear', n_jobs=-1, random_state=seed) \n","    clf.fit(train_all_vecs, train_all_labels)\n","    #print('Train acc: ', clf.score(train_all_vecs, train_all_labels))\n","    test_acc = clf.score(test_all_vecs, test_all_labels)\n","    #print('Test acc: ', test_acc )\n","  \n","  ###############################################################\n","  \n","    # Balanced Test Score Calculation\n","    nAncestors = len(test_labels[0])\n","    countCorrect = 0\n","    for i in range(nAncestors):\n","      \n","      scoreResponse0 = clf.predict_proba(test_all_vecs[i].reshape(1,-1))[0,1]\n","      scoreResponse1 = clf.predict_proba(test_all_vecs[i+nAncestors].reshape(1,-1))[0,1]\n","     \n","      if scoreResponse0 > scoreResponse1 and test_labels[0][i] == 1:\n","        countCorrect += 1\n","        \n","      elif scoreResponse1 > scoreResponse0 and test_labels[1][i] == 1:\n","        countCorrect += 1\n","       \n","    bal_test_score =  countCorrect/nAncestors\n","    #print(\"Balanced Test Score:\", bal_test_score )\n","    \n","    # F1 Prediction\n","    \n","    y_pred = []\n","    y_true = []\n","    \n","    for i in range(len(test_labels[0])+len(test_labels[1])):\n","      \n","      scoreResponse = clf.predict_proba(test_all_vecs[i].reshape(1,-1))[0][1]\n","      \n","      if i < nAncestors:\n","        \n","        y_true.append(test_labels[0][i])\n","        \n","      else:\n","        \n","        y_true.append(test_labels[1][i-nAncestors])\n","      \n","      if scoreResponse > 0.5:\n","        y_pred.append(1)\n","        \n","      else:\n","        y_pred.append(0)\n","       \n","    f1Score = f1_score(y_true, y_pred, pos_label=1, average='binary', sample_weight=None)\n","    #print(\"F1 Score:\", f1Score)\n","    \n","    #Store the results\n","    record_50 = record_50.append({'Acc (bal, bal)': bal_test_score, 'Acc (bal, reg)':test_acc , 'F1 (bal, reg)': f1Score}, ignore_index=True)\n","    \n","print(record_50)\n","\n","with open(\"/content/gdrive/My Drive/SARC pol/test_set_results_glove/test50.pickle\", 'wb') as handle:\n","  pickle.dump(record_50, handle)\n","  "],"execution_count":0,"outputs":[{"output_type":"stream","text":["project_training_50.csv \n","----------------------------------\n","   Acc (bal, bal)  Acc (bal, reg)  F1 (bal, reg)\n","0        0.729888        0.670581        0.66627\n","1        0.729888        0.670581        0.66627\n","2        0.729888        0.670581        0.66627\n","3        0.729888        0.670581        0.66627\n","4        0.729888        0.670581        0.66627\n"],"name":"stdout"}]},{"metadata":{"id":"hUSqIhNRpS0y","colab_type":"text"},"cell_type":"markdown","source":["### 25% project training set"]},{"metadata":{"id":"7s9GA5vcpKLX","colab_type":"code","outputId":"616bf2be-a66f-40d5-ac32-df4fc6cc5468","executionInfo":{"status":"ok","timestamp":1552324706463,"user_tz":0,"elapsed":471557,"user":{"displayName":"Joe Farrington","photoUrl":"https://lh5.googleusercontent.com/-bNEtdlkbGn8/AAAAAAAAAAI/AAAAAAAAAF4/7VpSGeR6wrY/s64/photo.jpg","userId":"09132137217736073231"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"cell_type":"code","source":["filename =  ['project_training_25.csv']\n","\n","record_25 = pd.DataFrame()\n","\n","#Load in the test set\n","validdf = pd.read_csv(SARC_POL+'balanced_test.csv', index_col = 0)\n","\n","for fname in filename:\n","  \n","  #Load in the training set\n","  traindf = pd.read_csv(SARC_POL+fname, index_col = 0)\n","  \n","  # Only use responses for this method. Ignore ancestors.\n","  train_resp = traindf['response'].values.tolist()\n","  test_resp = validdf['response'].values.tolist()\n","  train_labels = traindf['label'].values.tolist()\n","  test_labels = validdf['label'].values.tolist()\n","\n","  # Train resp\n","  first_resp = []\n","  second_resp = []\n","  for idx, resp in enumerate(train_resp):\n","\n","    if idx % 2 == 0:\n","      first_resp.append(resp)\n","    else:\n","      second_resp.append(resp)\n","\n","  train_docs = {0: first_resp, 1: second_resp}\n","\n","\n","  # Test resp\n","  first_resp = []\n","  second_resp = []\n","  for idx, resp in enumerate(test_resp):\n","\n","    if idx % 2 == 0:\n","      first_resp.append(resp)\n","    else:\n","      second_resp.append(resp)\n","\n","  test_docs = {0: first_resp, 1: second_resp}\n","\n","\n","  # Train labels\n","  first_label = []\n","  second_label = []\n","  for idx, label in enumerate(train_labels):\n","\n","    if idx % 2 == 0:\n","      first_label.append(label)\n","    else:\n","      second_label.append(label)\n","\n","  train_labels = {0: first_label, 1: second_label}\n","\n","\n","  # Test labels\n","  first_label = []\n","  second_label = []\n","  for idx, label in enumerate(test_labels):\n","\n","    if idx % 2 == 0:\n","      first_label.append(label)\n","    else:\n","      second_label.append(label)\n","\n","  test_labels = {0: first_label, 1: second_label}\n","\n","  ############################################ Khodak et al. 2017\n","  \n","  # Train a classifier on all responses in training data. We will later use this\n","  # classifier to determine for every sequence which of the 2 responses is more sarcastic.\n","  train_all_docs_tok = tokenize(train_docs[0] + train_docs[1])\n","  test_all_docs_tok = tokenize(test_docs[0] + test_docs[1])\n","  train_all_labels = np.array(train_labels[0] + train_labels[1])\n","  test_all_labels = np.array(test_labels[0] + test_labels[1])\n","\n","  weights = None\n","\n","  w2v = vocab2vecs({word for doc in train_all_docs_tok+test_all_docs_tok for word in doc}, vectorfile=CCGLOVE)\n","  train_all_vecs = docs2vecs(train_all_docs_tok, f2v=w2v, weights=weights)\n","  test_all_vecs = docs2vecs(test_all_docs_tok, f2v=w2v, weights=weights)\n","  \n","  print(fname, \"\\n----------------------------------\")\n","    \n","  for seed in [0, 24, 729, 857, 403]:\n","\n","    # Evaluate this classifier on all responses.\n","#     print('Evaluate the classifier on all responses')\n","    clf = LogitCV(Cs=[10**i for i in range(-2, 3)], fit_intercept=False, cv=2, dual=np.less(*train_all_vecs.shape), solver='liblinear', n_jobs=-1, random_state=seed) \n","    clf.fit(train_all_vecs, train_all_labels)\n","    #print('Train acc: ', clf.score(train_all_vecs, train_all_labels))\n","    test_acc = clf.score(test_all_vecs, test_all_labels)\n","    #print('Test acc: ', test_acc )\n","    \n","    \n","  ###############################################################\n","  \n","    # Balanced Test Score Calculation\n","    nAncestors = len(test_labels[0])\n","    countCorrect = 0\n","    for i in range(nAncestors):\n","      \n","      scoreResponse0 = clf.predict_proba(test_all_vecs[i].reshape(1,-1))[0,1]\n","      scoreResponse1 = clf.predict_proba(test_all_vecs[i+nAncestors].reshape(1,-1))[0,1]\n","     \n","      if scoreResponse0 > scoreResponse1 and test_labels[0][i] == 1:\n","        countCorrect += 1\n","        \n","      elif scoreResponse1 > scoreResponse0 and test_labels[1][i] == 1:\n","        countCorrect += 1\n","       \n","    bal_test_score =  countCorrect/nAncestors\n","    #print(\"Balanced Test Score:\", bal_test_score )\n","    \n","    # F1 Prediction\n","    \n","    y_pred = []\n","    y_true = []\n","    \n","    for i in range(len(test_labels[0])+len(test_labels[1])):\n","      \n","      scoreResponse = clf.predict_proba(test_all_vecs[i].reshape(1,-1))[0][1]\n","      \n","      if i < nAncestors:\n","        \n","        y_true.append(test_labels[0][i])\n","        \n","      else:\n","        \n","        y_true.append(test_labels[1][i-nAncestors])\n","      \n","      if scoreResponse > 0.5:\n","        y_pred.append(1)\n","        \n","      else:\n","        y_pred.append(0)\n","       \n","    f1Score = f1_score(y_true, y_pred, pos_label=1, average='binary', sample_weight=None)\n","    #print(\"F1 Score:\", f1Score)\n","    \n","    #Store the results\n","    record_25 = record_25.append({'Acc (bal, bal)': bal_test_score, 'Acc (bal, reg)':test_acc , 'F1 (bal, reg)': f1Score}, ignore_index=True)\n","    \n","print(record_25)\n","\n","with open(\"/content/gdrive/My Drive/SARC pol/test_set_results_glove/test25.pickle\", 'wb') as handle:\n","  pickle.dump(record_25, handle)\n","  "],"execution_count":0,"outputs":[{"output_type":"stream","text":["project_training_25.csv \n","----------------------------------\n","   Acc (bal, bal)  Acc (bal, reg)  F1 (bal, reg)\n","0        0.719906        0.655314       0.649343\n","1        0.719906        0.655314       0.649343\n","2        0.719906        0.655314       0.649343\n","3        0.719906        0.655314       0.649343\n","4        0.719906        0.655314       0.649343\n"],"name":"stdout"}]},{"metadata":{"id":"uIxNxWuRpOvE","colab_type":"text"},"cell_type":"markdown","source":["###12.5% project training set"]},{"metadata":{"id":"NXSVCfygpKIL","colab_type":"code","outputId":"c8092018-d29d-48e3-f5cb-1942a5255262","executionInfo":{"status":"ok","timestamp":1552324202681,"user_tz":0,"elapsed":378185,"user":{"displayName":"Joe Farrington","photoUrl":"https://lh5.googleusercontent.com/-bNEtdlkbGn8/AAAAAAAAAAI/AAAAAAAAAF4/7VpSGeR6wrY/s64/photo.jpg","userId":"09132137217736073231"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"cell_type":"code","source":["filename =  ['project_training_12.csv']\n","\n","record_12 = pd.DataFrame()\n","\n","#Load in the test set\n","validdf = pd.read_csv(SARC_POL+'balanced_test.csv', index_col = 0)\n","\n","for fname in filename:\n","  \n","  #Load in the training set\n","  traindf = pd.read_csv(SARC_POL+fname, index_col = 0)\n","  \n","  # Only use responses for this method. Ignore ancestors.\n","  train_resp = traindf['response'].values.tolist()\n","  test_resp = validdf['response'].values.tolist()\n","  train_labels = traindf['label'].values.tolist()\n","  test_labels = validdf['label'].values.tolist()\n","\n","  # Train resp\n","  first_resp = []\n","  second_resp = []\n","  for idx, resp in enumerate(train_resp):\n","\n","    if idx % 2 == 0:\n","      first_resp.append(resp)\n","    else:\n","      second_resp.append(resp)\n","\n","  train_docs = {0: first_resp, 1: second_resp}\n","\n","\n","  # Test resp\n","  first_resp = []\n","  second_resp = []\n","  for idx, resp in enumerate(test_resp):\n","\n","    if idx % 2 == 0:\n","      first_resp.append(resp)\n","    else:\n","      second_resp.append(resp)\n","\n","  test_docs = {0: first_resp, 1: second_resp}\n","\n","\n","  # Train labels\n","  first_label = []\n","  second_label = []\n","  for idx, label in enumerate(train_labels):\n","\n","    if idx % 2 == 0:\n","      first_label.append(label)\n","    else:\n","      second_label.append(label)\n","\n","  train_labels = {0: first_label, 1: second_label}\n","\n","\n","  # Test labels\n","  first_label = []\n","  second_label = []\n","  for idx, label in enumerate(test_labels):\n","\n","    if idx % 2 == 0:\n","      first_label.append(label)\n","    else:\n","      second_label.append(label)\n","\n","  test_labels = {0: first_label, 1: second_label}\n","\n","  ############################################ Khodak et al. 2017\n","  \n","  # Train a classifier on all responses in training data. We will later use this\n","  # classifier to determine for every sequence which of the 2 responses is more sarcastic.\n","  train_all_docs_tok = tokenize(train_docs[0] + train_docs[1])\n","  test_all_docs_tok = tokenize(test_docs[0] + test_docs[1])\n","  train_all_labels = np.array(train_labels[0] + train_labels[1])\n","  test_all_labels = np.array(test_labels[0] + test_labels[1])\n","\n","  weights = None\n","\n","  w2v = vocab2vecs({word for doc in train_all_docs_tok+test_all_docs_tok for word in doc}, vectorfile=CCGLOVE)\n","  train_all_vecs = docs2vecs(train_all_docs_tok, f2v=w2v, weights=weights)\n","  test_all_vecs = docs2vecs(test_all_docs_tok, f2v=w2v, weights=weights)\n","  \n","  print(fname, \"\\n----------------------------------\")\n","    \n","  for seed in [0, 24, 729, 857, 403]:\n","\n","    # Evaluate this classifier on all responses.\n","#     print('Evaluate the classifier on all responses')\n","    clf = LogitCV(Cs=[10**i for i in range(-2, 3)], fit_intercept=False, cv=2, dual=np.less(*train_all_vecs.shape), solver='liblinear', n_jobs=-1, random_state=seed) \n","    clf.fit(train_all_vecs, train_all_labels)\n","    #print('Train acc: ', clf.score(train_all_vecs, train_all_labels))\n","    test_acc = clf.score(test_all_vecs, test_all_labels)\n","    #print('Test acc: ', test_acc )\n","     \n","      \n","  ###############################################################\n","    # Balanced Test Score Calculation\n","    nAncestors = len(test_labels[0])\n","    countCorrect = 0\n","    for i in range(nAncestors):\n","      \n","      scoreResponse0 = clf.predict_proba(test_all_vecs[i].reshape(1,-1))[0,1]\n","      scoreResponse1 = clf.predict_proba(test_all_vecs[i+nAncestors].reshape(1,-1))[0,1]\n","     \n","      if scoreResponse0 > scoreResponse1 and test_labels[0][i] == 1:\n","        countCorrect += 1\n","        \n","      elif scoreResponse1 > scoreResponse0 and test_labels[1][i] == 1:\n","        countCorrect += 1\n","       \n","    bal_test_score =  countCorrect/nAncestors\n","    #print(\"Balanced Test Score:\", bal_test_score )\n","    \n","    # F1 Prediction\n","    \n","    y_pred = []\n","    y_true = []\n","    \n","    for i in range(len(test_labels[0])+len(test_labels[1])):\n","      \n","      scoreResponse = clf.predict_proba(test_all_vecs[i].reshape(1,-1))[0][1]\n","      \n","      if i < nAncestors:\n","        \n","        y_true.append(test_labels[0][i])\n","        \n","      else:\n","        \n","        y_true.append(test_labels[1][i-nAncestors])\n","      \n","      if scoreResponse > 0.5:\n","        y_pred.append(1)\n","        \n","      else:\n","        y_pred.append(0)\n","       \n","    f1Score = f1_score(y_true, y_pred, pos_label=1, average='binary', sample_weight=None)\n","    #print(\"F1 Score:\", f1Score)\n","    \n","    #Store the results\n","    record_12 = record_12.append({'Acc (bal, bal)': bal_test_score, 'Acc (bal, reg)':test_acc , 'F1 (bal, reg)': f1Score}, ignore_index=True)\n","    \n","print(record_12)\n","\n","with open(\"/content/gdrive/My Drive/SARC pol/test_set_results_glove/test12.pickle\", 'wb') as handle:\n","  pickle.dump(record_12, handle)\n","  "],"execution_count":0,"outputs":[{"output_type":"stream","text":["project_training_12.csv \n","----------------------------------\n","   Acc (bal, bal)  Acc (bal, reg)  F1 (bal, reg)\n","0        0.684087        0.645332       0.639403\n","1        0.684087        0.645332       0.639403\n","2        0.684087        0.645332       0.639403\n","3        0.684087        0.645332       0.639403\n","4        0.684087        0.645332       0.639403\n"],"name":"stdout"}]},{"metadata":{"id":"x97f8h26o_0I","colab_type":"text"},"cell_type":"markdown","source":["###6.25% project training set"]},{"metadata":{"id":"mEnsVqZ3h-0q","colab_type":"code","outputId":"aab39206-968e-43aa-ff38-f4b8f369522e","executionInfo":{"status":"ok","timestamp":1552323217108,"user_tz":0,"elapsed":362808,"user":{"displayName":"Joe Farrington","photoUrl":"https://lh5.googleusercontent.com/-bNEtdlkbGn8/AAAAAAAAAAI/AAAAAAAAAF4/7VpSGeR6wrY/s64/photo.jpg","userId":"09132137217736073231"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"cell_type":"code","source":["filename =  ['project_training_6.csv']\n","\n","record_6 = pd.DataFrame()\n","\n","#Load in the test set\n","validdf = pd.read_csv(SARC_POL+'balanced_test.csv', index_col = 0)\n","\n","for fname in filename:\n","  \n","  #Load in the training set\n","  traindf = pd.read_csv(SARC_POL+fname, index_col = 0)\n","  \n","  # Only use responses for this method. Ignore ancestors.\n","  train_resp = traindf['response'].values.tolist()\n","  test_resp = validdf['response'].values.tolist()\n","  train_labels = traindf['label'].values.tolist()\n","  test_labels = validdf['label'].values.tolist()\n","\n","  # Train resp\n","  first_resp = []\n","  second_resp = []\n","  for idx, resp in enumerate(train_resp):\n","\n","    if idx % 2 == 0:\n","      first_resp.append(resp)\n","    else:\n","      second_resp.append(resp)\n","\n","  train_docs = {0: first_resp, 1: second_resp}\n","\n","\n","  # Test resp\n","  first_resp = []\n","  second_resp = []\n","  for idx, resp in enumerate(test_resp):\n","\n","    if idx % 2 == 0:\n","      first_resp.append(resp)\n","    else:\n","      second_resp.append(resp)\n","\n","  test_docs = {0: first_resp, 1: second_resp}\n","\n","\n","  # Train labels\n","  first_label = []\n","  second_label = []\n","  for idx, label in enumerate(train_labels):\n","\n","    if idx % 2 == 0:\n","      first_label.append(label)\n","    else:\n","      second_label.append(label)\n","\n","  train_labels = {0: first_label, 1: second_label}\n","\n","\n","  # Test labels\n","  first_label = []\n","  second_label = []\n","  for idx, label in enumerate(test_labels):\n","\n","    if idx % 2 == 0:\n","      first_label.append(label)\n","    else:\n","      second_label.append(label)\n","\n","  test_labels = {0: first_label, 1: second_label}\n","\n","  ############################################ Khodak et al. 2017\n","  \n","  # Train a classifier on all responses in training data. We will later use this\n","  # classifier to determine for every sequence which of the 2 responses is more sarcastic.\n","  train_all_docs_tok = tokenize(train_docs[0] + train_docs[1])\n","  test_all_docs_tok = tokenize(test_docs[0] + test_docs[1])\n","  train_all_labels = np.array(train_labels[0] + train_labels[1])\n","  test_all_labels = np.array(test_labels[0] + test_labels[1])\n","\n","  weights = None\n","\n","  w2v = vocab2vecs({word for doc in train_all_docs_tok+test_all_docs_tok for word in doc}, vectorfile=CCGLOVE)\n","  train_all_vecs = docs2vecs(train_all_docs_tok, f2v=w2v, weights=weights)\n","  test_all_vecs = docs2vecs(test_all_docs_tok, f2v=w2v, weights=weights)\n","  \n","  print(fname, \"\\n----------------------------------\")\n","    \n","  for seed in [0, 24, 729, 857, 403]:\n","\n","    # Evaluate this classifier on all responses.\n","#     print('Evaluate the classifier on all responses')\n","    clf = LogitCV(Cs=[10**i for i in range(-2, 3)], fit_intercept=False, cv=2, dual=np.less(*train_all_vecs.shape), solver='liblinear', n_jobs=-1, random_state=seed) \n","    clf.fit(train_all_vecs, train_all_labels)\n","    #print('Train acc: ', clf.score(train_all_vecs, train_all_labels))\n","    test_acc = clf.score(test_all_vecs, test_all_labels)\n","    #print('Test acc: ', test_acc )\n","    \n","  ###############################################################\n","    \n","    # Balanced Test Score Calculation\n","    nAncestors = len(test_labels[0])\n","    countCorrect = 0\n","    for i in range(nAncestors):\n","      \n","      scoreResponse0 = clf.predict_proba(test_all_vecs[i].reshape(1,-1))[0,1]\n","      scoreResponse1 = clf.predict_proba(test_all_vecs[i+nAncestors].reshape(1,-1))[0,1]\n","     \n","      if scoreResponse0 > scoreResponse1 and test_labels[0][i] == 1:\n","        countCorrect += 1\n","        \n","      elif scoreResponse1 > scoreResponse0 and test_labels[1][i] == 1:\n","        countCorrect += 1\n","       \n","    bal_test_score =  countCorrect/nAncestors\n","    #print(\"Balanced Test Score:\", bal_test_score )\n","    \n","    # F1 Prediction\n","    \n","    y_pred = []\n","    y_true = []\n","    \n","    for i in range(len(test_labels[0])+len(test_labels[1])):\n","      \n","      scoreResponse = clf.predict_proba(test_all_vecs[i].reshape(1,-1))[0][1]\n","      \n","      if i < nAncestors:\n","        \n","        y_true.append(test_labels[0][i])\n","        \n","      else:\n","        \n","        y_true.append(test_labels[1][i-nAncestors])\n","      \n","      if scoreResponse > 0.5:\n","        y_pred.append(1)\n","        \n","      else:\n","        y_pred.append(0)\n","       \n","    f1Score = f1_score(y_true, y_pred, pos_label=1, average='binary', sample_weight=None)\n","    #print(\"F1 Score:\", f1Score)\n","    \n","    #Store the results\n","    record_6 = record_6.append({'Acc (bal, bal)': bal_test_score, 'Acc (bal, reg)':test_acc , 'F1 (bal, reg)': f1Score}, ignore_index=True)\n","    \n","print(record_6)\n","\n","with open(\"/content/gdrive/My Drive/SARC pol/test_set_results_glove/test6.pickle\", 'wb') as handle:\n","  pickle.dump(record_6, handle)\n","  "],"execution_count":0,"outputs":[{"output_type":"stream","text":["project_training_6.csv \n","----------------------------------\n","   Acc (bal, bal)  Acc (bal, reg)  F1 (bal, reg)\n","0         0.65825        0.608045       0.612931\n","1         0.65825        0.608045       0.612931\n","2         0.65825        0.608045       0.612931\n","3         0.65825        0.608045       0.612931\n","4         0.65825        0.608045       0.612931\n"],"name":"stdout"}]},{"metadata":{"id":"0_nl_okfrkRv","colab_type":"text"},"cell_type":"markdown","source":["## One data frame for GloVE results"]},{"metadata":{"id":"-eGOfK4Xrjtb","colab_type":"code","colab":{}},"cell_type":"code","source":["with open(\"/content/gdrive/My Drive/SARC pol/test_set_results_glove/test6.pickle\", 'rb') as handle:\n","  record_6 = pickle.load(handle)\n","  \n","with open(\"/content/gdrive/My Drive/SARC pol/test_set_results_glove/test12.pickle\", 'rb') as handle:\n","  record_12 = pickle.load(handle)\n","\n","with open(\"/content/gdrive/My Drive/SARC pol/test_set_results_glove/test25.pickle\", 'rb') as handle:\n","  record_25 = pickle.load(handle)\n","\n","with open(\"/content/gdrive/My Drive/SARC pol/test_set_results_glove/test50.pickle\", 'rb') as handle:\n","  record_50 = pickle.load(handle)\n","\n","with open(\"/content/gdrive/My Drive/SARC pol/test_set_results_glove/test100.pickle\", 'rb') as handle:\n","  record_100 = pickle.load(handle)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"aoFBdG05rpOf","colab_type":"code","colab":{}},"cell_type":"code","source":["Glove_results = pd.DataFrame()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-IDgHl4yr5AV","colab_type":"code","colab":{}},"cell_type":"code","source":["Glove_results = Glove_results.append(np.mean(record_100, axis=0), ignore_index=True)\n","Glove_results = Glove_results.append(np.mean(record_50, axis=0), ignore_index=True)\n","Glove_results = Glove_results.append(np.mean(record_25, axis=0), ignore_index=True)\n","Glove_results = Glove_results.append(np.mean(record_12, axis=0), ignore_index=True)\n","Glove_results = Glove_results.append(np.mean(record_6, axis=0), ignore_index=True)\n","Glove_results.index = ['100%','50%','25%','12.5%','6.25%']"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Nb7zQdaKRg35","colab_type":"code","colab":{}},"cell_type":"code","source":["with open(\"/content/gdrive/My Drive/SARC pol/test_set_results/GLOVE_results.pickle\", 'wb') as handle:\n","  pickle.dump(Glove_results, handle)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"BTyBKH_tRirb","colab_type":"code","colab":{}},"cell_type":"code","source":["with open(\"/content/gdrive/My Drive/SARC pol/test_set_results/GLOVE_results.pickle\", 'rb') as handle:\n","  Glove_results = pickle.load(handle)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ij9OhYLUsH_y","colab_type":"code","outputId":"01c071a0-ed51-4b0e-a5ba-ccdbf7477fa1","executionInfo":{"status":"ok","timestamp":1552383672373,"user_tz":0,"elapsed":730,"user":{"displayName":"Joe Farrington","photoUrl":"https://lh5.googleusercontent.com/-bNEtdlkbGn8/AAAAAAAAAAI/AAAAAAAAAF4/7VpSGeR6wrY/s64/photo.jpg","userId":"09132137217736073231"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"cell_type":"code","source":["Glove_results"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Acc (bal, bal)</th>\n","      <th>Acc (bal, reg)</th>\n","      <th>F1 (bal, reg)</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>100%</th>\n","      <td>0.744568</td>\n","      <td>0.676160</td>\n","      <td>0.669662</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>0.729888</td>\n","      <td>0.670581</td>\n","      <td>0.666270</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>0.719906</td>\n","      <td>0.655314</td>\n","      <td>0.649343</td>\n","    </tr>\n","    <tr>\n","      <th>12.5%</th>\n","      <td>0.684087</td>\n","      <td>0.645332</td>\n","      <td>0.639403</td>\n","    </tr>\n","    <tr>\n","      <th>6.25%</th>\n","      <td>0.658250</td>\n","      <td>0.608045</td>\n","      <td>0.612931</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       Acc (bal, bal)  Acc (bal, reg)  F1 (bal, reg)\n","100%         0.744568        0.676160       0.669662\n","50%          0.729888        0.670581       0.666270\n","25%          0.719906        0.655314       0.649343\n","12.5%        0.684087        0.645332       0.639403\n","6.25%        0.658250        0.608045       0.612931"]},"metadata":{"tags":[]},"execution_count":6}]}]}